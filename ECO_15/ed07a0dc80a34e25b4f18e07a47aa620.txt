Recommandations  relatives aux interactions Ecologie-Energie  Sans énergie on n’a plus rien, sans énergie on ne peut plus rien faire.   Recommandations liées au premier Mémoire : problèmes spécifiques liés à l’électricité  Recommandation N°1. Développer les recherches visant à mieux prévoir l’évolution climatique, en particulier sur les aspects   pour lesquels nous n’avons actuellement que peu de recul, comme les courants marins de grands fonds.   Recommandation N°2. La réduction de l’émission de CO2 lié à la consommation d’essence et de fuel de l’automobile, à la fois par les véhicules individuels et les poids lourds, passe par une amélioration notable du rendement des moteurs que ne permet pas le moteur dit à explosion.  L’essentiel des aides à la recherche- développement à la  fois gouvernementales et des constructeurs automobiles doivent porter sur la mise au point d’un nouveau type de moteur au rendement deux fois meilleur que les moteurs actuels, et utilisable par tous les véhicules tant individuels que camions.    Recommandation N°3. Les options véhicules automobiles totalement électriques à batteries, ne peuvent conduire qu’à des véhicules uniquement à usage urbain. Leur utilisation avec décharges profondes et recharges rapides, sont idéales pour tuer leurs batteries. Toutes les aides publiques actuelles, portant sur ces options tant véhicules que bornes de recharge sont à supprimer.   Les véhicules hybrides, hors de leur fonctionnement urbain sur batteries, s’avérant plus polluants que les véhicules classiques, cette information sera systématiquement divulguée, et ils ne pourront faire  l’objet d’aucune aide publique.   Recommandation N°4. Ne laisser croire à aucun moment que les piles à combustibles et l’hydrogène peuvent être une voie de  recours pour l’automobile.            Recommandation N°5. Le niveau de production de l’éolien et du photovoltaïque solaire ensemble ne doit pas dépasser 20 % de la production électrique française totale, car le risque d‘instabilité du réseau électrique national augmenterait fortement.  Recommandation N°6. Si malgré tout le niveau de production de l’éolien et du photovoltaïque dépense les 20% de la production. Il importe qu’un plan d’intervention soit dressé pour prévoir les conséquences de l’écroulement du réseau pour une durée de l’ordre de la semaine, indiquant les interventions à mener en pareil cas, à la fois par les organismes publics et les particuliers. Et que ce plan soit rappelé chaque fois qu’une forte tempête est annoncée.  Recommandation  N°7. La construction des éoliennes ayant atteint le stade production en série à partir duquel il n’y a plus guère de réduction notable de coût à attendre, il y a donc lieu de supprimer totalement la CSPE, avec réduction immédiate d‘au moins 7% sur les factures d’électricité des particuliers. Ce que vient d’ailleurs de décider la Cour Européenne de Justice  par son arrêt en date du  25 juillet 2018. Recommandation N° 8. Aller vers la réalité des coûts concernant la construction des éoliennes, sans aucune aide et du rachat par EDF du courant produit qui sera aligné sur le coût du marché d’échange international.  Recommandation N°9. Il faut s’assurer que les interconnections électriques France-Angleterre peuvent permettre l’échange d‘électricité dans les deux sens.  Recommandation N°10. Toute programmation gouvernementale dans le domaine électrique devra comporter le coût de l’électricité au particulier en résultant.  Recommandation N°11. Le gouvernement ne pourra plus imposer à EDF de vendre du courant à perte à ses concurrents.  Recommandation N°12. L’objectif de fermeture de 28 centrales nucléaires d’ici 2038, est à la fois illogique, irréaliste, ruineux et dangereux. Le programme de transition écologique en la matière est à revoir.  Recommandation N°13.   L’Agence de bassin concernée ne peut s’opposer à la remise en état des petites installations hydrauliques en service jusqu’à la fin de la dernière guerre mondiale.  Recommandation N°14. Si l’Agence de bassin juge qu’une passe à poisons est nécessaire, lors de la remise en  état  d’une petite installation hydraulique, elle en assure elle-même le financement si elle juge  cette passe nécessaire, et sa construction ne peut retarder la remise en service de l’installation.  Recommandation N°15. La centrale britannique Dungeness B ( Deux réacteurs AGR –Modérateur graphite, CO2 gaz caloporteur, de 600 MW chacun), vient de voir sa durée de fonctionnement prolongée de 2018 à 2028. Comme elle est la plus proche de la France, et que la ville de Boulogne-sur-Mer et tout le Boulonnais sont directement sous son vent,  il faut imposer aux autorités britanniques de transmettre l’étude d’impact qui a du être réalisée à l’occasion de cette prolongation. Le fait que l’exploitant est EDF Energy devrait faciliter les choses.    Recommandations liées au second Mémoire : Sécurité éolienne  Recommandation N°16. Dans les publications relatives à l’éolien, il sera pris grand soin de ne pas mélanger puissance  et énergie. Les publications présentant des données erronées seront tenues sur simple courrier  des lecteurs effectué par lettre recommandée de procéder à un rectificatif de même   importance que l’article erroné.  Recommandation N°17. Abaisser le niveau de puissance des éoliennes pour lesquelles une étude d‘impact est  obligatoire de 2,3 MW à 1 MW.   Recommandation N°18. Dans toute publication officielle indiquant la puissance totale des éoliennes installées, il sera tenu compte des éoliennes détruites ou hors service. Les publications officielles devront  indiquer par ailleurs la puissance du parc éolien français ayant dépassé sa durée de vie, prévue.  Recommandation N°19. Il sera créé une Agence de Sécurité Eolienne analogue à l’Agence de Sécurité Nucléaire, qui veillera entre-autres au respect des spécifications techniques portant sur toutes les parties de l’éolienne, mat et fondations comprises.   Recommandation N° 20. Toutes les éoliennes seront soumises à une révision décennale.  Recommandation N°21. Les normes élaborées par la CEI en ce domaine seront transformées en normes françaises   Recommandation N°22. Il sera indiqué dans les comptes rendus de fabrication, de montage et d’entretien, les précautions prises pour éviter les phénomènes de corrosion fissurante.  Recommandation N°23. Si il y a certification, elle portera sur l’ensemble de l’éolienne, mat et fondations compris.   Recommandations liées au troisième Mémoire : Pétrole et Gaz Naturel.  Recommandation N°24. Les gisements d’hydrocarbures actuellement exploités en France le seront jusqu’à ce qu’ils ne soient plus rentables.  Recommandation N°25. La recherche en France de nouveaux gisements  de pétrole et de gaz tant classique que de schiste seront de nouveau autorisés, conformément aux souhaits émis par les Missions de l’Assemblée Nationale et du Sénat, afin de faciliter la dé-indexation des prix du pétrole et du gaz naturel lors des discussions à venir.   L’interdiction de recherche d’hydrocarbure en date du 19 décembre  2017, sera annulée.  Recommandation N°26. Veillez à ce que dans leur exploitation du pétrole et gaz de schiste sous la Manche, les Anglais  n’empiètent pas sur le domaine français.  Recommandation N°27. Modification du régime foncier français, afin de permettre aux particuliers de mettre en valeur le sous-sol de leurs terrains.  Recommandation N°28. En raison de son très important domaine maritime, la France devra suivre de très près, les développements en cours concernant l’exploitation de l’hydrate de méthane.  Recommandation N°29. Le gaz naturel étant de loin la meilleure des solutions gazières en matière de chauffage des habitations particulières, le réseau gazier national sera développé autant que faire ce peut, en harmonie avec le chauffage électrique.    Recommandation N°30. Il faudra s’assurer que l’ensemble des interconnections du réseau gazier permettent des distributions dans les deux sens.         Mémoire relatif aux problèmes d’écologie et d’énergie.  I Problèmes spécifiques à l’électricité  Plan  I. Thème réchauffement climatique : certitudes, incertitudes  II. Thème transports  III. Thème énergie électrique  Résumé des conclusions    I.	Certitudes et incertitudes du réchauffement climatique  L’explication aujourd’hui admise pour expliquer les phases refroidissement-réchauffement-du climat terrestre est la fluctuation cyclique de l’orbite terrestre, donnée la première fois par Milankovitch, et dont la preuve a été faite actuellement pour les très longues fluctuations.  Le dernier cycle de l’ère quaternaire a été tout particulièrement étudié. La durée de refroidissement de la dernière glaciation ( Würm) est actuellement estimée à  120 000 ans.  Les traces incontestables trouvées dans les strates géologiques indiquent que le réchauffement climatique a effectivement commencé il y a 12 000 ans. A cette époque la glace recouvrait totalement l’Angleterre jusqu’à Londres, ainsi que le Nord de la France. Les Alpes avec leurs vallées étaient totalement  recouvertes de glace. Le niveau des océans était descendu à 120 m au dessous du niveau actuel. Il semble que la période de réchauffement est nettement plus rapide que la période de glaciation  En dehors de ces variations de longue durée, l’histoire des deux derniers millénaires a enregistré des fluctuations relativement rapides : période très froide à la fin de l’Empire romain, où l’on a pu, lors d‘un hiver particulièrement  froid, aller à pied de France en Angleterre, la Manche étant gelée. Une période de réchauffement relativement rapide après l’An Mil a conduit à une notable amélioration de la production agricole. Plus près de nous, et mieux connue, nous avons la petite période glacière de l’époque du règne de Louis XIV, où la calotte polaire arctique reliait la Norvège à l’Islande, et celle-ci au Groenland.  Il n’existe aucune explication unanimement reconnue actuellement pour ces variations rapides. Celle la plus souvent avancée est de les lier à des fluctuations solaires, pour d’autres le système solaire dans son déplacement d’ensemble rencontre des zones de l’espace plus chargées en gaz et poussières.  Enfin il existe des variations très rapides, telles que les “années sans été”. Elles sont liées de façon certaines aux très fortes éruptions volcaniques, dont la plus connue est celle du Krakatoa (en 1883), qui a donné lieu à de sérieuses études. Les maux d’Egypte de l’Ancien testament gardent probablement le souvenir de l’explosion de Santorin, il y a environ 3 500 ans, et  dont on a retrouvé la trace dans les glaces  du Groënland. Avant Santorin, il y a eu en Europe, au cours des temps préhistoriques, celle de Milo dont le cratère effondré est plus important que celui de Santorin. Enfin si l’on considère les temps géologiques, l’impact d’importants météores, dont les traces  des cratères géants sont toujours visibles (dont en France : Rochechouart. Haute-Vienne), ont donnés lieu de façons certaines à de forts refroidissements sur plusieurs décennies.  Une analyse fine des carottes de glace de l’Antarctique montre que le taux de CO2 de l’atmosphère suit une évolution parallèle à celle de températures, mais après un décalage de  800 ans  environ. (Pour nos amis canadiens, c’est un problème d’oeuf et de poule). Il faut également se rappeler que les thermomètres précis et fiables ne sont apparus que sous le règne de Louis XV. Les relevés de températures systématiques enregistrés en France, sont ceux de la Station de Montsouris. A l’époque le parc de Montsouris était en pleine campagne, loi du centre ville, il est maintenant intégré dans Paris. Ce qui se traduit par une élévation de température locale de l’ordre de 2°, dont les commentateurs qui annoncent des records de température ne tiennent pas compte. De plus, les relevés de température au niveau de l’ensemble du globe, terre et océans, calottes polaires et déserts, n’existent que depuis que des satellites météo ont été lancés (le premier Tiros 1. 1960) ce qui fait que les archives d’ensemble, précises et détaillées remontent seulement à une quarantaine d’années, et pour une durée bien moindre pour les courants marins de fond. Etant donné nos connaissances actuelles, une prévision d’évolution à l’échelle d‘un siècle n’est pas crédible, on ne fait que jongler avec des logiciels.  La climatologie a donc encore de grand progrès à faire, et les affirmations de certains climatologues en forme des paroles d‘évangile, pour la fin du siècle, et même pour les décennies à venir ne sont pas crédibles. Les Cassandres savent bien qu’ils seront morts avant  que les dates de leurs prévisions soient atteintes. Ils n’ont pas à craindre pour eux-mêmes de retour de bâton. Mais il est certain que nous sommes dans une période géologique d‘augmentation de température. Il ne peut donc être question que de parler d’accélération du réchauffement climatique, du fait de l’activité humaine.   Le danger du positionnement français  L’accord de Paris sur le climat a été conclu le 12 décembre 2015, par un pseudo vote unanime, les opposants n’ayant pas eu le temps d’exprimer leurs positions en raison de l’extrême rapidité de ce vote. Ce vote tronqué a été voulu par le représentant français, M. Fabius, alors Ministre français des affaires étrangères, Président des débats. Les raisons politiques liées à l’élection présidentielle à venir furent sûrement à l’origine de ce comportement.  Le problème est que la France s’est présentée et a voulu apparaître comme le leader mondial en la matière, et pour certains comme le maître donneur de leçons au monde comme à son habitude, alors qu’elle ne représente qu’1 % de la population mondiale. Il est quasiment impossible aux nouveaux dirigeants français de faire machine arrière sans perdre toute crédibilité au niveau mondial. Il leurs faut donc mettre en œuvre le programme de l’Accord de Paris, dont principalement la réduction de l’usage des produits carbonés. Il leurs faut développer de nouvelles technologies, ou améliorer fortement les anciennes, et donc “essuyer les plâtres”, ce qui entraine des coûts de développement considérables. Les ingénieurs savent bien que les premières technologiques coutent bien plus que leur estimation de départ (les ingénieurs utilisent l’expression américaine de règle du Pi à la célèbre valeur  3,14). C’est ce qui se vérifie aussi bien pour le nouveau type de réacteur nucléaire EPR développé par la France, que pour la Canopée du Forum des Halles de Paris,... Les dépenses de développement seront à la charge de la France, alors que l’Amérique, la  Chine, … ont  profiteront sans bourse délier (Dans le corps de ce mémoire ont trouvera l’exemple du photovoltaïque effectué en France, acquis à prix très réduit par le Canada, avant  de passer en Chine qui en inonde le monde.)  Nous voyons actuellement les conséquences du choix de la taxation pour répondre à l’obligation de réduire la consommation des carburants carbonés, en attendant la poursuite du gouvernement en justice pour non respect des accords internationaux élaborés et votés au nom de la France.  Il est un point clé qu’il me semble indispensable de rappeler avant de passer en revue les problèmes de nature écologique : nous sommes entrés dans une guerre économique sans précédent. Face aux USA, à la Chine,... le bon choix des options de développement possibles est seul à même de contrer notre déchéance économique. Si les choix de développement portent sur des impasses technologiques, ils conduiront fatalement à notre effondrement  économique et à tous les excès. Et cela n’est pas à l’échéance d’un siècle, comme pour les problèmes liés au réchauffement climatique, c’est à l‘échéance de la décennie ! Les choix définitifs à faire au cours des années immédiatement à venir sont donc redoutables.   II.	Thème des transports  Les moyens de transport, excepté le train électrique, sont une part importante du rejet humain du C02 dans l’atmosphère. Les autres étant le chauffage, et l’industrie (dont la production d’électricité hors la France). Il ne faut cependant pas oublier l’important rejet naturel de CO2 venant des volcans, ou des grands incendies comme celui qui vient de ravager la Californie. Le processus inverse étant la fixation du CO2 par la végétation et l’adsorption par les océans.  Les moyens de transport mécaniques ont commencé à se développer à partir de 1830, avec le  chemin de fer, alors à vapeur et charbon (la première ligne de chemin de fer en France : Saint Etienne -Andrézieux date de 1823). Les moyens routiers sont apparus à la fin du 19ème siècle avec les voitures électriques. Mais une fois les voitures à moteur à explosion au point, elles ont balayé les voitures électriques : 1905 est la dernière année où il y avait en France  plus de stations de recharge de batteries pour les voitures que de pompes à essence !  La domination du moteur à explosion. Les voitures électriques en Europe représentent 0,8 % du parc automobile léger, en France en raison d’un soutien financier hors normes elles sont de 1,2%. On peut donc parler d’une domination totale du moteur à explosion pour les transports routiers. Les points clefs à considérer sont le poids des moteurs des véhicules individuels : 	Moteurs 4 cylindres : 120 à 180 kg 		Moteurs  6 cylindres  220 à 300 kg. 	 A cela s’ajoute un réservoir d’essence de 50-60 litres, soit environ 40 kg, la batterie de  démarrage ayant un poids de l’ordre de  25 kg. (Nous  arrivons ainsi pour les éléments moteurs de la voiture de Monsieur Tout le Monde à 185-245 kg ou 285-365 kg)  Le point clé relativement à l’émission du CO2 résultant de la combustion de l’essence est le  faible rendement de ce type de moteur. Malgré un développement d’un siècle il plafonne à 36 % pour les meilleurs moteurs à essence à allumage  commandé, fabriqués en série. Le  rendement moyen effectif se situe en fonction de l’entretien, et de l’usure du moteur entre 25 et 30%. Le rendement des moteurs diesel, en particulier pour les poids lourds, est  couramment de 4 point au dessus des moteurs à essence. Il n’y a pas à attendre d’améliorations majeures après plus d’un siècle de recherches-développement, pour ces deux types de moteurs.   Alors comment réduire l’émission du CO2 par les véhicules de l’ensemble du parc  automobile ? Deux voies sont possibles : la voie réglementaire et la voie technologique.  Plusieurs options s’offrent à la voie réglementaire : 	Augmentation des taxes portant sur les carburants, afin de réduire, via l’augmentation de leur coût, leur consommation. C’est la voie qui avait été choisie jusqu’ici.   	La voie rationnement, via des tickets, mais qui aurait donné lieu à un marché noir. 	La voie alternative liée aux N° d’immatriculation.(jours pairs, jours impairs). Il est certain que ces trois solutions ont ou auraient donné lieu à des levées de boucliers, comme celle que l’on vient de voir.  	L’incitation pour le co-voiturage, aujourd’hui libre, pourrait se trouver renforcée par le remboursement des frais de transport dans les entreprises. (lieux communs, horaires communs), ou à la prise en charge du transport par les entreprises avec des bus ou mini-bus (solution qui ne pourrait être liée qu’à des cas très particuliers).  Mais toutes ces solutions ne sont pas à l’échelle du problème.  L’option technologique.  La aussi plusieurs solutions ont déjà été étudiées et pour certaines ont donné lieu à des opérations de grande ampleur.   1. L’utilisation de carburants contenant moins de carbone : hydrogène, méthane (ou gaz naturel) propane, butane au lieu du mélange actuel dont nous prendront pour calculer l’amélioration possible le mélange octane-septane. (Les supers carburants, où le carbone est remplacé par le bore, testés par l’armée américaine au cours des années 60 étant exclus en raison de leurs énormes inconvénients, coûts et dangerosités). En prenant pour simplifier que le rendement de moteurs tournant avec ces autres hydrocarbures, nous auront les réductions des émissions de CO2 suivantes :  	Noms		Formules	Pouvoir calorifique(PCI)	%C	Rapport émission 						MJ/kg					CO2 	Méthane 	CH4			50,0			0,75		0,79	 	Propane	C3H8			46,4			0,82		0,94 	Butane		C4H10			45,8			0,83		0,96 	Essence (C7H16 – C8H18)		44,5			0,84		1  D’où des réductions de 4% pour le Butane, 6% pour le Propane, 21% pour le Méthane.    Il ressort de ces données que seul le méthane permet un gain substantiel des émissions de C02  (ce qui est particulièrement mis en œuvre pour le chauffage des habitations, quand par chance on peut être raccordé au réseau de distribution de gaz naturel). Mais le problème pour l’automobile est que la température de liquéfaction du méthane est de -161° (L’hydrate de méthane objet actuel d’études et recherches, est seulement stable à 2°C, mais sous 300 atmosphères, ce qui n’amène rien par rapport au stockage haute pression, typiquement  200 atmosphères, dans de lourdes bouteilles métalliques)  Quelque soit le calorifugeage des réservoirs, on ne saurait éviter des pertes importante lors des périodes de non circulation, d’où des risques d’explosion considérablement accrus dans les parkings souterrains ainsi qu’en cas d’accident.   Le cas de l’hydrogène. Pour sa part l’hydrogène, très souvent mis en avant, car sa combustion ne fournit pas de CO2, mérite des explications particulières. Le problème lié à la basse température de liquéfaction du méthane, se trouve  considérablement aggravé pour l’hydrogène dont la température de liquéfaction est de -253 °, avec un autre inconvénient : sa très faible densité à l’état liquide de 71 kg /m3, c’est à dire par rapport à l’eau  0,07.  Son stockage dans des réservoirs hautement calorifugés pose   d’énormes problèmes qui font que l’H2 n’est actuellement utilisé que dans le domaine spatial. Les solutions alternatives :  -	l’usage de bouteilles métalliques haute pression présente beaucoup plus de problèmes que pour le méthane, en raison de la fragilisation de l’acier par les cycles de mise en pression et décompression. -	 la solution stockage sous forme d’hydrure, bien que très étudiée aux cours des  dernières décennies, n’est absolument pas adaptée à l’automobile aussi bien pour la quantité, son coût et la sécurité.  L’énergie minimum pour provoquer l’explosion d’un mélange hydrogène-air (dès que la  teneur d’hydrogène atteint 4%, ce qui est très facilement atteint en raison de l’accumulation de l’hydrogène  sous les plafonds) est de plus dix fois plus faible que celle du méthane, ce qui fait que l’usage et la présence de véhicule à hydrogène est interdite dans les parkings souterrains.  Sa production et son usage via des piles à combustible sera étudié plus loin.  Conclusion : aucune solution conduisant à une réduction importante de la quantité de CO2 rejetée, n’est à attendre d‘un changement de carburant.  2. L’option voiture électrique C’est l’option technologique choisi par le gouvernement, et pour laquelle des sommes  importantes sont engagées depuis plusieurs années : de l’ordre de dizaines de milliards d’Euro  par le gouvernement, les régions et villes et notre principal constructeur.  Le PPE (Programmation Pluriannuelle de l’Energie), a fixé pour les cinq prochaines années l’objectif  de 1,2 million de voitures électriques individuelles en France   (soit une moyenne de 240 000 par an) et 4,8 millions  dans les 10 ans à venir (soit une moyenne de 480 000 par an, afin d’y arriver. Les chiffres effectifs de vente  sont de 16 200 en 2015, 21 800 en 2016, on est bien loin de compte. Le Plan Climat lancé le 6 juillet 2017 vise la fin de la vente des voitures neuves émettant des gaz à effet de serre ! Il est un fait qui prouve que les gouvernements successifs eux-mêmes ne croient pas à ces projections : aucune obligation n’a été faite en ville que les immeubles nouvellement construit soient dotés, pour chaque place de parking, d’une prise de recharge électrique (et c’est également vrai pour les parkings urbains de toute nature). Et si vous habitez un immeuble demandez à voir le local électrique, vous verrez par vous même qu’aucune possibilité d’extension n’est possible à moins de réaliser d’énormes travaux, tout comme une forte augmentation de la puissance électrique mise à disposition en ville. Et les camions me direz-vous ? Rien n’est prévu et leur nombre est en augmentation.      Cette option officielle va conduire malheureusement à un fiasco qui sera probablement proche d ‘une cinquantaine de milliards d’Euro (si l’on poursuit encore dans cette voie pendant quelques années, cette valeur est à augmenter d’environ une quinzaine de milliards/an,) Le véhicule électrique n’ayant d’avenir que pour quelques niches. (On peut se demander comment elle a été décidée ! Le mythe de la Fée Electricité ?).  Voici pourquoi.  Le principe de la batterie électrique remonte aux premières années du 19ème siècle (Nicolas  Gautherot.1801) de même que celle de la pile à combustible dont la découverte est due à   William Grove en 1839.  Ensuite c’est Gaston Planté qui met au point la première batterie réellement utilisable (plomb-acide) en 1859. De fait il ne visait pas le stockage de l’électricité car la dynamo n’existait pas alors ( Zénobe Gramme 1871 ) mais l’obtention de hautes tensions. Planté a perfectionné pendant 30 ans sa batterie, qui est devenue opérationnelle pour la traction électrique (voitures, tramways) à partit de 1890, suivie de peu par les premiers  véhicules Thomas Edison à batteries nickel-fer. Les voitures automobiles, sans réelle concurrence se sont signalées par des exploits remarquables : participation à la première course française  (Paris-Bordeaux 1896), premier 100 km à l’heure (Jamais contente. 1899), record de distance sans recharge : Paris-Chatellerault. Après sa dégringolade à partir de 1905, de nombreuses tentatives de relance de la voiture  électrique ont eu lieu, notamment lors des crises d’approvisionnement en pétrole, la première  datant de 1919 ! Après la dernière guerre nous avons assisté à de multiples nouvelles tentatives, espacées en général d’une vingtaine d‘années (le temps que les décideurs oublient   qu’il y a eu une précédente tentative).  Lors de la dernière que nous avons vécu, EDF a, sur ordre du gouvernement, acheté 400 voitures Renault Type 4L Ce fut un fiasco total, dont le récit aujourd’hui ferait sourire. Bien sûr d’autres grandes entreprises où l’état était actionnaire ont subi le même dictat. Mais  comme toujours si l’on met toujours en avant ce type de lancement, lorsqu’il aboutit à un échec, c’est le “silence radio”. Comme opérations plus récentes condamnées à mort dès l’origine, nous nous avons eu le lancement de la Swatch (1983), voiture électrique urbaine à l’origine, qui vu les problèmes rencontrés va rapidement devenir une voiture à essence classique. L’opération parisienne Voiture électrique en libre service, dotée de batteries indiquées comme Bolloré, et fabriquées en Roumanie, vient de conduire à un désastre financier à la charge de tous les Parisiens, en attendant le futur échec de la Zoé de Renault.   D’autres pays ont également voulu imposer une relance de la voiture électrique. La plus connue est celle qui eût lieu en Californie, dont le sénat avait décidé par la loi, le remplacement de toutes les voitures à essence de la Californie par des voitures électriques, en dix ans, avec une taxation des voitures à essence restantes, augmentant chaque année au cours des dix ans suivant cette décision. Au cours  de la décennie qui a suivie les voitures électriques californiennes ont disparues mais pas la taxation. Plus récemment  la Tesla à 100 000 $  ( 172 000 pour la Roadster) l’unité vient  de conduire son constructeur à la faillite.  Les raisons des échecs passés et à venir. Prenons une voiture électrique indiquée comme pouvant parcourir 200 km et coutant 3 fois plus cher qu’une voiture à essence de même standing, malgré ses multiples contraintes et sa moindre fiabilité. Il faut savoir que la valeur indiquée correspond à un déplacement sur autoroute, à vitesse stabilisée, en région plane, de jour, par beau temps. C’est dire dans des conditions irréalistes.   Voyons ce que deviennent ces 200 km  dans la réalité :  -	sur route à revêtement de bitume 	 -25 km		 -	par temps de pluie			- 20 km -	de nuit					-25 km -	par temps froid 			-30 km.  Quand toutes ces conditions se trouvent réunies, les 200 km sont devenus 100 km. Mais dans ce cas, nous sommes en décharge totale, et toutes les expériences menées sur tous les types de batteries, montrent qu’il faut éviter les décharges profondes, qui par leurs répétitions tuent la batterie, d’autant plus vite que la décharge est rapide, (et donc que la vitesse de la voiture est grande) et donc qu’elle chauffe L’autre façon de tuer rapidement une batterie est la recharge rapide qui conduit également à une surchauffe de celle-ci. La personne qui veut assurer une bonne durée de vie à ses batteries, doit limiter les  décharges  à 10% de la charge totale (d’où 20 km)  avec une décharge la plus lente possible (les feux rouges de la circulation urbaine auront pour une fois un intérêt, en imposant une vitesse moyenne faible). Les batteries les plus connues des usagers, les batteries de démarrage qui bien qu’utilisées dans un contexte voisin ont une durée de vie de 50 à 100 h maximum. Les derniers développements ont porté sur le chauffage du conducteur et passagers, l’hiver, et à l’intersaison : remplacement du chauffage électrique, source d’une importante  consommation d’électricité, par une pompe à chaleur, mais avec une envolée du coût, et une éventuelle consommation électrique d’été. (A titre d’information historique, les 4 L Renault d’EDF évoquées ci-dessus, étaient dotée d’une chaufferette fuel d’où un réservoir de fuel et en plein hiver la consommation fuel de chauffage, égalait la consommation normale d‘une voiture à moteur à explosion, dans les mêmes conditions !!)      Enfin il faut indiquer que le rendement de restitution par les batteries de l’énergie électrique, dans les meilleures conditions est seulement de l’ordre de 60%. L’énergie perdue se retrouve sous forme de chaleur, provoquant l’augmentation de la température ce qu’elles n’aiment pas. Récemment des batteries au lithium, introduites par Boeing dans son dernier appareil   (Airliner), ont tellement chauffées qu’elles ont provoquées des incendies, qui ont conduits à l’interdiction de vol des appareils. Ce même type de batteries, dans le cas de l’usage routier, du fait des secousses et vibrations bien plus fortes, présenteront bien entendu ce type de risque. La production actuelle du lithium essentiellement bolivienne pose des problèmes de plusieurs natures : économique (surenchère possible) et écologique du fait de devoir utiliser beaucoup d’eau  pour sa production en milieu désertique.  Tous ces éléments montrent que les véhicules électriques à batteries   (camions et bus compris) sont et resteront strictement des véhicules urbains.  Qu’en est-il des véhicules dotés d’une pile à combustible ?  D’importantes et couteuses recherches portant sur les piles à combustible ont eu lieu aux  USA et en Europe il y a une quarantaine d’années. En France, l’Institut Français du Pétrole  (IFP) a réalisé des prototypes de 5kw.  Les problèmes majeurs qui ont conduit à l’échec sont : -	la  nécessité d’utiliser des métaux précieux  (platine) pour obtenir les cinétiques rapides nécessaires au niveau des électrodes. -	L’empoisonnement rapide des électrodes par toutes sortes d’impuretés dont les produits carbonés, avec bien sûr principalement le CO2, pour les anodes.  Cette dernière contrainte impose d’utiliser de l’Oxygène sans traces de CO2 ou de vapeurs d‘essence. Un véhicule à pile à combustible ne pourra pas circuler en compagnie de voitures  à essence, à moins d’avoir des systèmes de purification très performants, eux-aussi à base de métaux précieux.  Les développements des années 60, ont cependant conduit à des réalisations spectaculaires, mais dans le domaine spatial, avec en point d’orgue la voiture lunaire (Rover d’Apollo XVII. 1972) utilisant l’Hydrogène et l’Oxygène liquides. Mais là il n’y avait aucune limitation de coût.  L’Hydrogène apparaissant comme seul combustible possible pour les piles à combustibles, il nous faut dire quelques mots sur sa fabrication. H2 ne se trouve pas  dans la  nature à l’état libre. A l’état libre, il est le seul gaz  qui échappe à l’attraction terrestre ! Le composé qui en referme le plus est bien sur l’eau de formule H20.  Mais pour casser la molécule H2O, s’il faut théoriquement la même quantité d’énergie que celle obtenue  par sa combustion. Dans la pratique, c’est loin d’être la cas. Deux solutions existent pour obtenir l’Hydrogène à partir de l’eau.  La première est le chauffage à haute température avec du carbone (charbon). Industriellement cette solution a été pratiquée en Allemagne (procédé Haber), pour la production de l’ammoniac (NH3)  qui permettait la production de l’acide nitrique (NO3H) nécessaire à la fabrication des explosifs. (Procédé Ostwald). Comme  elle entraîne une importante production de CO2, elle est donc aujourd’hui à rejeter.  La seconde est la dissociation de l’eau par l’électricité : l’électrolyse, découverte le 2 mai 1800, par Carlisle et Nicholson dans les jours qui ont suivi l’arrivée du mémoire de Volta à Londres. Seule l’invention de la dynamo a permis la réalisation de la première unité d’électrolyse de l’eau. Cette première mondiale eut lieu en France, à Chalais-Meudon, par le colonel Charles Renard, l’hydrogène servant au gonflement des dirigeables (1886). La première grande unité mondiale mise en service est celle de Rjukan, en Norvège, effectuée pendant le Première Guerre Mondiale par la Société Norks Hydro, sous financement français, pour produire comme en Allemagne de l’ammoniac et à partir de là des explosifs pour les armées  alliées. Ce que n’oubliera pas  Hitler en 1940. L’unité de Rjukan sous contrôle allemand sera la source allemande de l’eau lourde de la  recherche nazie portant sur la bombe atomique. L’unité d’électrolyse de l’eau de Rjukan existe toujours ( Puissance 125 MW- Production de l’Hydrogène à pression atmosphérique) et sert à la fabrication du nitrate d’ammonium, excellent engrais, source de l’azote nécessaire aux plantes. Après la Première Guerre Mondiale, ce procédé va se développer principalement dans les pays disposant de d’électricité d’origine hydraulique. L’unité la plus  puissance du monde alors construite est semble-t-il celle de  Tokyo : 300 MW  que j’ai eu l’occasion de voir en 1976. A la fin des années 60, la Société d’ingénierie  allemande Lurgi, mit au point un électrolyseur sous pression (20 atmosphère) grâce à un matériau nouvellement mis sur le marché : le Téflon. Ce type d’électrolyseur pressurisé, mais de faible puissance, est toujours utilisé dans les sous-marins nucléaires pour fournir l’O2 nécessaire à l’équipage, et fait l’objet de recherches pour le spatial (futures bases lunaires et martiennes) Le plus important programme mondial moderne de développement de l’électrolyse de l’eau, pendant la décennie 1970-1980, est le programme  EDF-GDF. L’intérêt pour EDF était la valorisation des heures creuses nucléaires d’été que l’on prévoyait en liaison avec l’important développement du parc nucléaire en cours. Ce programme aboutit à la fin des années 1980, à une unité prototype de 24 MW de puissance, sous une pression de 20 atmosphères (ACB). Cette unité détient toujours aujourd’hui le record mondial de puissance pour une seule unité d’électrolyse. Ce programme fut arrêté pour une raison économique : les heures creuses nucléaires trouvèrent leur valorisation par l’exportation en Europe, via les réseaux très haute tension, aussi bien vers l’Angleterre (câble courant continu sous la Manche) que jusqu’à la Roumanie. L’Hydrogène produit en France peut être stocké en quantité massive dans les réservoirs souterrains de Gaz de France : pur dans les réservoirs salins, mélangé avec le gaz naturel, jusqu’à 10% d’Hydrogène dans les réservoirs dits de type aquifère. Par ailleurs un réseau de  distribution Hydrogène géré par l’Air Liquide existe dans le Nord de la  France, qui permet les échanges d’Hydrogène inter-usines, dont par exemple l’Hydrogène sous produit fatal de l’électrolyse de solutions de NaCl.  Comme nous l’avons vu plus haut nous ne savons pas stocker les faibles quantités                  d ‘Hydrogène nécessaires à des véhicules routiers, alors que nous savons le stocker massivement en site souterrain. Pour finir signalons que le développement du centre spatial de Kourou a nécessité pour la production de l’hydrogène nécessaire aux fusées comme Ariane, la construction du barrage de ”Petit Saut” permettant l’alimentation d’une unité d’électrolyse de l’eau.(Fourniture simultanée de l’H2 et de l’O2 )  Question rendement, si la tension théorique de décomposition de l’eau par électrolyse est de 1,23 Volt (Conditions dites Normales),  les électrolyseurs industriels produisent l’Hydrogène sous une tension se situant entre 2 et 2,4  volt. La différence étant essentiellement liée à la quantité de courant par unité de surface d’électrodes, le travail de faible densité de courant se traduit par un coût d’investissement nettement plus élevé.  D’où des rendements de 62 % à 56%.  La purification de l’Hydrogène (élimination des traces d’O2 par combustion catalytique), sa compression comme sa liquéfaction sont très couteuses en énergie et contribuent encore à abaisser ces rendements. On sera bien souvent en dessous de  50%. L’électrolyse sous pression permet d’éviter cette perte supplémentaire d’énergie pour comprimer le gaz, en améliorant un peu le rendement  de l’électrolyseur du fait du moindre  volume de gaz présent dans l’électrolyte. Mais  sa réalisation et exploitation posent de redoutables problèmes.  Quid sur les véhicules hybrides.  L’histoire des techniques est sans pitié pour les systèmes hybrides, qui ont donné lieu à l’expression péjorative “ A voile et à Vapeur”. Si deux techniques peuvent se trouver réunies pour le même usage, ce n’est que temporaire, l’une des deux par son évolution, ses perfectionnements prend le dessus.  Le seul assemblage ayant perduré une cinquantaine d‘année est le sous-marin classique qui est maintenant à propulsion nucléaire.    Les véhicules hybrides actuels sans recharge au domicile visent essentiellement transférer leur pollution du cœur des villes à la campagne  environnante. Mais du fait de leur poids plus élevé ils sont globalement plus polluants. Les véhicules hybrides avec recharge au domicile sont intéressant si l’on circule  essentiellement en ville, près de son domicile, et que l’on veut avoir à disposition un véhicule susceptible d’aller à grande distance, comme pour les weekends et les vacances, mais dans ce  cas uniquement avec son moteur à explosion.  Au sujet de la pollution par les micro particules.  Si la production des micro-particules est unanimement dénoncée pour les véhicules diesel, il ne fait cependant pas perdre de vue que le véhicule automobile les émet de trois façons : 	-la combustion des carburants par les moteurs 	- la circulation en raison de l’usure des pneus 	-  les plaquettes de frein lors des freinages Chacune de ces sources compte approximativement pour un tiers. Ainsi dans le cas d’un véhicule électrique, s’il n’y a plus de combustion, leur production par les deux autres sources seront plus élevées en raison du poids plus élevé du véhicule. Un véhicule électrique en émettra donc environ 70 à 75 % par rapport au véhicule à moteur à explosion. Le véhicule hybride en raison de son poids plus élevé, en émettra 110 à 115%  par rapport au véhicule à moteur à explosion.   Quelle solution ?  Toutes les solutions envisagées à la fois dans le PPE (1915) et le Plan Climat vert (2017), n’étant pas à même de répondre au problème posé, y-a-il des solutions non prises en compte jusqu’à présent à même d’avoir un effet positif. On ne peut pas exclure qu’une nouvelle découverte scientifique survienne à l’impromptu, mais il n’y a aucune certitude (la dernière annonce d‘une découverte scientifique majeure dans ce domaine, est celle qui a été appelée la “fusion froide” Elle a remué le monde scientifique et technique, il y a 25 ans, avant de s’évanouir progressivement). L’histoire des techniques vers qui nous nos tournons une nouvelle fois, nous offre l’exemple d’une amélioration majeure dans un domaine très voisin : celui de l’aviation où le moteur à explosion de même principe et de structure très voisine de ceux des voitures automobiles, totalement exclusif jusqu’à la fin de la dernière mondiale, a aujourd’hui quasiment cédé la place au moteur à réaction, qui utilise le principe de la turbine. Il s’en est suivi l’extraordinaire développement du transport aérien. Dans un turboréacteur l’énergie vient bien sûr de la combustion. Une partie de l’énergie est récupérée par la turbine pour faire tourner le compresseur centrifuge.  En aéronautique on arrive à avoir un rendement pour le compresseur de 85 % Par ailleurs les turbomachines ont intérêt à être de petites machines qui tournent le plus vite possible car l’énergie fournie y est proportionnelle au carré de la vitesse. Plus le turbo tourne vite, plus on récupère d’énergie. Or il se trouve que le développement actuel des drones, conduit à réaliser de très petits turbo-réacteurs. La démonstration le plus spectaculaire a été de doter un homme de deux de ces très petits turboréacteurs pour le transformer en homme volant. Ainsi équipé il a effectué la traversée la Manche au niveau du détroit du Pas de Calais, le 29 septembre 2008 (Yves Rossy, dit Jetman).  Il se trouve également que l’une des sociétés françaises qui développe ce type de petit réacteur à nom Hispano Suiza, célèbre pour ses automobiles avant la guerre 14-18, et qui après cette guerre a abandonné le secteur automobile pour passer à celui de l’aviation !    Toutes ces données conduisent à préconiser ce type de moteur pour arriver à réduire d’au moins de moitié la consommation d’essence de tout le secteur automobile (camions  compris), tout en gagnant en légèreté d’où également une réduction de la production de micro-particules.     III. Thème énergie : électricité, énergies renouvelables  Production électrique  Il faut d’abord  rappeler deux points clés : - l’électricité n’existant pas à l’état naturel (hors les éclairs pendant les orages) il faut la produire.  - On ne crée pas d’énergie, on la capte et on la transforme.  Les diverses sources sont :   -	 d’origine nucléaire liée au changement des structures des noyaux atomiques (selon la célèbre formule d’Enstein E=mC2)   -	la combustion c’est à dire une énergie chimique,  -	l’hydraulique c’est à dire une énergie dite gravitationnelle,   -	le photovoltaïque c’est à dire la captation d’une part de l’énergie lumineuse émise par le soleil, qui vient également de l’énergie nucléaire, -	le vent, l’énergie dite éolienne, ayant pour origine principale la captation différenciée de l’énergie solaire par les terres et les océans   D’autres sources existent, les principales sont : la géothermie ayant pour origine l’énergie nucléaire du noyau terrestre, l’utilisation du gradient thermique des mers, l’énergie marémotrice liée aussi à l’énergie gravitationnelle  (influences croisées de la Terre et de la Lune), … Il est un point clé développé déjà ci-dessus et plus loin : on ne sait pas stocker massivement l’électricité sous la forme électricité.  En 2016, le “mix électrique” s’est établi comme suit :  A niveau européen : combustibles carbonés : 48,7 %, nucléaire : 25,7 %, hydraulique : 12,1 %, éolien : 9,7 %,  photovoltaïque : 3,5 % %,  autres : 0,3 %.  Pour la France en 2016, pour une production totale alimentant le réseau électrique national, elle s’est montée à 476,9 TWh, avec la répartition suivante : nucléaire : 80 %, hydraulique : 13,4 % , éolien : 4,3 % , solaire : 1,7 %.  La production totale française : dont celle produite par les industriels pour leurs besoins propres (hors Marine nationale) : 531,3 TWh. Les industriels n’ayant pas de centrales nucléaires, le % du nucléaire français se chiffre à 72,3 %.   Les moyennes d’émissions de  CO2 pour la production électrique par les pays européens s’établissait comme suit en 2016 : 		France 		 0,09  kg CO2/KWh électrique.  		Espagne 	 	0,48 		Italie  			0,59 		Allemagne  		0,60 		Royaume Uni 		0,64 		Danem	ark		0,84    Maximum : 	Luxembourg 		1,08 Minimum	Suède			0,04  Le minimum de la Suède est liée à sa géographie qui lui permet une production électrique presque exclusivement hydraulique. A l’inverse le Luxembourg a une production électrique pratiquement totalement liée aux combustibles carbonés. Pour la France, c’est à la foi le nucléaire et l’hydraulique qui permettent une production électrique émettant aussi peu de CO2.     Le nucléaire  La volonté du Général de Gaule de se doter de l’arme nucléaire conduisit à la construction des premiers réacteurs français. Le premier Chinon EDF1 (filière Graphite Gaz, choisie pour sa plus grande production de Plutonium) est couplé au réseau en 1963, et arrêté en 1973. Son enceinte de protection sphérique abrite maintenant un musée. EDF 2 et 3, mis en service en 1965 et 1966, ont été arrêtés en 1985 et 1990. Leur démantèlement a donné une première expérience en la matière. Le petit réacteur Brennilis en Bretagne EL1, pour tester la filière canadienne Eau Lourde, mis en service en 1967, a été arrêté en 1985, après avoir été victime de deux attentats en 1975 et 1979. Soucieux de tester la filière la plus sécurisée en raison de sa double enceinte de protection le gouvernement français lance la construction du premier réacteur PWR (Pressurized Water Reactor), celui de Fessenheim, qui est construit de 1970 à 1977. Il entre en service en 1978. Les chocs pétroliers qui surviennent au cours des années 70  (1971, 1973, 1979)  conduisent à envisager la construction d’un parc nucléaire d’une cinquantaine d’unités. En 1971,  le choix  gouvernemental français porte définitivement sur la filière PWR, ou REP en français  (Réacteur à Eau Pressurisée), initialement Westinghouse, francisée progressivement. EDF reçoit le feu vert pour ce programme un mois avant la mort du président Pompidou (2 avril 1974), Pierre Messmer étant Premier Ministre. Le programme de construction atteint sa vitesse de croisière sous la présidence de Giscard d’Estaing (1974- 1981). Il a comme principal problème son financement. Giscard d’Estaing a en effet imposé de ne pas avoir recours aux disponibilités de financement française, et donc d’avoir recours au marché  international, afin que les sociétés françaises petites et moyennes ne voient pas leurs sources de financement habituelles s’assécher. Les emprunts en dollars fait par EDF, lui ont coûté cher en raison de la forte montée du dollars qui a suivi. Le poste du remboursement de la dette est alors devenu égal à celui de l’ensemble du personnel EDF. Les dernières des 58 centrales misent en service sont celles de Civaux  (Vienne) en 1997. Lors du développement de ce programme la puissance initiale de 880 MW a été portée à 1561 MW. Les recherches  EDF et CEA de ces dernières années visent à pouvoir allonger sans risque la durée de vue des réacteurs. Les centrales nucléaires hors l’hexagone les plus proches de la France sont les centrales anglaises de Dungeness. Les deux réacteurs de Dungeness A (filière Magnox) ont été arrêtés en 2006. Leur démantèlement est en cours. Les deux réacteurs de Dungeness B ( 2 fois 600 MWe , filière AGR. modérateur graphite, gaz caloporteur CO2) qui devaient s’arrêter en 2018, viennent de recevoir leur autorisation de fonctionner jusqu’en 2028. Son opérateur est EDF. Le Boulonnais, et donc Boulogne-sur-Mer sont en plein sous le vent de Dungeness, tout  comme la Manche (problème éventuel pour la pêche). Il serait souhaitable que l’étude  d’impact, liée à ces réacteurs, soit communiquée aux autorité boulonnaises  Au cours de ma carrière, il m’a été donné de visiter plusieurs types de centrales en construction (les PWR françaises, comme les 6 unités de Dunkerque, la centrale Général Electrique espagnole Filière BWR pour Boiling Water Reactor , la centrale Tchèque dernière filière russe) ainsi qu’en fonctionnement (bien sûr les PWR françaises, la Candu canadienne, l’Atomic anglaise de Dungeness). Il est certain que la filière PWR française est celle qui présente le degré de sécurité maximum. L’accident de Three Mile Island (TMI) en1979, est liée à de grossières erreurs de l’opérateur chargé du fonctionnement. De type PWR, elle n’a donné lieu à aucun rejet, ni aucun décès lié à la centrale. L’accident de Fukushima (2011) a pour origine un raz de marée exceptionnel qui a déferlé sur les centrales GE de type BWR, filière qui n’a pas les dispositifs de sécurité du PWR, et ce raz de marée a causé la mort de   20 000 personnes dont on ne parle guère.  Enfin l’accident de Tchernobyl (1986) est lié également à une erreur de conduite, l’opérateur ayant shunté les sécurités. Elle ne possédait pas d’enceinte de protection et c’est la combustion du graphite qui ralentissait les neutrons qui est responsable de la forte pollution qui en a résulté.( Les trois réacteurs nucléaires de Chinon, filière Graphite-gaz ont été arrêtés en 1973, 1985 et 1990 et leur démantèlement est bien avancé)  Le problème Feissenheim En France c’est l’Autorité de Sécurité Nucléaire qui au nom de l’état assure le contrôle de la  sureté nucléaire, délivre les autorisations de fonctionnement, dont bien sur leur renouvellement chaque décennie.  En cas de fermeture de Feissenheim imposée par le gouvernement, alors que l’autorisation décennale de fonctionner pour ses deux réacteurs vient d’être renouvelée par l’Autorité  de Sécurité Nucléaire, EDF subirait un préjudice indiscutable  (dixit le président  d’EDF). Le montant du préjudice, estimé en 2016 à 4miliards d’Euro par les députés Mariton et Goua, devra être déterminé avant toute décision finale de fermeture. L’état actionnaire à 85 % d’EDF, se trouve  alors dans une position inhabituelle, car il devra défendre en l’occurrence une position minimaliste, d’autant plus qu’elle servira à coup sûr de référence pour les autres fermetures. Les milliards s’additionneront.  Le passage à un pourcentage de nucléaire de 50 % dans le mix électrique, la production étant supposée constante, impliquerait la fermeture de  28 réacteurs. A raison de  2 milliards de perte par réacteur, auxquels s’ajouteraient pour l’Etat principal actionnaire de trouver 2 milliards pour le démantèlement de chaque centrale, on arrive à un total de 112 milliards d’Euro. Quel montant a-t-il été provisionné dans le cadre du plan énergétique ? Aucun !  En cas de refus de versement de montants de cet ordre, les petits actionnaires d’EDF  fortement lésés ne manqueront pas de poursuivre l’Etat en justice. (L’arrêt hors raison technique touchant des centrales de plus en plus modernes, il est certain que les demandes d’indemnisations augmenteront fortement)   Flamanville Actuellement sur le site de Flamanville (Manche, en bordure de mer) se trouvent en service deux réacteurs de 1 300 MW de puissance. Un troisième réacteur y est en construction. C’est le prototype de la nouvelle filière dite EPR (European Pressurized Reactor) dont la construction a démarrée en 2007. Le démarrage du réacteur est actuellement prévu pour la fin 2019, pour un coût estimé à 10,9 milliards. Sa durée de vie est prévue pour 60 ans, avec une disponibilité de 90 % et une puissance de 1650 MW.  La contestation qui porte sur lui est son coût actuel qui est de l’ordre de trois fois son coût initial. Les personnes qui portent cette contestation n’ont sûrement jamais mené un projet industriel prototype, sinon ils connaîtraient le Règle dite du pi (du nom de la lettre grecque que l’on utilise entre-autres dans les calculs relatifs aux cercles : sa valeur est  3,14 ) . Cette appellation d’origine américaine est due à l’Amiral Ricover qui a été chargé de la  construction du premier sous-marin nucléaire. Il est considéré comme normal que le coût final d’un projet prototype soit pi fois le cout du cout estimé initialement. Nous pouvons donner un exemple récent très concret, hors secteur nucléaire : la réalisation de la nouvelle canopée du “trou” de Halles de Paris, œuvre de conception totalement nouvelle. La dérive de la durée de réalisation est elle aussi normale. Ce qui est anormal, inhabituel, c’est le respect des devis et délais initiaux.   La surgénération En 1960, le CEA Cadarache obtient l’autorisation de construction, sur son site, d’un petit réacteur nucléaire expérimental à neutrons rapides refroidi au sodium liquide Rapsodie qui est en service en 1967 (initialement d’une puissance de 24 MW thermique, il sera ensuite porté jusqu’à 40 MW thermique), arrêté  en 1983 il est aujourd’hui en phase de démantèlement. Les résultats  positifs : démonstration du principe de surgénération l’uranium soumis au flux de neutrons rapides donne du plutonium, produisant ainsi plus de combustible que celui  consommé, d’où le nom, ainsi que l’intérêt que le cœur radioactif est à la pression atmosphérique)  conduisent à la construction d’un réacteur de démonstration, producteur d’électricité Phénix  (sur le site de Marcoule), d’une puissance de 250 MW électrique mis en service en 1973 et arrêté en 2010.  Il s’en suit la décision de construction d’une centrale de 1200 MW, Super-Phénix, réacteur tête de série, Creys-Malville (Isère) dont les essais de mis en marche, à partir de 1996, rencontrent divers problèmes, dont ceux liés des fuites de sodium liquide (hautement inflammable à l’air). La forte contestation qui en résulte conduit en à son arrêt définitif en 1998, et à son démantèlement pour raison politique.  Son arrêt n’a pas été contesté par EDF, en raison d’un nouveau développement : le  combustible  MOX (mixte  Uranium-Plutonium) qui a fait que chaque réacteur classique  existant devient pour 20 % surgénérateur. Cette nouvelle technologie a doté  EDF  de  l’équivalent d’une dizaine de surgénérateurs immédiatement opérationnels.  La filière neutrons rapides à caloporteur sodium liquide n’est cependant pas abandonnée. Le projet d’un réacteur de 4ème génération, nommé ASTRID, de 600 MW, est développé par le CEA. Il devrait être mis en service en 2020. Des projets similaires sont en cours en Grande  Bretagne, Chine et aux Etats Unis, seul le projet allemand a été récemment abandonné, dans le cadre de l’abandon de la filière nucléaire en Allemagne, pour des raisons politiques.     Quand aux recherches sur la possibilité d’utiliser l’énergie de fusion (au lieu de celle de fission) utilisant l’Hydrogène et le Deutérium, elles se heurtent à de redoutables problèmes, dont l’un des plus ardu est la récupération de l’énergie au niveau des parois du réacteur. Actuellement, le délai envisagé pour résoudre ces problèmes est de l’ordre du demi-siècle.  Les développement des centrales nucléaires a eu de nombreuses retombées, imprévues pour  certaines, prévisibles pour les autres. Nous donnerons trois exemples : -le besoin de tubes en titane pour le refroidissement du circuit secondaire des centrales bords de mer, à conduit à des besoins en titane sans commune mesure avec les besoin précédents de ce métal, ce qui a conduit au développement d’une métallurgie française du titane, avec comme retombé imprévue la disponibilité en chirurgie de toutes sortes d’implants, la plus  connue étant celles utilisée pour les fractures du col du fémur, notamment pour les personnes âgées. -le développement des connaissance en matière de corrosion métallique, notamment saline, qui est à même de réduire les risques de rupture des grandes structures exposées de l’air et soumises à des vibrations, comme les éoliennes.  -L’élevage de crocodiles dans les eaux chaudes de Pierrelatte (Eurodif)  Les énergies renouvelables  Sont considérés comme énergies renouvelables opérationnelles : l’hydraulique, l’éolien, le solaire, l’énergie marémotrice et l’énergie lié à la combustion ou la fermentation de la  biomasse qui produit des gaz combustibles. Sont considérées comme énergies renouvelables non opérationnelles, même si elle ont par le passé donné lieu à des centrales expérimentales de grande taille : l’énergie thermique des mers (Centrale d’Abidjan), l’énergie des vagues (Station d’essais de Bayonne), l’énergie des courants marins, l’énergie de dialyse (mélange eau douce-eau salée).   Par contre l’énergie marémotrice a donné lieu à des centrales opérationnelles. En France      seule la centrale de la Rance, captant l’énergie des marées, est toujours en service, les projets à plus grande échelle : Baie du Mont Saint Michel, sont restés à l’état de projet. La seule centrale à l’étranger du même type est celle de l’ancienne Baie des Français, au Canada. .  Elles se divisent en deux grandes catégories :  - celles quasiment constantes comme l’hydraulique, ou celles dont la variation est parfaitement connue et prévisible comme la marémotrice. - celles très fluctuantes comme l’éolienne et  le solaire, même si les variations se superpose à un cycle bien connu (jour-nuit). La différence est fondamentale, car un réseau électrique doit assurer la sécurité  d’approvisionnement. Une production électrique non programmable, peut être couplée à un réseau électrique si celui-ci dispose de moyens de production pouvant effacer les   fluctuations, comme l’hydraulique de barrage. (Le stockage électrochimique de très forte capacité n’existant pas). Au delà d’une certaine proportion d’énergie fluctuante, l’hydraulique de barrages ne suffit plus, cela nécessite la construction de centrales de secours capables de réagir rapidement. La seule technologie, autre que l’hydraulique de barrage, capable aujourd’hui de répondre à ces conditions est la turbine à gaz. Les dernières turbines à gaz opérationnelles fabriquées en série ont une puissance de 100 MW.   Les problèmes spécifiques de l’éolien Les génératrices éoliennes sont les descendantes en ligne directe des anciens moulins à vent. Ce qu’on a oublié, c’est que la durée de vie des moulins étaient de l’ordre de 20 ans, car il  arrivait invariablement au cours de cette durée une tempête assez forte pour mettre  complétement par terre le moulin s’il était en bois, ou ses ailes et sa machinerie s’il s’agissait  d’un moulin à tour de pierre.  C’est encore le cas aujourd’hui : si nous prenons un pays doté d’un grand nombre d’éoliennes modernes, et qui s’en est doté déjà depuis plusieurs décennies comme le Danemark, à partir de l’analyse du nombre de chutes, on obtient une durée moyenne de vie de l’ordre de 20 ans.  En Boulonnais, deux éoliennes récentes ont été mises à bas (Widehen et la Digue Carnot) sans que ce soit par une tempête exceptionnelle comme une tempête référencée centenaire. (Lors de sa construction Widehen était la plus puissante éolienne d’Europe)   Les éoliennes actuelles à mat métallique sont inévitablement soumises à la corrosion  fissurante liée aux vibrations permanentes créées par le passage de chaque palme devant  le mat support. Cette corrosion est particulièrement rapide au niveau des soudures ( ZAC  ou Zone Affectée Thermiquement) si le plus grand soin n’a pas été pris, avec recuit des zones où se trouvent une soudure. Un autre phénomène accélère très fortement de type de  corrosion pour toutes les structures métalliques à base de fer : la présence de traces de sel marin !  (Chlorure de Sodium : bienvenu aux éoliennes de bord de mer ou de pleine mer !). Vibrations et présence de traces de sels rendent ce type de corrosion fissurante extrêmement rapide et donc très dangereuse. La  présence des traces de sel présentent dans l’eau de pluie jusqu’à une centaine de km de la mer ou de l’océan est suffisante, ainsi que la manipulation à mains nues  lorsque du montage des éolienne, en raison du sel de notre sueur.  Qu’elles précautions ont été prises lors de la fabrication et du montage ? J’ai questionné plusieurs  maires des communes où ont été installées des éoliennes, aucun n’avait jamais  entendu parler de cela, et n’en savaient donc rien ! Il est par ailleurs un autre point particulièrement sensible : celui des pattes de fixation. D’abord  les pattes ont été soudée sur la base du pylone : quelles conditions ont été prises pour éliminer la ZAC, ensuite la fixation au socle de béton armé se fait classiquement avec  de grosses  tiges métallique filetées, prises  dans le ciment du socle, avec ensuite rondelles, rondelle arrêtoir et boulon. Tous ces matériaux doivent tous être strictement de même nature  (composition,  traitements thermique) sinon en sus de la corrosion fissurante vient s’ajouter  une corrosion électrochimique d’autant plus forte en  présence d‘eau surtout si cette eau comporte des traces de sel. (Les éoliennes de la Digue Carnot de Boulogne citées plus  haut) sont dans un milieu particulièrement hostile, tout comme les éoliennes en mer) Une peinture de bonne qualité ne  retardera que très peu de temps ce type de corrosion et la moindre fissure au niveau de celle ci ne fera que l’augmenter.     Les questions que j’ai posé en cette matière, du fait de connaissances liées aux études de  corrosion pour les centrales nucléaires, n’ont  jamais reçu de réponses. Les expertises après   accident, comme ceux de Widehen et de la Digue Carnot, ne sont pas accessibles. A mon avis il y  à 9 chances sur 10, que toutes ces précautions n’ont jamais été prises. Comment obtenir  ces rapports ?    Il est nécessaire de connaître qu’elle est la tempête de référence prise pour le calcul de la tenue du mat support. A minimum il faut que ce soit la référence tempête centenaire qui soit prise, sinon vu l’augmentation constatée actuellement de la force des tempêtes on va vers un désastre. Une série de tempêtes comme celles de la fin du dernier siècle, serait en effet  susceptible de mettre par terre une bonne partie du parc éolien français Dans ce cas, étant donné que la remise en état des centrales nucléaires récemment arrêtées  prendrait beaucoup de temps, imagine-t-on le pays privée pour une durée notable de 25 à 30% de son électricité ?   Il faut donc en ce domaine imposer : la prise en compte pour le dimensionnement de la tempête locale centenaire,  définir des règles de fabrication et d’installation très strictes ainsi que de se doter des moyens de suivre leurs dimensionnement, fabrication, installation, et entretien. Ce  qui conduit à la création d’une agence similaire à celle de Sûreté Nucléaire.          Quel nombre d‘éoliennes faudra–t-il pour remplacer les 28 réacteurs nucléaires que l’on envisage de fermer ?  ( Ce chiffre de 28 réacteurs est depuis toujours très fluctuant. Dans la dernière déclaration officielle faite par le Président de la République en novembre 2018, l’objectif  est la  fermeture de 14 réacteurs d’ici 2028. Cette fermeture serait  accompagnée d’une aide de 71 Milliards d’Euro pour le développement des énergies renouvelables. L’objectif de fermeture   de 28 réacteurs correspond à 2035. )    Le taux de fonctionnement des réacteurs nucléaire compte-tenu de leurs arrêts pour entretien, et révision est de 60 %  Considérons les chiffres disponibles pour 2017, l’année qui a vu le plus grand nombre d’éoliennes installées en France. La Puissance totale installée en France à la fin de  2017 s’élevait à 14 275 MW  (source  Le journal de l’Eolien), et l’Energie produite  à 24 TWh. (même source) Avec ces deux données il est facile de calculer X  le taux de fonctionnement du parc éolien français.     (calcul ci-dessous, rappelons l’échelle des puissances: KW, MW, GW, TW)  	24 000 000 MWh = 14 275 MW x 365 x 24 x X. = 125 049 000 . X  MWh  ce qui donne : 24 TWh=  125 . X			X = 0,192   Le taux de disponibilité de l’éolien est donc particulièrement bas, et dans toutes les publications, journaux on évite d’en parler. On y trouve cependant le chiffre moyen de puissance des éoliennes françaises : 2,3 MW, ce qui conduit à un nombre d’éoliennes installée à la fin de 2017 : 			14 275  divisé par 2,3  égale 6 200 éoliennes.  La construction du parc éolien ayant commencé en 2000, le nombre moyen d’éoliennes (de puissance 2,3 MW) installées à par an s’élève à 6200 / 17 = 365.  Quel nombre d‘éoliennes faudra–t-il pour remplacer les 28 réacteurs nucléaires que l’on envisage de fermer ? Le taux de fonctionnement des réacteurs nucléaire est nous l’avons vu de  60 %,  il faudra donc installer :  			28 x 930 x 0,6 = P x 0,19   			15 624/ 0,19 = 82 232 MW D’où : 35 752 éoliennes nécessaires. Au rythme moyen de construction depuis le début de la construction du parc : 98 ans !     Si nous prenons le rythme d’augmentation de puissance des dernières années :  2016-2017   1798 MW		L’augmentation du rythme	1798/ 1617 = 1,25 2015-2016   1617 MW			 2014-2015   1415 MW		 2013-2014   1350 MW		  (Rappelons que la puissance totale installée fin 2017 était : 14 275 MW)  Si nous considérons une accélération permanente du rythme d‘augmentation constaté lors des deux dernières années (progression exponentielle): 1,25, il faudra 18 ans pour arriver aux 82 232 MW nécessaires, d’où 2036.  L’objectif  50 % de nucléaire vient en septembre  2018, d’être repoussé par le  gouvernement de 2025 à 2035.  Les conseillers scientifiques du gouvernement semblent avoir fait le même calcul que  celui présenté ci-dessus. Mais le taux d’augmentation de 1,25 / an sera-t-il obtenu sur une telle durée ?    Nous attendrons avec impatience la publication des chiffres pour  2018, nous verrons s’ils  atteignent : 2247 MW.  Seul est actuellement connu le chiffre du premier  semestre 2018 : puissance totale installée : 14 367 MW, soit une très faible  augmentation de 92 MW !   A noter de plus, qu’en  2035, les éoliennes installées en 2015 et avant seront arrivées à leur fin de vie ( 20 ans), 10 869 MW supplémentaires seront donc à installer, non comptabilisées dans ce qui suit (4720 éoliennes).    La partie de l’hydraulique qui est susceptible d’être en secours des éoliennes en cas d’arrêt total de celles ci est de l’ordre de 4700 MW, ce qui correspond à 2000 éoliennes.( 12 000 MW en pointe, pendant seulement quelques heures ) Or il est une règle chez toutes les compagnies d’électricité ayant un réseau de distribution important : aucune centrale ne doit fournir plus de 10% de la puissance totale, car en cas d’arrêt brutale de cette centrale le réseau devenu instable s’écroule.  Une tempête de type centenaire survenant par exemple sur une région fortement équipée  en éolienne conduira à l’écroulement du réseau à moins que des unités de secours soient  disponibles  et pouvant être mise en marche très rapidement (délais s’exprimant en heures ). L’hydraulique ne pouvant le faire que jusqu’à 2000 éoliennes mises au sol,  seul un  équipement  de turbines à gaz est à même de répondre au problème. Or si l’on arrive aux      40 000 éoliennes nécessaires pour le projet envisagé, environ 10 000 seraient en Haut de  France ! D’où la double nécessité d’ordonner que respecter les règles de conception et de construction ci-dessus, et de se doter d’un parc de plus d’une centaine de turbines à gaz de 100 MW.  (10 000 - 4 700). 2,3 / 100 = 122).qui viendront grever le coût de production de l’électricité éolienne. (Les coûts à disposition du public de telles installations sont très rares.  Nous donnerons celle de la centrale EDF de Pointe Jarry en Guadeloupe : 2 turbines à gaz  de  100 MW, pour un coût 500 M D’Euro, en 2010.  La construction des 122 centrales à gaz de  secours nécessiterait donc un investissement de l’ordre de 60 Milliards d’Euro).  Les conséquences pour les centrales nucléaires de l’écroulement d réseau électrique.  L’écroulement du réseau électrique du fait par exemple d’une très forte tempête induisant    une perte  supérieur à 10 % de  la puissance connectée au réseau risque conduirait les  réacteurs nucléaires alimentant  alors le réseau, à passer au régime îlotage. Coup du réseau  électrique les réacteurs à passer alors à faible régime, afin de continuer à produire l’énergie  électrique nécessaire à son fonctionnement. L’échec de l’îlotage conduit à un arrêt automatique du réacteur et un basculement sur les groupes électrogènes de secours, qui assurent la sécurité du réacteur.  Le  redémarrage des réacteurs ayant  raté  leur îlotage, une fois  réaccordés au réseau ne pourra  se faire  que très lentement  en raison de l’effet xénon. Le  test îlotage a lieu pour chaque centrale tous les quatre ans. Il serait intéressant  de  connaître la proportion d’îlotage réussi.              Les changements de régime des réacteurs nucléaires doivent se faire très progressivement  Le passage  brutal à un faible régime peut conduire à l’étouffement du réacteur par le xénon 135 produit en fonctionnement normal, ce radio élément étant particulièrement neutrophage. On parle alors de “pic xénon”. La période  du Xénon 135 est de 9 heures. Lors d’un redémarrage au moment du “pic xénon”, la disparition du xénon par interaction avec le flux neutronique provoque un apport de réactivité  important, d’autant plus rapide que  la puissance est grande et que la quantité de xénon restante est importante. La remontée en puissance du réacteur doit être de ce fait suffisamment lente.    L’élimination du xénon 136,  par décomposition radio active à une teneur suffisamment  faible pour ne poser aucun problème : 1/100  nécessite  60 heures, soit près de 3 jours.    L’arrêt brutal d’un réacteur au cas où le réseau électrique s’est écroulé, du fait par exemple  d’une très forte tempête mettant à bas une part notable des éoliennes, induisant une perte supérieure à 10% de la puissance connectée au réseau, risque donc d’entrainer l’arrêt des  réacteurs ayant raté leur ilotage, pour des périodes de l’ordre de 3 jours, le retour à une production normale excédant la semaine. Image-t-on le pays privé d’électricité jusqu’à une semaine ? Il importe qu’un plan d’intervention soit dressé pour prévoir les interventions en pareil cas, à la fois des organismes publics et des particuliers. Et que ce plan soit rappelé chaque fois qu’une forte tempête est annoncée.  Il serait intéressant d’examiner les possibilités des interconnections France-Angleterre (Les sous-marines  IFA 2000 de capacité 200 MW, IFA 2 de  1GW, et l’interconnection qui transite par le tunnel sous la Manche : Eleclink 1 GW ). Si elles permettent  actuellement l’exportation d’électricité vers l’Angleterre, peuvent elles faire l’inverse. C’est à vérifier.  A noter que les 16  centrales nucléaires britanniques en service sont exploitées par EDF Energy, et quelles fournissent 16 %  de l’électricité britannique.  Pour ne pas surcharger ce mémoire nous ne parlerons pas des inévitables harmoniques, qu’il est impératif d’éliminer pour éviter des surtensions au niveau du réseau.      Le financement et le cout de l’électricité.  Le dernier coût des éoliennes que l’on trouve dans les documentations disponibles et sur internet est de 2,4 Millions d’Euro par MW installé, et 1,5 Millions pour les fermes  éoliennes. A coup sûr ne sont pas pris en compte : le coût des dossiers pour obtenir les  autorisations, le coût du terrain, celui lié aux recours en justice, et certainement le raccordement au réseau électrique, ainsi que le renforcement du réseau électrique local pour les fermes éoliennes. A mon avis cela conduit à 2 Millions d’Euros par MW pour les fermes et  2,8 à 3 millions pour les éoliennes seules. La fabrication est série étant déjà bien établie, il n’y a pas à attendre de diminution notable du coût d’autant plus que les matériaux spéciaux pour la fabrication des génératrices sont fortement susceptibles d’augmenter dans les années  à venir.  Les 82 232 MW nécessaires évoquées ci-dessus, ne seraient réalisables que par la multiplication des fermes, ce qui nous conduit à prendre la valeur de 2 M/MW. D’où un financement global de : 160 Milliards, auxquels il faut ajouter les 60 Milliards pour la sécurité de l’approvisionnement et la stabilité du réseau de distribution. Nous arrivons  ainsi à un besoin pour le financement du programme de construction envisagé de 220 Milliards auxquels il faut ajouter le dédommagement pour arrêt d’installations opérationnelles et leur démantèlement établis ci-dessus, soit : 112 Milliards, d’où un total de 332 Milliards !  (soit 4 700 Euros par Français) Tout cela pour se priver de centrales opérationnelles.    La dernière déclaration officielle, de novembre  2018 du Président Macron relative à l’objectif de fermeture de 14 réacteurs  nucléaires pour 2025, prévoit une aide au développement des énergies nouvelles de 71 Milliards d’Euro, d’ici 2025, soit sur 7 ans. En gardant le même montant moyen annuel, nous  arrivons pour 2035 à : 172 milliards, c’est à dire moitié moins que nécessaire. Où trouver les 160 milliards manquants ?    La taxe portant sur le courant délivré  par EDF à tous les foyers, appelée CSPE  (Contribution au Service  Public  d’Electricité ) a été introduite en 2003 par l’Etat dans le but  de financer le rachat à un prix élevé des énergies renouvelables, et par là contribuer notablement à leur financement. C’est la taxe introduite dans la tarification de l’électricité qui a le plus augmentée : 550% en 13 ans Elle peut actuellement atteindre 7% du coût de l’électricité effectivement  payée. (Le gouvernement à trop tendance à considérer EDF comme une vache à lait que l’on peut traire comme l’on veut, ou que l’on peut surcharger à volonté, mais L’Etat n’est plus le seul actionnaire d‘EDF, d’où des difficultés à venir)  Le  25 juillet 2018, la Cour de justice de l’Union Européenne a rendu un arrêt ouvrant la voie  au remboursement de la  CSPE,  jugeant que le tarif d’achat d’électricité d’origine verte, financée grâce à la  CSPE, est “une imposition indirecte frappant l’électricité”. Dès lors les consommateurs peuvent faire valoir leur droit à un remboursement partiel qui sera toutefois plafonné : le  Conseil d’Etat, a le 3 décembre  2018, accorde un remboursement plafonné  à   7,42 % , pour les seuls  requérents ayant fait la demande  dans les délais impartis.  Le développement des énergies nouvelles, ne pourra pas être indéfiniment lié à un supplément de taxes, les besoins de financement étant en progression exponentielle comme nous venons de l’expliquer ci-dessus. Les autres sources d’aide au financement : Europe, Gouvernement, Régions, Communautés urbaines… conduiront (et se conduisent  déjà) par une augmentation des impôts liés à ces structures.   Il est inéluctable d‘aller vers la réalité des coûts.  Le cout moyen de production d’origine nucléaire varie selon les centrales entre 60 et 110 Euros/ MWh, suivant leur amortissement. Le cout moyen réel du KWh éolien, incorporant la réelle valeur d’amortissement, varie de  150 à 200  Euros / MWh,  300 et plus pour les éoliennes en mer.   Compte tenu que le photovoltaïque solaire est dans les mêmes conditions de financement  de l’ordre de 300 Euro/MWh.  Et comme la durée de vie moyenne estimée d’une éolienne de 20 ans, est à comparer aux 60 ans des centrales nucléaires, si le programme de réduction à 50% de l’électricité d’origine nucléaire des centrales déjà amorties financièrement pour  une bonne partie et qui le seront alors toutes.  On ira à minima vers un triplement du coût de l’électricité produite en France.   Les problèmes spécifiques du  photovoltaïque  Si l’idée de captation de l’énergie solaire pour les habitations remonte à la nuit des temps, sa concentration a été réalisé pour la première fois à des fins militaires : Archimède au siège de  Syracuse (213 avant J.C.)  En France, les anciennes expériences les plus célèbres sont celles de Lavoisier : fusion de l’or, combustion de diamants. Immédiatement après la fin de la dernière Guerre, le Professeur Trombe à Mont-Louis, (Pyrénées Orientales)  utilisant d’abord du matériel de guerre de récupération, a construit à partir de 1947 des fours solaire de plus en plus puissants, permettant la fusion des matériaux  les plus réfractaires.  Ils furent suivis de la construction du four solaire d’Odeillo (Font Romeu, Pyrénées Orientales) alors le plus grand du monde, et toujours existant car classé Monument  Historique. Mis en service en 1970, ses héliostats couvrent une surface de 2600 m2 ( 54 m par 48 m) ce qui permet d’obtenir une puissance thermique de 1 MW. Ces développements ont conduit EDF à construire la centrale solaire dite thermodynamique à tour Thémis d’une puissance de 2MW électriques. Elle comportait un champ de 200 héliostats qui suivaient le mouvement solaire, renvoyaient le rayonnement solaire sur un four situé au sommet d’une tour, pour  y porter à haute température un mélange de sels fondus (dit  HTS. Heat Tansfer Salt : nitrate de sodium, nitrate de potassium, nitrite de sodium), qui produisaient via un échangeur thermique la vapeur alimentant une turbine électrique. Mise en service en 1983, elle fut arrêtée en 1986, ses installations furent ensuite transformées en radio-télescope.   Quant à la découverte de l’effet photovoltaïque, elle est due à Edmond  Becquerel, en 1838. (Il s’agit du père d’Henri Becquerel découvreur de la  radio-activité.)  Les péripéties de Photowatt  La filière dite thermodynamique solaire de Themis, n’eut pas de suite en raison du développement de la filière photovoltaïque, développement auquel contribua également  EDF. Crée il y a maintenant 40 ans, Photowatt ne put se développer que grâce à un soutient constant d’EDF. Le créneau technologique basé sur le silicium sur lequel s‘est placé dès l’origine Photowatt est toujours celui actuellement utilisé industriellement pour la production électrique à partir du solaire.(Le soutien d’EDF m’a permis de visiter en détail l’usine Photowatt de Bourgoin-Jallieu à plusieurs reprises, de rencontrer ses dirigeants et de discuter de certains  problèmes dont la fabrication du silicium : monocristallin ou polycristallin )  Bien que produisant d’excellents produits la société Photowatt, a subi de multiples aléas : vente en 1997 de la société par son directeur à la société canadienne Automatic Tooling Systems, qui opère alors un transfert de technologie vers son usine en Ontario.  Pour éviter la disparition de Photowatt, EDF ENR et le CEA créent un regroupement de recherche en 2008 (maintien de l’emploi du tiers des salariés). Malgré cela la société est mise en redressement judiciaire en 2011 (suppression de 119 emplois). L’année suivante, Photowatt est reprise sur ordre du Président Sarkosy par EDF Energies Nouvelles. Les pertes de temps liées à toutes ces péripéties, ont permis le développement d’une technologie copie, par les Chinois, qui très rapidement sont devenus les leaders de cette technologie. En 2018, pour assurer une nouvelle fois sa survie Photowatt s’associe au sino-canadien Canadian Solar. Le développement  du photovoltaïque solaire est désormais totalement entre les mains des Chinois.  (Photowatt est considéré maintenant comme l’un des exemples type de gâchis industriel)  Estimation des couts d’installation et de production  Les panneaux solaires industriellement disponibles sont d’une puissance de 300 Wcrête, C’est à dire la puissance maximum à atteindre dans les conditions idéales suivantes :   	Ensoleillement   	1000 W /m2  	Température  		25°C (perte de 0,5 % par degré supplémentaire  	Orientation au sud, avec une inclinaison de  30 °. L’inclinaison change bien sûr avec la  latitude. Pour utiliser des toits plats, il faut mieux être à l’équateur Les salissures non régulièrement enlevées conduisent à des pertes de 2 à 7%.   Les valeurs de coùt (matériel + pose) intégré au bâti existant varient de 9 000 à 12 000 Euros  par  KWc installé. (information internet).  Le cout des panneaux standards nus tels que portés sur le catalogues de vente accessibles (internet) : 	3900 Euro  pour  3000 W  		D’où 1,3 Euro par W.	( 1300 /KW) 	3890 pour 26 panneaux de  300 W 	D’où 0,5 Euro par W.	 (500/KW), Le coût des panneaux dans une installation photovoltaïque ne représente donc que de 5,6% à 10,8%. C’est à dire que l’évolution du cout de fabrication et de vente des panneaux solaires ne  conduira pas à une diminution substance du prix de revient de l’électricité produite.  Cela me rappelle une discussion tenue il y a une trentaine d’année avec mes collègues ingénieurs chargés du photovoltaïque, sur les baisses de cout à attendre de l’électricité photovoltaïque. Pour évaluer celui ci il a été décidé de considérer que les éléments de silicium photovoltaïque disponibles alors (et dont le rendement ne s’est que peu amélioré depuis) ne coutaient rien ! En simplifiant au maximum les structures supports, en allant même prendre comme terrain des flancs de collines, avec les possibilités financières habituelles et une durée de vie de l’installation de 20 ans nous étions arrivé (via une estimation confiée à un bureau d’ingénièrie) à un coût d’installation tout compris  (y compris le raccordement au réseau) donnant un KWh photovoltaïque égal à 4 fois celui du KWh standard de l’époque. (Ce  rapport doit toujours exister dans les archives EEF DER)  Les couts relatifs aux grandes installations seront très voisins de ceux des installations sur les  toits des particuliers, en raison des couts supplémentaires qu’elles nécessitent : achat de terrain, structures supports plus importantes, raccordement au réseau, renforcement du réseau local. Relativement au rendement,  “Quelle Energie”, accessible sur internet, donne comme exemple de production annuelle : 1 300 KWh/KWc ce qui correspond à un rendement de 15%. Nous avons vu que le rendement des éoliennes est de l’ordre de 19  %, mais aussi bien la nuit  que le jour. Il est donc plus intéressant pour un réseau électrique d‘être alimenté par des  éoliennes. Le renforcement du réseau local sera moindre.  Enfin, les panneaux installés sur les toits, et les grandes centrales sur leurs supports, auront une importante prise au vent du fait de leur orientation plein sud. Lors des tempêtes le vent dominant venant généralement de l’Ouest s’infiltrera entre les panneaux et les toitures, provoquant l’arrachement des panneaux et endommageant les toitures, avec le risque d’accidents humains. Comme pour l’éolien la création d’un organisme de contrôle  indépendant vérifiant la réalisation des installations me paraît nécessaire. Le seul facteur  positif est l’absente de vibrations permanentes. Comme pour l’éolien, un développement important du photovoltaïque nécessiterait  la  construction de centrales électrique de secours à démarrage rapide, donc à base de turbines à gaz, comme expliqué plus haut.    L’empreinte carbone du photovoltaïque n’est pas nulle car deux de ses composants : le  silicium et l’aluminium conduisent à l’émission importante de  CO2 lors de leur fabrication.   Prenant conscience peu à peu du faible intérêt pour le réseau national de l’électricité photovoltaïque le gouvernement a fortement diminué les tarifs de rachat obligatoires par EDF et les autres compagnies d’électricité françaises. De 2011 à 2015, le tarif d’achat a été divisé par 4,6 passant de 0,60 Euro/KWh à 0,13 Euro/ KWh. Cette baisse des prix a bien évidemment provoqué une chute importante des créations d’installation. Cette même baisse a été bien plus importante en Espagne, pays ensoleillé par excellence, mais où l’on parle de désastre : champs couverts de panneaux non rentables, arbres arrachés en masse, familles endettées… (Les cellules photovoltaïques demeurent économiquement intéressantes, pour de petites installations non connectées à une réseau électrique, tels de téléphones au bord des  autoroutes, panneaux indicateurs annonçant l’arrivée des bus en ville,… )    L’hydraulique, l’essentiel actuel  de l’énergie verte  Historique  A l’époque de la Révolution et de l’Empire, existent en France environ 20 000 moulins, dont  plus des trois quarts sont hydrauliques. Les moulins à vent sont alors utilisés essentiellement en secours, soit en cas de sécheresse ou de grands gels. Les deux inventaires détaillés de la  Révolution, toujours accessibles aux Archives Nationales, précisent leur capacité de production, dont la principale est la production de farine.  Environ 10 000 chutes possèdent encore actuellement une part de leur équipement d’alors : canal d’amenée, radier, barrage…  ce qui les rend susceptibles d’être remis en service relativement facilement.  Au cours du XIXème siècle, les moulins à vapeur prirent le pas sur les moulins hydrauliques, sans que ceux ci soient arrêtés, et que le rendement d’utilisation de l’énergie hydraulique disponible de leurs installations augmente très fortement suite à l’invention de la turbine Fourneyron en 1832. Le renouveau de l’utilisation de l’énergie hydraulique qui suivie est du à Aristide Bergés qui installe en 1869, en Ariège, une conduite forcée conduisant l’eau sous pression à une turbine. (l’appellation “Houille  Blanche ” apparaît en 1878). Bergés perfectionne son installation en 1882 en la dotant d’une dynamo Gramme. L’hydro-électricité vient de naître.  Elle se développe alors rapidement dans les Pyrénées pour l’alimentation électrique du réseau ferré du Sud-Ouest. La guerre 14-18, (au cours de laquelle la France se voit privée de l’essentiel de sa production de charbon), accentue très fort son développement pour les besoins de la production du nitrate nécessaire aux munitions. Au cours de cette période, les banques françaises contribuent fortement à la création de la célèbre Société  Norsk-Hydro, déjà évoquée précédemment.  A la sortie de la seconde guerre mondiale, l’hydroélectricté française connaît son âge d‘or. De 1945 à 1960, 120 barrages sont construits, suivis par l‘aménagement du Rhin déjà initié avant-guerre (Kembs 1932) et du Rhône (Génissiat 1948, Donzère-Mondragon 1952, SerrePonçon 1960). Ces installations sont toujours la base de la production hydraulique française.     Disponibilité hydraulique actuelle  La puissance actuelle des équipements hydrauliques français est de 25 GW, soit  25 % de la puissance de l’ensemble des centrales électriques fournissant de l’énergie au réseau national français. Le  KWh  hydraulique est le moins cher des KWh  produits aujourd’hui, les   barrages ayant leurs couts totalement amortis Un des intérêts majeurs du parc hydroélectrique est de disposer d’une puissance de pointe de  12 000 MW mobilisable en quelques minutes, ce qui permet d’assurer la stabilité du réseau national. (Cette puissance couvre actuellement les risques liés à l’éolien, qui a actuellement une puissance totale installée de 14 275 MW, tel que détaillé ci-dessus) L’énergie fournie 67 TWh représente 14% de l’énergie électrique produite. En 2014, 80 % des barrages français étaient exploités par EDF. Ils assurent 13 % de l’énergie électrique nationale.  Les Hauts de France est la plus faiblement équipée des régions françaises.  Le petit hydraulique  Pour les petites installations de moins de 20 KW de puissance, on parle de pico-centrales.  Pour les particuliers une pico-centrale peut suffire à couvrir l’intégralité des besoins d’une  habitation en électricité, chauffage compris.  Pour réaliser l’une de ces pico-centrales il faut demander un permis de construire, ainsi que d’une autorisation de travaux auprès de la Direction Départementale du Territoire. Le dossier   doit comprendre une évaluation de l’impact environnemental de la centrale sur la vie aquatique du site.   A l’heure actuelle de moins en moins d’autorisations sont délivrées avec pour principale raison d’opposition la continuité écologique des cours d‘eau, c’est à dire la libre circulation  des poissons, et des sédiments. C’est ce que nous avons pu constater nous-même lors d’une réunion avec l’Agence de Bassin de  Rouen. Nous y avons rappelé qu’il y avait infiniment plus de poissons dans les rivières à l’époque où les 15 000 moulins étaient en service que maintenant (En 1900, Le Journal de Montreuil adresse ses félicitations à un chasseur de loutres qui vient d’en abattre la centième sur la Canche ! ) Pour les poissons qui sont censés devoir être protégé pour remonter les cours d’eau, dans les régions du Nord de la France, via  de couteuses échelles (ou passes) à poissons nous avons essentiellement les anguilles (il n’y a pas eu d’esturgeons signalés dans les petits cours d‘eau nordiques depuis un siècle). Or les anguilles sont capables d’escalader les murs des chutes comme de nombreuses études récentes le démontrent, où de les contourner par voie de terre, en rampant comme les serpents.   Ré-équipement des anciennes chutes  Côté économique, si le site dispose déjà d’infrastructures, et que seul le générateur reste à poser, l’installation est alors facile à amortir. C’est le cas d’environ la moitié des anciennes  installations  (les anciens construisaient très solide !). Des constructeurs comme Turbiwatt propose  une gamme de turbines  hydroélectriques de  basse chute déjà fabriquées en petites séries  ( 0,6 à 0,8 KW ; 3à 12 KW ; 6 à 60 KW ; 24 à 130 KW ), prêtes à être posées avec un minimum de travaux. La puissance électrique que l’une est susceptible de fournir s’exprime par la formule :  			P (KW) = Q (m3/s)  x H (m) x g x R 			( (H hauteur de  la  chute, g : constante de Newton, R rendement ) Si nous considérons les deux chiffres ci-dessus : 20 KW et 10 000 sites ré-aménageables, nous aboutissons à un gisement potentiel de 200 MW, soit équivalent à 1 GW d’éoliennes installées (équivalent de 435 éoliennes d’une puissance de  2,3 MW), tout en étant insensible aux risques liés aux fortes tempêtes.  Il est un chiffre important de rappeler : l’eau et 1000 fois plus dense que l’air, les installations  sont donc environs 1000 fois plus petites, donc l’impact écologique avancé contre les pico-centrales ne tient pas. Alors que des bâtons sont mis dans les roues, systématiquement aujourd’hui, allant même jusqu’à vouloir fermer les installations encore existantes, il faut changer de politique, en mettent en avant tout l’intérêt du ré-équipement, y compris pour le développement de la pisciculture.  Par exemple, en Boulonnais, une dizaine des anciennes chutes sur la seule rivière Liane devraient pouvoir être ré-équipées. En conséquence,  je propose que soient prises les deux décisions suivantes : 1. L’Agence de  bassin concernée ne peut s’opposer à la remise en état des installations hydrauliques en service jusqu’à la fin de la dernière guerre mondiale. 2. Si l’Agence de  bassin juge qu’une passe à poisons est  nécessaire, elle en assure elle-même le financement, et sa construction ne peut retarder la remise en service de l’installation.  Le cout    Les offres de prix que l’on trouve sur le net pour les installations clés en main vont de 400 Euro/KW pour 100 KW de puissance, à 6000 Euro/KW pour les installations de l’ordre du KW. La turbine avec sa génératrice électrique comptant pour environ 40 % du cout. Une fabrication en grande série est susceptible de faire baisser notablement cette valeur, probablement de moitié, ainsi que le fait de passer à une réglementation plus réaliste. (A comparer aux 2 400 Euro par KW pour les éoliennes standards actuelles unitaires de  puissance  2,4 MW)   Conclusion  S’il est certain que nous sommes actuellement dans une phase géologique de réchauffement  climatique, son accélération du fait des activités humaines n’est qu’imparfaitement connue. Actuellement l’augmentation de la teneur en CO2 de l’atmosphère est mise en avant comme principale cause de ce réchauffement, mais de nombreux phénomènes sont encore très mal connus, tels par exemple les courants sous-marins de grand fond. Pour avoir une meilleure compréhension de l’ensemble de nombreux types d‘études sont à développer et à initier. Les extrapolations fin du siècle actuel, basées sur des modèles mathématiques sont à prendre avec précautions.  L’une des causes principales de l’émission de CO2 et de son rejet à l’atmosphère est liée à l’automobile en raison de l’utilisation quasi exclusive du moteur à explosion. Les solutions actuelles mises en branle dont le changement de carburant et les véhicules hybrides ne sont pas à la hauteur du problème posé. Les problèmes liés aux camions ne sont jamais évoqués. Comme le véhicule électrique est une impasse technologique qu’il soit à batteries ou à pile à combustible, la seule voie techniquement envisageable est celle qui passant par une amélioration très importante du rendement des moteurs à essence pour les voitures individuelles comme pour les camions, similaire à la forte augmentation réalisée ces dernières décennies en aviation avec le passage du moteur à explosion au moteur à turbine. Elle est possible pour l’automobile à condition d’y mettre les moyens de développement, consacré actuellement et inutilement au véhicule électrique. ( De l’ordre de 50 milliards rien que pour la France : Etat, Régions, Villes… et constructeurs automobiles) En matière du C02 lié à la production électrique, la France est dans une position exceptionnelle bonne, en raison de son approvisionnement à base de nucléaire et d’hydraulique. La réduction (dogmatique et illogique) du parc nucléaire existant et amorti, visant à remplacer 28 centrales par des éoliennes est à la fois dangereuse et ruineuse.  Dangereuse car en l’absence d’un organisme officiel, semblable à celui contrôlant le nucléaire, chargé de vérifier la bonne  conformité de conception, de construction et d’entretien des éoliennes, des tempêtes de type centenaire comme celles qui ont ravagées la France à la fin du siècle dernier sont à même de mettre à bas une bonne part des éoliennes qui existeraient alors, conduisant à des instabilités du réseau électrique pendant de longues durées. Pour le second point, le cout d’un tel programme, jamais mis en avant, est pharaonique, se chiffrant à plus de 300 milliards d’Euro sans aucune programmation.  Le cout actuel de l’électricité délivrée au consommateur lambda serait environ multiplié par trois. Ce point n’est jamais spécifié lors des sondages portant sur le nucléaire. Le courant  délivré actuellement aux particuliers est déjà de plus en plus taxé, avec une augmentation bien plus rapide que celles des taxes carbone portant sur l’essence. Toutes les causes d‘une  nouvelle révolte se mettent  en place.   Le photovoltaïque est d’un moindre intérêt que l’éolien, tout en présentant des risques  similaires. Il est difficile de comprendre l’attitude dogmatique des agences de bassin qui s’opposent au  redéveloppement du petit hydraulique, plus rentable que l’éolien et que le photovoltaïque. Il y avait infiniment  plus de poissons dans les rivières quand les 15 000 moulins étaient service. La solution pour lever les blocages me semble être qu’il soit décidé que les passes à poissons, si elles sont nécessaires, soient financées par l’Agence de Bassin.      					Christian BAILLEUX	Janvier 2019       Mémoire  relatif aux problèmes d’écologie et d’énergie.  II  Sécurité éolienne   Le seul document que  j’ai trouvé sur internet est le rapport ci-dessous  dont  je donne les parties qui me semblent les plus pertinentes.   Rapport sur la sécurité des installations éoliennes Juillet 2004  Ministère  de l’économie, des finances et de l’industrie  Le 26 mars  2004, le ministère missionne le Conseil Général des Mines pour étudier le cadre  réglementaire régissant la sécurité des installations éoliennes.  Référence : Conseil Général des Mines. N° 04-5  Chapitre I. Les accidents  d’éoliennes.  A la date du rapport, 4  accidents importants ont été signalés : 	-Port la Nouvelle (Aude)  en 2000 le mat d’une machine  s’est plié lots d’une tempête 	-Névian (Aude) 28 décembre  2002. Lors d’une tempête , l’une d es palmes  d’une machine  se détache, ce  qui entraine la rupture du mat. 	-Boulogne-Le Portel,(L’une des 4 éoliennes  de la  digue Carnot) en date du 1 janvier  2004.  Lors d’une tempête, perte d’une palme, puis de deux, et enfin rupture  du mat. (L’une des palmes se retrouve sur  le rivage de Wimereux) 	-Loon Plage  (port d e Dunkerque) couchage d’une  éolienne, le  20 mars 2004 , avec le mat et une partie de sa fondation qui a été  arrachée, suivie  de l’éclatement  d’ensemble de la  machine.   L’explication donnée pour l’accident du Portel : erreur du dispositif de fixation des palmes  Fissuration bien visible sur  les palmes éjectées. (à la  suite de  quoi les trois autres éoliennes ont vu leurs fixations des palmes renforcées ) L’explication donnée pour  Loon-Plage : une erreur de  calcul d’un facteur 10, portant sur les  fondations nécessaires.(à la suite de quoi, l’ensemble  du parc  éolien de Loon-Plage a été déconstruit.)  Chapitre II.  Sur les bases techniques de la sécurité éolienne (Texte du rapport) Force est de constater qu’une grande confusion règne dans les esprits des personnes  rencontrés par la mission, et singulièrement de la majorité des professionnels de l’éolien, quand aux spécifications techniques et aux modes de preuve à obtenir pour avoir des assurances quant à la sécurité des éoliennes implantées en France. Certains ignorent tout du sujet, s’en désintéressent totalement et déclarent s’en remettre  à une “bonne assurance”. D’autres se reposent  entièrement sur leur fournisseur de machines au motif de leur réputation sur la scène européenne. La plupart confondent réglementation, norme, certification, contrôle technique … et se satisfont du “certificat” remis par le constructeur dont ils perçoivent mal la signification réelle. Les professionnels français ne participent pas  aux travaux de Normalisation qui ont pourtant  des conséquences directes sur leurs  activités.  Bref, la sécurité, les spécifications techniques qui la concerne et plus  généralement le respect de la  réglementation qui l’encadre ne semble pas être le centre des préoccupations des professionnels de l’éolien. (en gras dans le texte )  …… La sécurité des éoliennes ne semble pas avoir été non plus au centre des préoccupations des autorités publiques. (idem)  On observera  que les textes d’application de la loi du 10 février  2000 ne s’intéressent pas à la sécurité des machines.  Ces documents traduisent la priorité des Autorités Publiques : promouvoir l’énergie éolienne dans le respect de l’environnement, mais sans égard pour la sécurité. (idem)  II.1.Normalisation.  Les professionnels français n’ont pas participé aux travaux du groupe de travail éolien de la  CEI (Commission Electrotechnique Internationale) . Selon les informations recueillies, les éoliennes produites en France ne seraient pas conformes aux dispositions de la norme CEI  61-400-1, ce qui constitue un handicap majeur pour l’exportation.  La mission ne peut que regretter que les normes élaborées par la CEI dans le domaine de l’éolien n’aient pas été transformées en normes françaises. (en gras dans le texte )  Il n’y eu aucune participation française à la fois aux normes internationales et aux normes  européennes.  La certification des éoliennes  Comme à leurs  habitudes les pays d’Europe du Nord, ont dès 1990 développé des systèmes de certification (Allemagne, Danemark, Pays-Bas). Ces certifications sont à géométrie  variable, et portent parfois seulement  sur une partie des appareils. En principe la certification est purement volontaire, mais  elle peut devenir obligatoire de fait  sur certains marchés. La certification constitue partout un atout commercial déterminant sur la plupart des marchés. En absence d’un organisme de certification français, les  constructeurs de l’hexagone ont  recours à la certification Germanisher Lloyd (GL). Il fait noter cependant qu’en absence  de spécification du donneur d‘ordre les règles françaises particulières d’une part (comme les affichages en français) et certaines parties de l’éolienne (mats, fondations) ne peuvent pas être couvertes par la certification.  Les éoliennes du parc de Dunkerque avaient des générateurs certifiés par GL en 1996, ce qui n’a pas suffit à éviter une banale erreur de calcul dans les fondations. Ni les mats, ni les  fondations n’étaient couverts par la certification GL.  Réglementation existante.   La  circulaire des ministres  chargés de l’écologie, de l’équipement et de l’industrie  aux préfets,  du 10 septembre  2003  (issue de la loi du 10 février 2000) fait obligation aux entrepreneurs  de projets d’éoliennes d’obtenir : A ) Une autorisation d’exploitation par le  ministre chargé de l’industrie.  Le critère de  sécurité dans la loi  du 10 février 2000 apparaît sous la forme : les critères d’octroi de l’autorisation… portent  sur la sécurité  et la sûreté des réseaux publics d’électricité des installations et des équipements associés.    B) Une autorisation de raccordement au réseau électrique    Ces  autorisations ignorent totalement les préoccupations générales de sécurité, à la fois  du public et de l’exploitant.  A cela s’ajoutent les textes généraux : 	-permis de  construire  	-étude d’impact pour une éolienne de puissance supérieure à 2,5 MW  (Remarque CBx : c’est ce qui fait la majorité des éoliennes françaises ont une puissance maximale d e  2,5 MW) Quand à la réglementation de la construction, il y a du flou relativement aux fondations.  La conclusion générale à l’époque du rapport était : La mission estime que si le ministère chargé de l’industrie souhaite voir renforcer la sécurité des éoliennes, condition de leurs développements, il doit y consacrer les unités d’œuvre nécessaires. La mission suggère au ministre de maintenir sous l’autorité de la DRIRE l’inspection du travail dans les parcs éoliens.  Questions C. Bailleux : Le rapport contient 19 propositions  d’améliorations des  règlements  alors existants. Qu’elles suites ont été données à ce rapport ?  Existe-t-il des rapports similaires mais plus récents ? Comment le savoir et comment se les procurer : Ministère ou  Service Général des Mines ?  Comment  avoir le rapport d’accident de Boulogne-Le Portel, avec examen des causes ? Le maire du Portel de l’époque a-t-il eu communication de ce rapport ? Quels documents a eu en main le maire du Portel pour donner le permis de construire ?   L’accident de Widehem n’est pas évoqué dans ce rapport car survenu après. Là aussi j’aimerai beaucoup avoir le rapport d’expertise d’après accident. Le maire de Widehem l’a-t-il eu ?       Mémoire  relatif aux problèmes d’écologie et d’énergie.  III  Aspect pétrole-gaz naturel  Plan  I. La place du pétrole et du gaz naturel dans l’approvisionnement énergétique de la France.  II. La production française  actuelle.  III. Les fluctuations de prix. Le problème du déficit de la balance commerciale française.  IV. La théorie du Peak Oil marque le pas  V. Les pétroles non conventionnels.  VI. Les éléments spécifiques liés Gaz Naturel.   Recommandations   I.	La place du pétrole et du gaz naturel dans l’approvisionnement de la France  Si  nous considérons l’ensemble énergétique français, nous obtenons pour 2016 : 		combustibles carbonés fossiles : 67,7 % (charbon 2,0%, pétrole 43,5 %, gaz naturel 		22,2 %),  	nucléaire :18,1 %,  	énergies renouvelables : 14,2% (biomasse, déchets 9,7%, hydraulique 2,9%, 			éolien 1%, solaire 0,4 % )  	 autres : 0,2 % (marée et géothermie). L’énergie délivrée via l’électricité représentait alors 25% de la consommation énergétique française totale.  L’un de points important de l’approvisionnement énergétique français est sa dépendance de l’étranger.  Après un chiffre record de 56,5 % en 2014 elle est légèrement redescendue en 2016 : 54,2 %. Elle reste un très gros problème tant politique qu’économique. Les importations de produits pétroliers sont la principale source du déficit de la balance commerciale française.   La France a consommé en 2015 : 76,7 millions de tonnes de produits pétroliers, un chiffre   tendanciellement en baisse depuis les années 1970.  La production mondiale 2015 étant  de 34 901 millions de barils, soit  4 886, 14 tonnes,    La France consomme donc: 1,6 %  de la consommation mondiale.  Il importe d‘être réaliste, la France n’a aucun poids en ce domaine. Aucune des décisions qu’elle peut prendre n’aura de conséquence au niveau mondial.   La France dispose d’un approvisionnement diversifié en pétrole brut, l’Arabie Saoudite étant le seul pays disposant en 2014 d’une part de marché supérieure à 20 %.  Les autres pays de l’OPEP : le  Nigéria, l’Algérie et l’Angola rassemblés nous en fournissent 30%. Les pays de l’ancien bloc soviétique : la Russie, le Kazakhstan et l’Azerbaïjan nous en fournissent environ 30 %, après vient la Norvège. La flexibilité de l’ensemble a permit de surmonter la perte des approvisionnements irakiens  en 1990, et libyens en 2011.   II.	La production française actuelle  En 2011, 2012, 2013 et 2014, la France a produit 1, 2 millions de tonnes de pétrole, soit 1,6 % de sa consommation (équivalent de 7,5 millions de barils annuels. En 2017, ce chiffre est tombé à 815 millions de tonnes et 0,15 milliards de m3 de gaz (107 millions de tonnes) Au cours de la période 1956-2017, la France a produit 100 millions de tonnes de pétrole et 300 milliards de m3 de gaz naturel (245 pour le  seul  gisement de Lacq, et 56 pour Meillon) Actuellement, environ 20 000 barils de brut sont extraits chaque jour de deux régions (55% en Ile de France, 45 % en Aquitaine). Le principal producteur (3/4 de la production française) est la société canadienne Vermilion Energy implantée en France depuis 1997. Le second actuellement est l’International Petroleum Corporation basé également au Canada.  En septembre 2017, le gouvernement français annonce  la fin de toute exploitation d’hydrocarbures  sur tout le territoire national d’ici 2040. Cette décision fait fi de l’économie, elle n’est d’aucun poids à l’international. Elle est de ce fait purement dogmatique   Le 19 décembre 2017, de plus l’Assemblée Nationale française, interdit la recherche d’hydrocarbures sur le territoire français avec effet immédiat.  Cette décision est en opposition totale avec le rapport de la mission de l’Assemblée Nationale chargée d’étudier l’intérêt du pétrole et du gaz de schiste en date d’avril 2014, présenté en détail, ci-après dans la paragraphe gaz de schiste, ainsi qu’au rapport du Sénat (OPECST) qui lui-aussi préconise de continuer les recherches en la matière, en date du 7 janvier  2014. Cependant vu les contrats passés antérieurement, la recherche du pétrole en Guyane peut continuer ainsi que son exploitation éventuelle (Total-Shell).          III. Les fluctuations de prix du pétrole. Le problème du déficit de la balance commerciale française  Les fluctuations du prix du pétrole.  Les fluctuations du prix du pétrole sont depuis une quarantaine d’années plus liées à des raisons politiques qu’à des difficultés techniques d’approvisionnement. Le premier choc pétrolier, celui de 1973-1974 , résulte de la guerre entre Israël et une  coalisation de pays-arabes. Comme au cours de cette guerre aucune  installation pétrolière ne  fut détruite, c’est une affaire purement politique : le 16 octobre 1973, les pays arabes de  l’OPEP réduisaient délibérément leur production de pétrole de 5%, puis de 25% le 5 novembre. De ces décisions résultent que Le prix du pétrole est multiplié par quatre. Les conséquences économiques sont lourdes : c’est la fin des “Trente Glorieuses”. Le second choc pétrolier eut lieu en 1979. Le prix du pétrole passa de 15 $ le baril en septembre 1978, à  40 $  en avril 1980, en raison de l’arrêt de la  production iranienne du fait de la révolution en cours dans ce pays. Le pic atteint en avril 1980  semble lié à la guerre Iran-Irak.  L’invasion du Koweit  par l’Irak en 1990  fut à nouveau la cause d’une forte hausse, mais à la  suite de l’arrivée d’un important contingent de troupes américaines en Arabie Saoudite, les  craintes de  perdre la production saoudienne disparut et le prix du pétrole chuta. Par contre la crise économique asiatique de 1997 en raison de la moindre demande, provoqua la chute du baril à 11 $. Puis à la fin des années 90, les prix repartirent à la hausse.  Avec le nouveau siècle deux perturbations arrivèrent liée d’abord fin 2002 à la chute de la production vénézuélienne (Révolution), puis en 2003 de celle de l’Irak (Guerre Iran-Irak).  La hausse du prix du pétrole entre le milieu de l’année 2003 et le milieu de l’année 2008 est la plus forte que l’économie mondiale ait connu depuis celle de 1979. Le prix du pétrole  (WTI)  est passé de  28 à 134 $. (avec un pic proche de 150 $)        Puis entre juin 2014 et janvier 2015, le prix du pétrole Brent passa de 112 à 47 dollars. En ce tout début  2019, le prix du baril est à 52 $.  Il est clair que les variations de prix n’ont rien à voir avec les capacités de production, elles résultent des guerres, révolutions, spéculation au niveau mondial. Sur le plan économique la France n’a aucune possibilité d’action, en raison de son faible poids.  Sa seule possibilité d’intervention lors de ces chocs, est délicate : elle est d’ordre militaire.  Le déficit de la balance économique française  En 1971, la France accusait un déficit important. La guerre du Kippour l’aggrava fortement. Le déficit de la branche énergie passa de 18 à 52 milliards de Francs.  Le  déficit français se résorba progressivement pour atteindre l‘équilibre en 1993. Après des fluctuations autour de l’équilibre entre 1993 et 2003, le déficit n’a cessé de plonger   : - 60 milliards d’Euro en 2010,  -82 milliards en 2012. En 2016 il atteint  - 48,3 M d’Euro, et  - 62,3 milliards  en 2017.   Les deux causes principales considérées par les experts sont : -	la première est la faiblesse du tissu d’entreprises françaises : les PME  françaises sont en nombre insuffisant et n’arrivent pas à grandir.  -	-La seconde sont les importations énergétiques : pétrole et gaz.  En 2016 la  France a importé  pour  32,4 milliards de pétrole et de gaz. En 2017, la facture énergétique  s’est établie à 38,6 milliards d’Euro. Elle représente donc : 38,6/ 62,3 = 62 %, du déficit de la balance commerciale française. Si nous supposons une réduction actuelle de 50 % du parc nucléaire, et son remplacement par une production à base de pétrole et gaz, le déficit passerait  à : 48 %. Sans nucléaire nous  aurions un déficit lié au pétrole de 55 milliards d’Euro. (D’où un déficit total de 80 milliards)   IV. La théorie du peak oil marque le pas  Cette théorie est apparue au début au  20ème siècle avec la première crise pétrolière, celle de 1919. Le peak oil c’est  le moment  ”apocalytique” où la production mondiale va plafonner avant de décliner irrémédiablement. Certain prophétisaient  le prix du baril à 300 Dollars, même plus. Cette  théorie refait surface environ tous les vingt ans. Elle est souvent liée aux annonces que les compagnies pétrolières ont fortement réduits leurs recherches. C’est perdre de vue quand une compagnie pétrolière est assurée de pouvoir fournir du pétrole au cours des 20 ans à venir, elle réduit ses recherches. Cette réduction est liée à une bonne gestion économique et rien d’autre.   Depuis l’exploitation du pétrole of shore qui a démarré à partir de 1934  dans le golfe du Mexique, précédée en 1912 par les plateformes sur le lac Maracaïbo  au Vénézuéla, les barges, puis les plateformes pétrolières ont conquis progressivement les océans, au rythme des chocs pétroliers  successifs. C’est ainsi que le choc de 1973, a conduit les états européens à s’intéresser aux gisements gaz et pétrole de la Mer du Nord. Les progrès technologiques développés pour la Mer du Nord ont ouvert la porte à l’exploration dans une bonne partie des mers et océans du globe. L’exploitation of shore est passée ainsi de 10% en 1960, à 30% en  2010. L’exploitation of  shore est bien loin d’être terminée. Elle est passée de l’exploitation des fonds marins de  500 m dans les années  70, à plus de 2500 m dans les années 2000. Le challenge actuel est l’exploitation de l’arctique.(Et l’Antarctique me direz vous ? Chut il ne faut pas en parler, c’est par pur hasard que la Russie a découvert un océan souterrain dans sa zone).  On estime que la consommation de pétrole pourrait presque doubler d’ici 2050 avec l’augmentation  de la population mondiale et de la croissance économique.  Pour doubler la production de pétrole devra de plus en plus faire appel à ceux qu’on appelle pétroles  non conventionnels   V. Les pétroles non conventionnels.  Au cours  des dernières  décennies deux nouveaux types de pétrole sont apparus en force.  Les sables bitumineux D’abord les sables bitumineux, avec deux gisements fabuleux. Celui de Fort Mac Murray dans le Nord de l’Alberta au Canada, qui est à même à lui seul de fournir le pétrole à la terre entière pendant un siècle (au niveau de production actuelle) .(De passage en Alberta, j’ai pris connaissance d’une pétition locale demandant à ce que le Canada conserve pour lui ce pétrole pour ses besoins propres lors des six siècles à venir !) Comment exploiter au mieux cette manne, sans faire hurler les écologistes ?  Le département Pétrole de l’Université d’Edmonton, créé spécialement, a été chargé il y a vingt ans de mettre au point les procédés d’extraction non polluant, et de déterminer à quel niveau le coût du brut mondial rendrait l’exploitation économiquement viable. Le verdict fût 38 dollars le baril. C’est ainsi que l’exploitation a commencée il y a maintenant dix ans. Le seul problème non alors résolu était l’exportation du pétrole obtenu : le projet en cours de réalisation maintenant, depuis la présidence Trump est celui de la construction d’un pipe-line reliant l’Alberta à la Louisiane. La solution de rechange était un pipe-line trans-canadien menant le pétrole au Québec ou en Nouvelle-Ecosse (Halifax), avec ensuite des tankers pour l’alimentation de l’Europe.   Un autre gisement de sables bitumineux, de taille comparable, existe. Il se situe au Vénézuela, mais  en pleine forêt vierge. Son exploitation posera plus de problèmes que l’exploitation canadienne. Er vu les  problèmes actuels de ce pays, l’exploitation est loin de commencer.  Le pétrole de schiste Le pétrole de schiste est un pétrole léger contenu dans des formations géologiques de faible porosité, souvent du schiste. Contrairement aux gisements  classiques où la roche-mère  est poreuse, le mélange schiste-argile qui abrite le pétrole n’est pas poreux. Il faut fracturer cette roche pour en extraire le gaz et le pétrole. Son exploitation a commencée en France, en 1930, à Creverney  (Haute-Saône) ! En 1933 la production s’établissait à 5 000 l par jour. Au cours du demi siècle qui a suivi, les disponibilités de pétrole à faible coût d’exploitation, ont conduit à son abandon. Ce second pétrole non conventionnel a fait son retour en force  il y a maintenant une dizaine d’années, à la fois pour le pétrole et le gaz, en raison du développement des techniques d’exploitation  le  concernant, par les pétroliers texans. L’économie  américaine s’en est trouvée bouleversée, avec aussi  d’importantes conséquences au niveau mondial. En 2010 en France, 64 permis d’exploration ont été délivrés par le gouvernement pour trouver du pétrole ou du gaz, dont 15 concernaient la recherche d’hydrocarbures non conventionnels. Selon l’Agence Gouvernementale Américaine de l’Energie (EIA) la France et la Pologne seraient les deux pays européens aux ressources en gaz de schiste les plus importantes. En France,  cela  représenterait  15 gisement  de  type Lacq,  plusieurs régions ont été explorés il y a déjà plus de deux décennies : il s’agit du bassin sud-ouest, ainsi que les deux boutonnières tertiaires françaises : le Boulonnais et le Pays de Bray. (Les  gisements se trouvant sous ceux de charbon ) Ce qui pose problème est la fracturation souterraine en grande profondeur des schistes renfermant le gaz et/ou le pétrole. La seule technique opérationnelle actuellement est la fracturation hydraulique, qui a provoqué une levée de boucliers des  écologistes, soit disant en raison des risques de pollution de nappes phréatiques, mais ne sommes nous pas en grande profondeur ?   Les écologistes français ont obtenu un moratoire sur ce type d‘exploitation.  Ayant eu l’occasion de rencontrer un membre de la direction de Total, je lui ait demandé pourquoi  Total n’avait pas protesté contre cette décision. Sa  réponse fut, que ce n’était pas nécessaire, “nous  savons parfaitement où se  rouvent les gisements français” !  Concernant  le Boulonnais, Je ne doute pas que les Anglais très pratiques, installent des derricks en bordure de la Manche dans le Kent, pour pomper le pétrole existant sous la Manche, sans tenir compte de frontière.   Une mission du Sénat a été envoyé récemment sur les champs d’exploitation du pétrole schiste, à cet instant je n’ai pas encore réussi à m’en procurer le rapport. Quoiqu’il en soit, le pétrole de schiste vient de permettre  aux Etats-Unis de redevenir le premier producteur mondial de pétrole et d’importateur notamment de gaz, de devenir exportateur. (Ce qui peut avoir des conséquences politiques incalculables, les USA n’étant plus tributaire du Moyen-Orient pour son pétrole)   VI. Eléments spécifiques liés au Gaz Naturel  Gaz Naturel : belle appellation écologique du méhane : CH4.  Historique de Gaz de France Née le 8 avril 1946, en même temps qu’EDF, Gaz de France, est formé par le transfert de la quasi totalité des sociétés gazières privées. Sont exclues les sociétés d’économie mixtes (Régies) dont a plus importante  est celle de Bordeaux (à comparer  avec EDF,  dont la principale régie qui  échappe à la nationalisation est Electricité de Strasbourg qui couvre l’Alsace). Dans ses premières années  d’existence, GDF  fournit du gaz de ville,  produit à partir de charbon. La découverte, et la mise en exploitation du gisement de gaz naturel de Lacq à la fin de 1950,  permet  à GDF  de réorienter  son activité vers le Gaz Naturel. Le fort développement  économique qui suivit, fit que Lacq n’était plus  suffisant. De nouvelles sources d’approvisionnement furent recherchées. Ce fut d’abord les Pays-Bas  (Gaz de Groningue), puis l’URSS qui nécessitèrent l’établissement de conduites gazières trans-européennes. Le Gaz Algérien nécessita la création de nouvelles structures très particulière : unité de liquéfaction d’Arzew, construction de méthaniers, et d’unités de gazéification en France, conduisant  le gaz dans d’important réservoirs de stockage souterrains, alimentant le réseau gazier national. Cette technologie a ouvert la porte à d’autres sources d‘approvisionnement : Quatar et depuis peu les Etats-Unis.       Aujourd’hui le gisement de Lacq est considéré comme épuisé, ce qui implique que l’on importe la  totalité du Gaz Naturel consommé en France. A partir de  2002 (Président Chirac) le statut de GDF évolue : séparation d’avec EDF, ouverture du capital au privé. En 2006, officiellement pour contrer une OPA de l’Italien ENEL, le gouvernement  annonce la fusion de GDF avec Suez. Ce projet de privatisation déguisée pose beaucoup de problèmes. Finalement, GDF est officiellement privatisé le 7 décembre  2006. La fusion est concrétisée en 2008. Depuis GDF-Suez, a pris le nom d’ENGIE.   La consommation gazière française La consommation gazière française de  2017 s’est élevée à 465 TWh dont 190 TWh pour usage industriel. Elle a été en légère augmentation par rapport à 2016 : + 0,4% , essentiellement en raison de  15 jours très froids en janvier. Il est bon de remarquer que dans la part consommation industrielle 55 TWh vont aux centrales à gaz, productrices d’électricité. Quand au biométhane, sa production s’est élevée à 408 GWh (0,408 TWh). L’objectif est l’injection de 90 TWh dans le réseau gazier  en 2030. (On peut rêver)   Le problème majeur actuel relatif à l’approvisionnement en Gaz Naturel est  l’indexation de son prix sur celui du pétrole.  Depuis de nombreuses années le gouvernement français comme la plupart des gouvernements  européen luttent pour l’annulation de cette indexation, avec bien sur comme opposants les grands  pays producteurs : Russie, Qatar, Algérie, Norvège… Un des argument  développé est que les  réserves gazières sont colossales, bien plus importantes que celle de pétrole, sans ternir compte du gaz naturel non conventionnel : gaz de schiste, hydrate de méthane.  L’exploitation du gaz du schiste Elle est tout à fait similaire à celle du pétrole et a levé dans certains pays des levées de boucliers par les écologistes. Des pays comme les USA et le Canada s’y sont complètement lancés. Les présentations  journalistiques sur le  sujet sont à considérer avec beaucoup de précaution.  Il est un fait certain souligné dans le compte-rendu de la commission de l’Assemblée Nationale  chargée d’enquêter sur  les conséquences de la production de pétrole et de schiste (N° 1919 de  M. Frédéric Barbier). En raison du développement de l’exploitation du gaz de schiste américain : la seule  évolution notable pour la France est la renégociation progressive des contrats signés avec les  fournisseurs norvégiens et russes, visant à aboutir à une désindexation partielle des contrats sur les prix des produits pétroliers.  L’aspect négatif pour l’Europe hors la France, du point de vue écologique : l’exploitation du gaz de  schiste aux Etats-Unis conduit à des exportations de charbon à faible coût. Certaines centrales  électriques à gaz européennes sont repassées au charbon. (Diminution du CO2 émis par les USA, augmentation inverse pour leurs acheteurs de charbon) L’un des points  mis en avant pour expliquer le succès américain est la  possession du sous-sol des terrains par les propriétaires de ceux-ci.   Ce qui impliquerait  une modification du régime foncier français.  L’industrie chimique américaine, dont celles de la chimie organique et la pharmaceutique sont en plein boom de fait de ces nouveau approvisionnement, en particulier de l’ éthane, un  produit très  intéressant pour la synthèse organique. Les industries françaises de ce secteur risquent de souffrir cruellement du renouveau des industries américaines de ce même secteur.  Le rapport de l’Assemblée  Nationale évoqué ci-dessus  préconisait de relancer les recherches en matière de gaz et de pétrole de  schiste, afin de se servir des découvertes à venir comme arme de négociation face aux Russes, Norvégiens et Algériens.          L’hydrate de méthane Les hydrate  de méthane (ou clathrate de méthane )  sont des composés organiques naturellement présent dans les  fonds marins et sur certains talus continentaux, ainsi que dans les régions polaires. Les ressources mondiales en méthane en la matière sont colossales. Le Japon examine avec grand soin ces hydrates qui lui permettrait de retrouver son indépendance  énergétique. En 2013, l’hydrate de méthane a été pour la première fois extrait avec succès à partir d’un navire de forage.  En Europe, ce sont les Ecossais qui s’intéressent particulièrement à leur éventuelle exploitation.  La France avec son très important domaine maritime devrait suivre avec beaucoup d’intérêt les développements en cours.    V. Le chauffage des habitations particulières  et des locaux de plus grande taille  Pour se chauffer au gaz, trois possibilités existent : le méthane  (où Gaz Naturel) propane et le butane que l’on compare au fuel domestique :.  	Noms		Formules	Pouvoir calorifique(PCI)	%C	 						KWh/kg			 	Méthane 	CH4			14,15			0,75			 	Propane	C3H8			12,07			0,82		 	Butane		C4H10			11,78			0,83		 	Fuel (C7H16 – C8H18)	            12,4			0,84		  Le fioul domestique est la fraction  C16 à C18 issue du raffinage. Sa température d’ébullition selon sa composition varie de 300 à 400°. On y ajoute quelques composés plus légers afin de faciliter son allumage. La très forte augmentation du coût du fuel domestique au cours des dernières décennies a fait que le chauffage domestique a basculé vers les combustibles gazeux.   De loin le meilleur combustible gazeux disponible est le Gaz Naturel, le problème majeur posé est  le  développement du réseau de distribution, qu’il est très couteux d’étendre hors des villes.     Le rendement des chaudières à gaz a connu ces dernières années un progrès sensible avec l’apparition des chaudières à condensation qui permettent de récupérer une part de la chaleur latente de la vapeur d‘eau contenue dans les gaz d’échappement.  L’amélioration de rendement peut théoriquement aller jusqu’à 11% du PCI  pour une chaudière gaz, à comparer aux  6 %  des chaudières à fuel.  Le rendement global de ces chaudières à condensation est excellent, pouvant atteindre  90 %.  En France, l’ADEME (Agence de l’Environnement et de la Maîtrise de l’Energie) a publié en décembre  2014  un avis sur les performances des différents systèmes de chauffage.   Le chauffage  électrique utilisé dans 9,5 millions de Français est la seconde énergie de chauffage. Il est une solution très pratique, à moindre coût d’investissement. Il nécessite bien moins d’entretien que les chauffages au gaz et fuel, et il disponible sans s’occuper d’approvisionnement  (aucun combustible à  stocker ). Avec la domotique moderne, le chauffage des différentes pièces d’une maison et d’un appartement peuvent être programmées, même de l’extérieur.  Son coût jusqu’à présent est, dans le cas français, insensible aux fluctuations de prix du pétrole et du gaz qui lui est indexé. Il a augmenté cependant de l’ordre de  7-10%  en raison de la taxe : CSPE (Contribution au service public d’Electricité)    Et dans le contexte écologique, du fait  de la production électrique à base de nucléaire  et d’hydraulique, il ne rejette pas de  C02 dans l’atmosphère. C’est le  seul avec le chauffage géothermique qui reste cependant très peu développée en raison de son coût d’investissement et de ses  contraintes d’utilisation (chauffage par le  sol) Le seul risque est que si le remplacement  des centrales nucléaires envisagé actuellement par des  éoliennes est  effectivement mis en œuvre, le coût de l’électricité risque d‘être multiplié au moins par  3, ce qui posera d’énormes problèmes aux personnes disposant de ce type de chauffage. Il faut souhaiter que le gouvernement informe les particuliers de cette évolution des prix du fait de ses  choix. Cette information arrêterait très certainement le  développement du chauffage  électrique.   Les risques de se retrouver sans chauffage, liés à l’instabilité du réseau, détaillée dans le premier mémoire, si une  trop grande part de l’électricité est fournie par les éoliennes, sont les mêmes pour le chauffage électrique que pour le chauffage au gaz ou au fuel : sans  électricité tous les système de chauffage s’arrêtent.   L’isolation  thermique, développée en particulier par Saint Gobain, un des leaders mondiaux en la matière et de plus français, est très performante. De plus Saint Gobain, un des grands verriers  mondiaux (son premier métier) a développé les doubles et triples vitrages. Ces derniers sont surtout  utilisés dans les régions risquant de souffrir particulièrement du froid.   Les aides gouvernementales existantes à la fois relativement aux chaudières modernes à condensation et l’isolation vont dans le  bon sens.    					 								Christian BAILLEUX 				 									Janvier  2019