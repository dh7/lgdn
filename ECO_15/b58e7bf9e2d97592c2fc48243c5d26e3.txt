LA TRANSITION ENERGETIQUE 2	Mise en œuvre de la transition énergétique : 2.1	Réduction de 75 % à 50 % la part du nucléaire dans la production d'électricité François Hollande avait annoncé son intention de modifier radicalement le mix énergétique de la France dans l'hypothèse où il serait élu président de la République. L'accord politique avec les Verts comprenait un engagement à faire chuter de 75 % à 50 % la part du nucléaire dans la production d'électricité à horizon 2025. Ce plan impliquait la fermeture de 24 réacteurs sur les 58 exploités par EDF Chez les Républicains on pense que François Hollande devait aussi envoyer des gages à l'Allemagne qui avait fait le choix de sortir du nucléaire et qui était particulièrement sensible à la position géographique frontalière de la centrale de Fessenheim. Pendant tous son quinquennat, il a oublié cette promesse, mais pas son ex compagne qui le 9 avril 1977 (14 jours avant le premier tour de l’élection présidentielle) a passé un décret sur la fermeture de la centrale de Fessenheim, arrêté qui a été retoqué en 2018 ! 2.2	Débat impossible sur certains sujets En octobre 2013 Robert Badinter, Jean-Pierre Chevènement, Alain Juppé et Michel Rocard ont émis le communiqué suivant qui est toujours d’actualité : " Nous assistons à une évolution inquiétante des relations entre la société française et les sciences et techniques. Des minorités constituées autour d’un rejet de celles-ci tentent d’imposer peu à peu leur loi et d’interdire progressivement tout débat sérieux et toute expression publique des scientifiques qui ne partagent pas leurs opinions. L’impossibilité de tenir un débat public libre sur le site de stockage des déchets de la Cigéo est l’exemple le plus récent de cette atmosphère et de ces pratiques d’intimidation, qui spéculent sur la faiblesse des pouvoirs publics et des élus. […] Nous appelons donc solennellement les médias et les femmes et hommes politiques à exiger que les débats publics vraiment ouverts et contradictoires puissent avoir lieu sans être entravés par des minorités bruyantes et, parfois provocantes, voire violentes. Il est indispensable que les scientifiques et ingénieurs puissent s’exprimer et être écoutés dans leur rôle d’expertise. L’existence même de la démocratie est menacée si elle n’est plus capable d’entendre des expertises, même contraires à la pensée dominante. Il serait souhaitable que ce communiqué soit suivi et en particulier par les medias d’état et que ces médias soient objectifs. 2.3	Extraits d’avis de différentes instances scientifiques sur la transition énergétique 2.3.1	Avis de l’Académie des Sciences Les membres de l’Académie des Sciences affirment que l’énergie nucléaire est objectivement le moyen le plus efficace pour réduire la part des énergies fossiles dans la production d’énergie électrique et qu’il y a une véritable contradiction à vouloir diminuer les émissions de gaz à effet de serre tout en réduisant la part du nucléaire. Enfin de nombreuses études montrent que la part totale des énergies renouvelables dans le mix électrique ne pourra pas aller très au-delà de 30-40 % sans conduire à un coût exorbitant de l’électricité et des émissions croissantes de gaz à effet de serre et à la mise en question de la sécurité de la fourniture générale de l’électricité. 2.3.2	Avis de l’ l'Académie des technologies Les membres de l’Académie des technologies estiment que l’objectif de réduire la part du nucléaire dans la production d’électricité à 50% à l’horizon 2025 ne peut être atteint par la seule augmentation de la puissance installée en énergie renouvelable dans l’état actuel des technologies compte tenu des régimes de vents et de soleil dans l’hexagone. Cet objectif de 50% imposerait une augmentation de la production d’électricité d’origine fossile et donc une augmentation des émissions de CO2 Le nucléaire permet à la France d’être parmi les premiers en émettant 5,52 t/an/habitant de CO2 (contre 9,32t/an en Allemagne) pour une consommation semblable d'énergie primaire par habitant. Cette performance est due à la structure de notre appareil de production d’électricité qui n’émet du CO2 que pour 10 % environ de sa production alors que presque partout dans le monde, la production d’électricité constitue la première source d'émissions de CO2. L’expérience allemande du développement rapide des EnR intermittentes (associé à la sortie programmée du nucléaire) conduit à une augmentation des émissions de gaz à effet de serre et à un coût élevé pour les consommateurs. Cela n’est pas cohérent avec les objectifs affichés par la loi. 2.3.3	Avis du GIEC Dans ce nouveau rapport, tous les scénarios qui permettent de respecter la COP 21 prévoient une augmentation substantielle du nucléaire dans le monde, et même jusqu’à une multiplication par… six. La politique française visant à diminuer la part de l’énergie nucléaire dans le mix électrique (en fermant la centrale de Fessenheim et en visant 50% de nucléaire) est donc contraire… aux objectifs affichés sur le climat lors de la conférence de Paris en décembre 2015, y compris par le gouvernement français. Il serait pertinent que nos gouvernants s’appuient sur l’Académie des Sciences, l’Académie des technologies, sur les recommandations du GIEC lorsqu’ils prennent des décisions concernant des sujets à caractère scientifique et non sur des partis politiques minoritaires et viscéralement opposés à l’énergie nucléaire ou sur l’ADEME dirigé par un ancien membre des Verts. On pourrait attendre de nos gouvernants qu’ils respectent les décisions prises lors de la COP 21.  2.3.4	Tribune de François-Marie Bréon, Michael Shellenberger, Valérie Faudon et J M Jancovci.  Extrait de la Tribune parue dans Le Monde, daté du 16 novembre 2018, co-signée de François-Marie Bréon, directeur adjoint du Laboratoire des Sciences du Climat et de l’Environnement, Michael Shellenberger, président de Environmental Progress, Valérie Faudon, cofondatrice de Nuclear for Climate, et J M Jancovci, ancien élève de l'École polytechnique et ingénieur civil diplômé de l'École nationale supérieure des télécommunications, il a collaboré avec l'ADEME pour la mise au point du bilan carbone dont il est le principal développeur : Les scénarios du GIEC, de l’Agence internationale de l’énergie ou encore de l’European Climate Foundation (qui soutient de nombreuses ONG écologistes) montrent qu’il est impossible de réduire les émissions de gaz à effet de serre à la bonne vitesse sans énergie nucléaire. L’impasse de la transition énergétique allemande, pour l’heure incapable de sortir du charbon, et le retour à la hausse des émissions des autres pays de l’OCDE depuis 2015 malgré un développement massif des ENR doivent nous alerter : les voyants rouges s’allument les uns après les autres sur notre tableau de bord. Dans ce contexte, il est irresponsable de se priver d’une source massive d’électricité décarbonée, et de ne pas agir avec pragmatisme. Dans notre pays, l’urgence n’est pas de substituer les renouvelables électriques au nucléaire, mais bien de compléter ce dernier par de la sobriété dans les comportements, et des renouvelables dans la chaleur, pour diminuer au plus vite les combustibles fossiles 2.3.5	Article de Francis Sorin de la SFEN Il est ainsi désolant de constater qu'à la faveur de cette curieuse « transition écologique » le dogme de la diminution du nucléaire aboutit à la déconstruction d'un système électrique faiblement émetteur de CO2 et à son remplacement par un système potentiellement générateur de fortes quantités de ce gaz, ce qui est l'exact contraire de l'objectif affiché ! Les concepteurs de cette « transition » font fausse route : la cible doit être le CO2 et pas le nucléaire. Tout indique au contraire que cette énergie doit être non seulement confortée mais aussi développée. C'est ce que prônent maintenant, après des années de tergiversations, les grandes instances internationales engagées dans la lutte pour le climat, comme la COP 24 ou le GIEC : dans ses quatre scénarios pour décideurs, celui-ci en appelle à un recours considérablement accru au nucléaire, allant d'un doublement à un quintuplement de sa capacité planétaire installée. Dans ce contexte, loin d'ostraciser le nucléaire, la France devrait veiller à son utilisation stratégique et écologique optimale sur un plan national ainsi que dans l'ensemble européen. Il est peut-être temps de ce point de vue de jeter les bases d'un système électrique européen intégré où la France, développant son nucléaire au-delà de sa demande intérieure, deviendrait un important fournisseur de ses voisins en électricité sans CO2, contribuant ainsi à la décarbonation de l'Europe. 2.3.6	Bill Gates parie sur le nucléaire Bill Gates est membre du fonds d’investissement « Breakthrough Energy Ventures » destiné à financer des technologies propres (les « cleantech »). Ce fonds investit par exemple dans la start-up "TAE Technologies" qui développe un réacteur de fusion nucléaire. Bill Gates préside la start-up « Terra Power » dont l’objectif consiste à développer un réacteur nucléaire de quatrième génération à neutrons rapides refroidi au sodium, appelé « Travelling Wave Reactor », ou « réacteur cigare ». Jeff Bezos, PDG d’Amazon investit aussi dans la start-up de fusion nucléaire « General Fusion ».  La politique énergétique doit être revue et il serait souhaitable que le Ministère de la transition écologique cesse d’être confié depuis des décennies à des idéologues et soir confié à des scientifiques sans a priori qui tiennent compte en particulier de l’avis de l’Académie des Sciences et aussi de la Cour des comptes. 2.4	Limites des énergies renouvelables 2.4.1	Solutions envisageables pour remplacer la totalité du parc nucléaire actuel de la France J. M. Jancovici Imaginons que nous voulions remplacer le nucléaire par des éoliennes. La première chose à avoir en tête est que, pour une même quantité d'électricité produite sur la même durée, il va falloir installer bien plus de puissance qu'avec du nucléaire. Sur une année, un réacteur nucléaire français fournit autant d'électricité que s'il produisait à pleine puissance 75 % du temps (taux de charge75%). Une éolienne située en Europe, c'est beaucoup moins : à la fin de l’année l'éolienne fournit autant d'électricité que si elle produit à pleine puissance 15 à 25 % du temps, selon les années ou le pays (taux de charge moyen 20%). Pour une même production annuelle, il faut donc installer 3 à 4 fois plus de puissance en éolien qu'en nucléaire : nous voici donc avec 200 à 240 gigawatts d'éolien à installer, soit 20 à 25 fois le parc installé en France à fin 2014 (et 5 à 6 fois le parc allemand). Mais les deux moyens ne fournissent pas non plus de la même manière : le nucléaire est largement pilotable (on peut arrêter ou démarrer un réacteur, baisser ou monter sa puissance, etc.), alors que le vent n’a pas été programmé pour souffler uniquement quand il y a de la demande électrique. Avec un parc installé dont la puissance est aussi importante que celle évoquée ci-dessus, une partie de la production éolienne arrivera quand il n'y aura pas de consommateurs, alors qu'une partie de la demande aura lieu quand il n'y aura pas du vent. II va donc falloir stocker une fraction de la production excédentaire quand il n'y a pas de demande, pour la rendre disponible quand la demande est là. Comme nous avons supposé un système 100 % éolien, il n'y a donc pas de centrale à charbon ou à gaz pour pallier l'absence de vent. Comment stocker ? Le mode le plus efficace est le barrage réversible, ou station de pompage. Il s'agit d'un barrage, comme celui de Serre-Ponçon, auquel a été adjointe une retenue d'eau à l'aval de la turbine. Une fois passée dans cette dernière, l'eau ne repart pas dans le lit de la rivière, mais reste disponible dans la retenue située sous le barrage. Quand il y a un surplus d'électricité sur le réseau, on peut faire fonctionner une pompe qui remonte l'eau de cette retenue dans le lac de barrage, où elle pourra à nouveau servir à fournir de l'électricité. Le rendement d'une telle installation est d'environ 75 %. Jean Marc Jancovici démontre que pour atteindre l’objectif fixé, il faudrait l’équivalent de 300 barrages de Serre Ponçon, ce qui est irréalisable sur le territoire français. De plus Le réseau électrique doit aussi être adapté à cette nouvelle donne : au lieu de raccorder 20 sites de production avec le nucléaire, il faut raccorder des milliers avec l'éolien. L’objectif est encore plus difficile à atteindre avec l’éolien qui a un taux de charge inférieur à celui de l’éolien (taux de charge15%). Les articles suivants dans « Connaissances des Energies » et de « Capital » confirment les conclusions de Jean-Marc Jancovici.* 2.4.2	Inconvénients des énergies renouvelables La construction d’une éolienne nécessite des travaux de génie civil important ainsi que des quantités de matériaux importantes L’énergie de rotation des éoliennes est convertie directement en électricité grâce à des aimants permanents, notamment ceux à base de néodyme, qui emploient une grande quantité de terres rares, jusqu’à 600 kg pour une éolienne de 3,5 mégawatts. Des projections estiment qu'il faudrait 150 000 tonnes de néodyme pour fournir 250 gigawatts 2.4.2.1	Durée de vie des éoliennes et du photovoltaïque  La durée de vie d’un système photovoltaïque est supérieure à 20 ans. Mais cela ne signifie pas qu’après 20 ans, le panneau solaire ne fonctionne plus : en général, les fabricants garantissent 80 % de la puissance initiale après 25 ans. L’onduleur photovoltaïque lui a une durée de vie d’une dizaine d’années. Avec un taux de charge de 15%, les panneaux photovoltaïques auront fonctionné au mieux à pleine puissance pendant 3 ans, en supposant que ses performances n’ont pas décru au cours des années. Pour le voisinage, nombreuses sont les nuisances: bruit, foudre, effets stroboscopiques… On a trop longtemps négligé les infrasons et les champs électromagnétiques qui traversent les murs et s'attaquent aux organes des hommes ou des animaux, même à plusieurs kilomètres de distance. Suite à un colloque scientifique il n'est plus possible d'en faire abstraction.  La durée de vie d'une éolienne est fixée à quinze ans, correspondant à la période pendant laquelle elle est soutenue financièrement par les pouvoirs publics. Cela n'empêche pas les éoliennes de fonctionner au terme de cette échéance, mais les matériaux s'usent Selon la Fédération environnement durable, les sommes et les structures prévues pour le démantèlement et le recyclage des matériaux éoliens sont largement insuffisantes. 2.4.2.2	Restrictions pour la construction de parcs d’éoliennes Autre restriction pour la construction d’éoliennes, leur installation fait l’objet d’une réglementation pour des soucis évidents de sécurité aérienne. C’est pour cette raison qu’il est interdit d’en ériger dans un rayon de 30 km autour des systèmes de détection ou à proximité du réseau à très basse altitude (RTBA) utilisé pour les vol d’entraînement. L’aviation civile et Météo France qui utilisent des radars, sont aussi consultés quand il s’agit d’installer un parc éolien. Les deux, qui utilisent des radars, sont aussi consultés quand il s’agit d’installer un parc éolien. 2.4.3	Le stockage de l’électricité généré par les renouvelables est à ce jour irréalisable Le principal risque pour les 10 à 20 ans à venir provient d'une négligence quasi systématique des coûts associés au stockage de l'électricité. 99 % de l'électricité stockée dans le monde l'est sous forme de stockage d'eau en altitude La France dispose du deuxième parc européen avec 2300 barrages et nos marges de développements sont minimes tant pour des raisons géographiques qu'écologiques. L'importance d'une électricité fiable s'illustre aisément : à l'échelle d'un pays, un système électrique défaillant peut plonger le pays dans le chaos en quelques jours ou à tout le moins faire peser des coûts extravagants sur des pans entiers de l'économie : le fonctionnement des systèmes de santé, de toute la chaîne agroalimentaire, des opérations financières, des transports.  En France, si tous les réservoirs étaient pleins en même temps (ce qui n'arrive jamais), ils pourraient couvrir un tiers de la puissance moyenne (20 GW sur 60 GW) pendant 5 heures. Ensuite, il faudrait se contenter de la puissance disponible sur les rivières, au fil de l'eau (environ 10 % de la puissance totale), avant d'attendre des jours ou des mois pour remplir à nouveau les retenues. L'engagement massif pour les ENR représente 141 milliards d'euros pour seulement 5 % de la production annuelle... Le stockage d'énergie devient impératif, il pourrait coûter plus cher encore. L'éolien peut manquer à l'appel durant des jours entiers, sur tout le pays. En effet, les régimes de vent, même à l'échelle de l'Europe, ne se compensent nullement. Quant au photovoltaïque, son développement massif requiert un stockage de plus de 6 mois de l'électricité essentiellement produite en été, ce qui est totalement hors de portée de toute technologie connue si l'on parle de dizaines de gigawatts. L'Allemagne a démontré que subventionner massivement ces énergies ne permet en aucun cas de garantir l'émergence de filières nationales : plus aucun panneau photovoltaïque pour le grand public n'est produit en Allemagne. Ses émissions de CO2 ont augmenté et la fiabilité de son réseau électrique faiblit d'année en année. L'avis de l'Autorité de Sûreté Nucléaire - favorable à la prolongation de la durée de vie des centrales, dont Fessenheim, sous réserve de travaux - est remis en cause par la décision purement politique de fermer cette centrale et d'autres encore.  La seule attitude raisonnable consiste à prolonger la vie de ce qui fonctionne de manière sûre et propre et à privilégier des investissements dans des équipements durables plutôt que des équipements non démontrés et/ou à faible durée de vie : éolien et photovoltaïque sont garantis 25 ans uniquement et aucune grande installation n'a tourné plus de 10 ans pour l'éolien de forte puissance. Ne nous faisons pas écraser par la charge du stockage d'énergie après avoir, malgré nous, engagé des sommes colossales pour la production de seulement 5 % de notre électricité !  Tant que le stockage massif d’électricité n’est pas réalisable, il faut maintenir sinon augmenter le parc des réacteurs nucléaires, poursuivre le développement des énergies renouvelables tout en étant conscient des limites de ces énergies renouvelables et onéreuses tant que le problème du stockage de l’énergie n’est pas possible.  2.5	Avantages et inconvénients de l’énergie nucléaire  2.5.1	Le Nucléaire est-il écologique ? L’électricité nucléaire est parmi celles qui produisent le moins de CO2 sur l’ensemble de son cycle de vie (L’énergie nucléaire a une empreinte carbone médiane de 12 g de CO2 eq par kWh d’électricité produite, soit autant que l’énergie éolienne, et 3 à 4 fois moins que l’énergie solaire ou 70 fois moins que les centrales à charbon (selon les analystes du GIEC).  À ce jour, l’énergie nucléaire est l’une des sources de production d’électricité les plus efficientes pour produire de l’électricité sans contribuer au réchauffement climatique et sans polluer l’atmosphère.  2.5.2	Peut-on remplacer le nucléaire par des énergies renouvelables ? Si l’on ferme des centrales nucléaires comme c’était l’objectif initial de la Loi sur la Transition Énergétique, il faut compenser la baisse de la production que cela engendre. Les 17 réacteurs les plus anciens de France ont produit en un an environ 85 tWh d’électricité. Au total, toutes les installations solaires et éoliennes de France ont produit sur la même période environ 30 tWh d’électricité ; cela veut dire que pour supprimer 17 réacteurs nucléaires, il faudrait au minimum compenser en triplant la capacité de renouvelables installés sur le territoire. Mais en réalité, il faut beaucoup plus du fait de l’intermittence de ces énergies. Si l’on ferme 17 réacteurs d’ici 2030, comment fait-on pour multiplier par 3 la production renouvelable en seulement 12 ans, sachant que la construction d’un seul parc solaire ou éolien peut prendre plus de 5 à 7 ans ? D’où la conclusion du rapport de RTE : si l’on ferme brutalement les centrales, il faudra maintenir des centrales à charbon et construire de nombreuses centrales au gaz pour compenser. Or le charbon et le gaz sont contraires à nos objectifs de réduction des émissions de CO2 et à nos objectifs de lutte contre le réchauffement climatique. Se posent les questions du prix de ces énergies, de leur stockage pour compenser leur intermittence.  2.5.3	Faut-il privilégier la sortie du nucléaire ou la lutte contre le réchauffement climatique ? D’après les climatologues, si nous n’inversons pas la courbe de nos émissions de CO2 avant 2020, la situation climatique risque de devenir catastrophique. À l’heure actuelle, le changement climatique et la pollution de l’air liée au charbon font plus de dégât chaque année que tous les accidents nucléaires de l’histoire réunis. Cela ne veut pas dire qu’il ne faut pas sortir du nucléaire, bien sûr, ni d’ailleurs qu’il faut chercher à prolonger volontairement l’exploitation de centrales non efficientes. Mais peut être qu’envisager une sortie plus progressive est une idée plus intelligente si l’on veut pouvoir tenir nos objectifs de protection du climat.  2.5.4	Electricité: le charbon plus radioactif que le nucléaire  Gros émetteur de radon, le cycle du charbon plombe le bilan nucléaire de la principale filière mondiale de production d’électricité, souligne l’Unscear. 60.000 professionnels de santé britannique ont signé une pétition réclamant l’arrêt des centrales au charbon du royaume, responsables à leurs yeux de 3.000 décès prématurés par an. Des chercheurs de Harvard ont montré que la construction de nouvelles installations en Asie du Sud-Est pourrait tripler le nombre de décès liés à la pollution de l’air. Cette fois, il ne s’agit plus de particules fines, mais radioactives. Vingt-quatre ans après sa dernière étude sur le sujet, le Comité scientifique des Nations unies pour l'étude des effets des rayonnements ionisants (Unscear) a réévalué la contamination radioactive du public et des travailleurs exploitant les centrales à charbon 2.5.5	Déchets nucléaires, rejets du charbon : concentrer ou diluer les déchets ?  La gestion des déchets du charbon pose des problèmes bien plus importants que celle des déchets issus du nucléaire. Dans les deux cas, elle est un fardeau pour l'humanité, et implique à l'avenir de ne produire que des déchets générés par ces deux sources d'électricité, en comparant d'une part les déchets nucléaires, et d'autre part les déchets et rejets du charbon. A l'échelle mondiale, les déchets de la production d'électricité sont avant tout des déchets issus du charbon, à l'exception de la France, où les trois quarts de l'électricité sont d'origine nucléaire. 2.5.5.1	Déchets issus de l’énergie nucléaires  D'un côté, le nucléaire produit, entre autres, des déchets dits Haute Activité radioactive à Vie Longue (HA-VL). Ces déchets après solution française, actée par la loi de 2006, consiste à concentrer ces déchets Les déchets de HA sont vitrifiés ; par l’incorporation des éléments radioactifs dans du verre en fusion. Après refroidissement, la radioactivité est retenue prisonnière dans la matrice vitreuse, coulée dans des conteneurs en acier inoxydable ensuite hermétiquement fermés. Ces colis de déchets entreposés (par le CEA et Areva) sur leur lieu de production seront ensuite stockés dans une couche d'argile à 500 m de profondeur. Cela vise à les protéger des agressions extérieures et les isoler à long terme de la biosphère, sans nécessiter d'action humaine au-delà d'environ un siècle. C'est le projet Cigéo. Un élément fondamental pour appréhender ce type de déchet est le fait que l'énergie nucléaire est une énergie extrêmement dense. 1kg d'uranium naturel, permet de produire autant d'énergie que 10 tonnes de charbon. C'est parce que cette énergie est si concentrée qu'elle conduit à un déchet lui aussi concentré, et aussi dangereux. Mais cette concentration limite les volumes de déchets associés ; de l'ordre de la taille d'une piscine olympique pour les déchets Haute Activité français. Volume qui est gérable, et compatible avec une solution de traitement. 2.5.5.2	Déchets issus de l’industrie charbonnière A l'opposé, les centrales à charbon utilisent un combustible énergétiquement peu dense, avec des déchets moins concentrés : les cendres qui sont récupérées et les gaz et poussières sont rejetés dans l'atmosphère. Les cendres représentent en moyenne 15% du poids initial du charbon. Pour une centrale équivalente à un réacteur nucléaire, cela représente quelques centaines de milliers de tonnes par an. Une partie de ces cendres est recyclée, le reste est stocké en surface. Or, ces cendres, contiennent des métaux lourds extrêmement toxiques (arsenic, mercure, plomb). Les gaz et poussières, trop peu denses, sont rejetés par la cheminée, puis dispersés dans l'atmosphère. On y retrouve des cendres sous forme de particules fines, des métaux lourds, des oxydes de soufre (conduisant à des pluies acides), des oxydes d'azote, du monoxyde de carbone, de l'ammoniac et des dioxines et des goudrons cancérigènes... Cette pollution est transportée au gré des vents et impacte la santé des populations à des centaines voire milliers de kilomètres de son lieu de production. La mortalité attribuable actuellement à cette pollution atmosphérique en Europe est évaluée à quelques dizaines de milliers de morts par an. 2.5.5.3	Par kWh, le charbon tue 100 fois plus que le nucléaire A titre de comparaison, l'accident de Tchernobyl a tué, directement ou du fait des cancers induits, quelques milliers de personnes selon les différentes évaluations de l'UNSCEAR et de l'OMS. Les ordres de grandeur sont les mêmes, entre l'impact sanitaire annuel d'une partie des déchets émis en fonctionnement normal par les centrales à charbon européennes, et l'accident nucléaire le plus grave de l'histoire.  2.6	Le plan tout renouvelable de l’ADEME contesté Un document émis par l’ADEME, Trajectoires d’évolution du mix électrique 2020-2060, est présenté comme une étude technico-économique réalisée selon les meilleurs standards scientifiques. Et dont les résultats seraient sans appel. Mais une analyse d’économistes spécialisés en énergie sur ce document est sévère : il relève d’une tentative de manipulation de l’opinion publique et ne peut pas convaincre un auditoire instruit des méthodes économiques utilisées par les auteurs. Sa présentation au grand public par David Marchal, Directeur adjoint de l’ADEME, assène que «la place très prépondérante des ENR dans le système électrique français est sans appel (…) et le nucléaire de nouvelle génération (type EPR) n’apparaît pas compétitif». Une affirmation qui reposerait sur un outil de calcul économique très sophistiqué L’ennui, c’est que ce type d’outil, utilisé par l’équipe de l’ADEME, a déjà été utilisé par d’autres équipes – avec des hypothèses de coûts similaires pour les ENR et le nucléaire et une simulation où les ENR doivent se déployer dans un marché normal, sans subventions publiques massives. Des équipes variées, en France, en Allemagne ou aux Etats-Unis ont publié leurs résultats ces dernières années. Or, elles trouvent toutes des résultats très différents de l’équipe de l’ADEME. Il faut donc justifier un tel écart, pour le moins surprenant. 2.6.1	La valeur économique de l’électricité En effet, dans toutes ces autres simulations, si les ENRv ne parviennent pas à évincer le nucléaire, c’est que la valeur économique réelle de l’électricité qu’elles produisent ne supporte pas la compétition. La raison principale ? Elle provient d’un phénomène intuitif : puisque cette électricité varie en fonction des variations naturelles des vents et du Soleil, elles ne suivent pas celles de la demande. Or, la valeur économique de l’électricité est justement déterminée par cette dernière. Si vous avez trop de jus à vendre par rapport à la demande, comme vous ne pouvez le stocker, vous devez le brader. A l’inverse si vous avez un moyen de production pilotable, pouvoir répondre à la demande vous permet de le vendre très cher lorsqu’il est nécessaire et sans compétiteurs. 2.6.2	Hypothèses héroïques Les résultats surprenant de l’ADEME s’expliquent par des hypothèses «héroïques» sur nombre d’éléments du système électrique, sans que soit testée l’influence de ces hypothèses sur les résultats, ce qu’une démarche rigoureuse commanderait de faire, et que les exercices précités font. En résumé, tout est fait pour que soit maintenue et rehaussée la valeur économique des productions variables des ENRv au fur et à mesure de leur développement, alors que cette valeur plonge à partir de 30-40 % de parts de marché dans les autres modèles sans ces hypothèses outrées. Quelles sont-elles ? En voici les principales : ►Presque toutes les consommations sont supposées être asservies à la variabilité des productions des éoliennes et des installations photovoltaïques développées à grande échelle.  ► L’ADEME fait l’hypothèse d’un triplement des interconnexions (de 12 à 36 GW) avec des systèmes étrangers lesquels évoluent comme par magie pour servir les besoins français tant en exportations qu’en importations.   ►L’ ADEME suppose un développement téléguidé d’usages plutôt baroques de l’électricité pour absorber les surplus de production des équipements d’ENRv… Production de chaleur industrielle par des pompes à chaleur, production d’hydrogène par électrolyse 2.6.3	Calculs économiques En résumé, plus vous implantez d’éoliennes et plus la valeur économique de leur production va diminuer. C’est ainsi que, dans les modèles d’optimisation qui simulent le développement des ENRv uniquement par le marché, leur développement s’arrête autour de 10-15% de parts de production. Dès lors que l’on va au-delà, et surtout si l’on atteint les 80% d’ENRv dans la production, les coûts grimpent pour une raison simple et intuitive : il faut bien payer les investissements et l’exploitation des moyens pilotables ou de stockage dont la seule fonction (non rentable) est d’intervenir pour sauver le système électrique lorsque vent et/ou soleil font défaut, ce qui survient nécessairement. C’est bien pourquoi l’ADEME fait des « hypothèses héroïques » sur ce qui pourrait contrebalancer ce phénomène (flexibilité gigantesque, import/export miraculeusement aligné sur les besoins et surplus…) afin de « sauver » le soldat ENRv dominant le système électrique. Parmi les « résultats » de l’étude de l’ADEME, l’un au moins suscite le sourire : lorsqu’il est recommandé de fermer les réacteurs nucléaires actuels plus vite car leur trop bas coût de production d’électricité gène le déploiement des ENRv, handicapées par ce concurrent trop efficace. Comme le recommande le sociologue Raymond Boudon pour nous protéger des «idées fausses, fragiles ou douteuses» construites sur des raisonnements apparemment justes, il faut nous défier des prémisses implicites à base idéologique qu’il s’agit de mettre à jour 2.6.4	Un ex-Verts à l'ADEME C’est Arnaud Leroy, l’ancien porte-parole d’Emmanuel Macron durant la campagne présidentielle, qui remplace Bruno Léchevin, en fin de mandat, à la tête de l’ADEME. Diplômé en droit maritime, membre du conseil d’administration de La République en marche, il a d’abord été militant écologiste chez les Verts, dont il est devenu le secrétaire général du groupe français au Parlement européen. En désaccord sur le traité constitutionnel européen, il quitte les Verts pour le Parti socialiste en 2005. Élu député PS de la cinquième circonscription des Français établis hors de France en 2012, il choisit de suivre Emmanuel Macron en 2017. L’en voilà remercié, président de l’ADEME où il percevra mensuellement 15.830 euros bruts. Encore un exemple de favoritisme pratiqué par le Président de la République. Il est anormal que l'ADEME, établissement public à caractère industriel et commercial (EPIC) qui participe à la mise en œuvre des politiques publiques en matière d'énergie et de protection de l'environnement.et qui intervient, de la recherche à la diffusion de l'information, dans les domaines de l’efficacité énergétique et des énergies renouvelables soit dirigée par un idéologue tel que Arnaud Leroy. Les conclusions de la publication de l’ADEME (qui n’ont pas été soumises  aux Académies des Sciences et à celle des Technologies) étaient prévisibles avec un ex Verts à sa tête !  Pour mémoire :Lieu de réflexions et de propositions d’actions face aux grands défis technologiques, l’Académie des technologies tire son originalité de la diversité des origines de ses 316 membres : ingénieurs, industriels, chercheurs, agronomes, architectes, médecins, sociologues, économistes, avec une forte représentativité des directeurs de recherche du privé.  Les académiciens sont élus dans le cadre d’une procédure de recrutement rigoureuse, qui prend en compte l’excellence des personnes et le rayonnement de leurs travaux en Europe et à l’international. Cette diversité des approches permet d’apporter une expertise collective et indépendante et de rechercher un consensus large sur des questions complexes débattues au sein de 12 commissions. Les documents produits par l’Académie doivent être validés par l’Assemblée plénière à l’issue d’un processus garantissant la qualité et l’impartialité. 2.7	Hydrogène  2.7.1	Eau Electrolyse/Pile à combustible  Lors de la production de dihydrogène et de dioxygène, l’électrolyse de l’eau ne convertit que 50% à 80% de l’énergie électrique en énergie chimique ; des pertes sous forme de chaleur sont responsables de la chute de rendement. Pour la pile à combustible (PAC) l’efficacité du processus de combinaison du dihydrogène et du dioxygène en eau n’est également pas de 100%. Des pertes de plus de 50% sous forme de chaleur peuvent être enregistrées  L’efficacité d’un système combinant l’électrolyse de l’eau et la pile à combustible n’est pas supérieure à 30-50% selon les conditions. 2.7.1.1	Hydrogène décarboné : un rêve loin de devenir réalité, selon France stratégie  France Stratégie n'envisage pas un développement à court terme du vecteur hydrogène. Les experts chargés de conseiller Matignon proposent d'abandonner le financement des projets intégrés au profit de la R&D sur l'électrolyse et les PAC.  L'hydrogène a "une aura exceptionnelle", estime France stratégie, le service d'analyse rattaché au Premier ministre, car "il est perçu comme « propre » et comme pouvant remplacer les hydrocarbures à terme".  2.7.1.1.1	Très cher hydrogène  Parmi les freins, France Stratégie retient surtout son coût de production décarbonée. En effet, il faut avant tout commencer par dépenser de l'énergie pour produire de l'hydrogène. Pour rendre compétitif l'hydrogène décarboné, il faudrait qu'au minimum le prix du gaz quintuple et que le prix de l'électricité reste stable. Des projets de stockage hors de toute rentabilité  Malgré ce frein économique, les initiatives en faveur de l'hydrogène fleurissent. Mais, France Stratégie se montre dubitatif, pour ne pas dire très pessimiste, à court et moyen termes. 2.7.1.1.2	Doubler le prix des carburants classiques  Alors que "l'acceptation sociale de l'hydrogène dépend de la confiance du public en sa sûreté", rappelle France Stratégie, "sur le plan de la sécurité « grand public », les obstacles semblent difficilement surmontables. Quand bien même l'hydrogène serait largement distribué, quelques accidents pourraient retarder ou même mettre en cause l'émergence de la filière", estime la note. L'exemple du gaz de pétrole liquéfié (GPL) a été retenu.   Autre écueil, le stockage qui lui aussi coûte très cher. Pour obtenir une autonomie comparable à celle offerte par le pétrole, il faut installer un réservoir de 150 litres, pesant 100 kg et pressurisé à 700 bars. "Un tel réservoir coûte 2.000 euros. 2.7.1.2	MYRTE : sous le soleil, le contribuable  MYRTE (Mission hYdrogène Renouvelable pour l’inTégration au réseau Électrique) est le joli nom donné à une centrale électrique photovoltaïque dont la production solaire, par nature erratique (nuits, nuages), est modulée par une transformation en hydrogène et en oxygène temporairement stockés. Ces deux éléments sont ensuite recombinés dans une pile à combustible (PAC) pour produire de l’électricité suivant le besoin du réseau en Corse. Le prix de vente de l’électricité sur le marché national se négocie généralement autour de 4 c€/kWh. La loi oblige EDF à vendre un quart de sa production nucléaire à 4,2 c€/kWh à ses concurrents. Or, les 24 millions d’euros engloutis jusqu’à présent dans cette « plateforme MYRTE » conduisent à produire une électricité coûtant environ… 220 c€/kWh ! Ce coût de production représente… plus de 50 fois le prix du marché actuel ou celui de l’électricité vendue par EDF à ses concurrents ! MYRTE est une expérience peu probante de stockage d’électricité par hydrogène dont les aspects techniques sont déjà connus. Elle ne représente pas non plus l’avenir de la production d’électricité, tant que les coûts de stockage massif de cette énergie resteront prohibitifs.  2.7.1.3	Comment utiliser l’hydrogène ? Les propriétés physiques de l’H2 en font un gaz encombrant. À la pression atmosphérique, 3000 litres d’H2 contiennent l’équivalent en énergie d’un litre d’essence (9 kWh). On comprime donc généralement l’H2 à 200 fois la pression atmosphérique (200 bars), ou à 700 bars, ou on le liquéfie, ce qui consomme de plus en plus d’énergie à chaque étape. Il ne faut alors plus que 7 litres d’H2 à 700 bars ou 4 litres d’H2 liquide (à - 253°C dans un contenant isolant et volumineux) pour disposer de l’équivalent énergétique d’un litre d’essence. L’hydrogène liquide est difficile à conserver dans des voitures particulières (fuites). Par rapport à l’essence, pour parcourir 600 km, aujourd’hui le meilleur compromis est le réservoir d’hydrogène sous pression à 700 bars qui est près de dix fois plus gros que le réservoir d’essence (400 litres au lieu de 42 litres) et six fois plus lourd (240 kg au lieu de 40 kg). À partir de l’électricité initiale, il y a une perte de 50 % d’énergie pour obtenir de l’H2 sous pression à 700 bars et jusqu’à 60% pour obtenir de l’H2 liquide. Puis, au minimum, une nouvelle perte de 50% intervient pour transformer l’H2 en électricité dans une PAC. Le rendement global en y incluant les pertes diverses (transport, stockage,…) est donc de moins de 25%. L’usage énergétique de l’H2 est actuellement quasiment inexistant au niveau mondial parce qu’il est difficile à manier, conditionner, transporter, stocker… ce qui le rend peu pratique à utiliser et très coûteux à exploiter. 2.7.1.4	Quel avenir pour les véhicules à pile à combustible (à hydrogène) ?  2.7.1.4.1	Une recherche active pour combler les défauts de la pile à combustible  L’inconvénient numéro un est lié à la dangerosité de l’hydrogène, un gaz volatil et hautement explosif. Aujourd’hui le transport et le stockage sont sécurisés et aucun accident n’a eu lieu depuis que cette technologie est appliquée à des véhicules, mais certaines voix soulignent que faire rouler des véhicules pouvant se transformer aussi facilement en bombe présente des risques, ne serait-ce que vis-à-vis du terrorisme. 2.7.1.4.2	Des véhicules contraignants, trop chers, à la durée de vie réduite  La réaction chimique de la pile à combustible utilise actuellement du platine, un métal noble, aussi cher que l’or. La technologie demeure complexe et chère, si bien que le prix d’une voiture particulière à hydrogène approche aujourd’hui les 80 000 euros. Autre soucis, la durée de vie d’une pile à combustible est réduite, à peine plus de 4 000 heures, ce qui nécessite de la remplacer après environ 150 000 kilomètres, pour un coût extrêmement élevé, et de réduire l’impact des phénomènes physiques et chimiques qui altère la membrane utilisée par la pile. 2.7.1.5	Risque hydrogène  L’hydrogène est le plus léger des gaz. A l’état liquide ou gazeux, l’H2 est particulièrement sujet aux fuites à cause de sa basse viscosité et de sa faible masse moléculaire. Le risque principal lié à l’hydrogène est celui de l’incendie ou de l’explosion, du fait de son domaine d’inflammabilité très large (de 4 à 75 % dans l’air, plus large encore dans des atmosphères enrichies en oxygène ou en chlore), ainsi que de sa très faible énergie d’activation. Les sources d’ignition des nuages inflammables formés par l’hydrogène sont multiples dans l’accidentologie : point chaud, foudre, origine électrique et étincelle mécanique ou encore électricité statique.  Le vecteur hydrogène sera peut être développé dans quelques décennies, mais son cout de production exorbitant et sa propension à exploser au contact de l’air le rendent inadapté pour un stockage massif d’électricité ou pour son utilisation dans des piles à combustible. 2.8	Les dessous peu ragoutants de la transition énergétique : jaune devant, Macron derrière… « La transition énergétique a bon dos ! » ; « On se moque de nous ! ». Les gilets jaunes voient rouge à cause des verts… Les Français en colère se dressent désespérément devant les taxes servant à alimenter la transition énergétique, et le Président Macron pousse derrière pour développer de ruineuses énergies renouvelables. Le gouvernement s’abrite derrière la loi de transition énergétique pour la croissance verte (LTECV) d’août 2015 et le respect de l’accord de Paris (pour lancer des mesures censées diminuer nos rejets de CO2. Une « stratégie énergétique » a été définie jusqu’en 2028 par l’annonce récente de la Programmation Pluriannuelle de l’énergie.  Cette « stratégie » inclut notamment la diminution des véhicules diesels au profit des véhicules essence. 2.8.1	 Pourquoi s’acharner ainsi sur le diesel ?  Quel est le rapport avec les émissions de CO2 ? La raison cachée est peut-être simple : la fiscalité dite « écologique » est indexée sur les émissions de CO2. L’achat des véhicules les plus émetteurs de ce gaz doit donc être encouragé pour augmenter les rentrées fiscales. Le rendement thermique du diesel est bien meilleur que celui d’un moteur à essence, un diesel émet 20 à 25% de moins de CO2 par km parcouru. Quant aux « particules fines, les véhicules diesels sont équipés d’un filtre à particules obligatoire depuis 2011. et ils émettent dorénavant 10 fois moins de particules qu’un moteur à essence ! 2.8.2	Le gouvernement raisonne donc à l’envers pour « sauver la planète »  Augmenter les taxes sur les carburants pour sauver la planète Le raisonnement qui a été employé pour lutter contre l’usage du tabac n’est pas pertinent pour les carburants. Les consommateurs sont généralement contraints de se déplacer. Restreindre leurs déplacements par l’argent touche à leur liberté fondamentale ! Pour la majorité d’entre eux, c’est une nécessité vitale. Tous les citoyens vont payer leurs déplacements plus chers au bénéfice d’un État dispendieux, notamment pour subventionner les énergies renouvelables inutiles, fatales et intermittentes. 2.8.3	PPE et respect des accords de Paris La France, en se dotant d’un parc conséquent de réacteurs nucléaires, a non seulement bénéficié d’une électricité bon marché mais elle est aussi l’un des meilleurs élèves concernant les émissions de CO2 au niveau mondial. Or, pour des raisons « bassement » électorales, les « Verts » jouent un rôle néfaste en incitant le gouvernement à envisager l’arrêt de 14 réacteurs nucléaires en 2035 pour les remplacer hypothétiquement par des énergies intermittentes et non fiables : l’éolien et le solaire. Si notre électricité est encore aujourd’hui l’une des moins chères d’Europe, le coût du kWh a doublé depuis les années 2000 en raison des taxes. La plus importante (CSPE = 2,25 c€/kWh) sert essentiellement à financer le coût élevé du recours aux énergies intermittentes. Or, elles sont censées remplacer les réacteurs nucléaires qui doivent être fermés par la volonté gouvernementale. De plus, l’intermittence de l’éolien et du photovoltaïque nécessite l’adjonction de centrales pilotables à gaz. Un Français rejetait 5,75 tonnes de CO2 par an en 2010, 7 tonnes en 2015, et 7,4 tonnes en 2017. Puisque le Président Macron a annoncé vouloir tripler la production éolienne et multiplier par cinq les capacités solaires, la situation ne va pas s’améliorer… 2.8.4	Une politique de gribouille Les subventions à l’éolien et au photovoltaïque coûtent chaque année à la France 2 réacteurs EPR. Il est à noter que les investissements dans les EPR dureront au moins 60 ans, alors qu’il faudra renouveler dans 20 ans les éoliennes, et dans 10 à 15 ans les panneaux solaires. Cet « oubli » de la durée de vie est la supercherie qui permet de prétendre que ces sources d’énergies renouvelables seraient compétitives. 2.8.5	Les conséquences Les conséquences de cette PPE pour notre pays peuvent se résumer ainsi : plus de rejets de CO2, et un coût plus élevé de l’énergie (électricité, carburants, fioul,…). Ce résultat prévisible ne va pas dans le sens des demandes actuelles de l’opinion en faveur du pouvoir d’achat… De plus, l’accroissement considérable des énergies intermittentes dans notre pays déstabilisera le réseau d’électricité et pourrait entrainer… de catastrophiques coupures de courant intempestives ! Voilà les dessous peu ragoutants de la transition énergétique votée par le Parlement en 2015 ! Alors les gilets jaunes ont quelques raisons de s’alarmer devant ces gabegies qui amputent leur pouvoir d’achat tandis que le Président Macron, certainement bien conseillé, pousse derrière… La politique conduite lors des quinquennats précédent et actuel est ubuesque et dangereuse pour l’avenir du pays, Il faut développer l’énergie nucléaire et la substituer au maximum aux énergies carbonées le plus tôt possible, les efforts sur les énergies renouvelables ne sont intéressants à partir d’un certain stade que si on a les moyens de stocker à des prix raisonnables. 2.9	La consommation d’énergie devra baisser 2.9.1	La situation actuelle La consommation d’énergie s’est stabilisée en France et en Europe depuis la crise commencée en 2008 mais elle continue d’augmenter au niveau mondial. Plus de 80% de cette énergie étant d’origine fossile, la question se pose de savoir combien de temps encore ces ressources limitées pourront satisfaire la demande. La production de ces énergies devrait passer dans les années à venir par un pic ou un plateau avant de décroitre. Il est clair que le pétrole manquera d’abord au cours du 21ème siècle, suivi par le gaz. Les réserves de charbon sont plus importantes, le charbon pourrait ne manquer qu’au 22èmesiècle. Le charbon, première source d’énergie au monde pour la production d’électricité, devrait, d’après l’Agence Internationale de l’Energie, devenir la première source d’énergie au monde tous usages confondus en 2015. C’est pourtant la plus polluante et la plus émettrice de gaz à effet de serre des sources d’énergie. L'extraction du charbon et la pollution due à sa combustion font des centaines de milliers de morts chaque année. Dans le cadre de la lutte contre le réchauffement climatique s’est engagée à diviser par quatre ses émissions à l’horizon 2050. La raréfaction à venir du pétrole et du gaz, et l’engagement de réduire les émissions de gaz à effet de serre impliquent une forte baisse de la consommation d’énergie fossile. La manière d'y parvenir a largement été étudiée par plusieurs scénarios. 2.9.2	Quelques scénarios de transition énergétique Plusieurs associations et organismes ont élaboré pour la France des scénarios de transition énergétique. En voici un aperçu : 2.9.2.1	Négawatt  Le scénario Négawatt (Négawatt, 2011) est sans doute le plus connu. Il préconise que 90% de nos besoins soient assurés en 2050 par les énergies renouvelables essentiellement grâce à une meilleure exploitation de la biomasse, de l’éolien et du photovoltaïque. Un recours accru au gaz serait temporaire afin de fermer progressivement la totalité des réacteurs nucléaires (personnellement je crains que ce temporaire dure...). En 2050 les énergies fossiles ne représenteraient plus que 10% des besoins. Un tel scénario supposerait des efforts considérables, notamment dans l’éolien qui devrait fournir 209 TWh en 2050 contre 15 TWh en 2012, les problèmes d’intermittence étant réglés par la production d’hydrogène et de méthane. Quand on sait que le potentiel éolien français est estimé à 160 TWh par l’ADEME, connaissant les difficultés du stockage par hydrogène, on mesure une partie de l’optimisme de ce scénario quant à la production des énergies renouvelables. En parallèle de ces investissements considérables, il faudrait en particulier selon Négawatt réduire la demande en énergie primaire de 66% alors que la population augmenterait de 15%. Cette réduction devrait venir de l’efficacité et de la sobriété énergétique. L’efficacité consiste à améliorer les techniques pour rendre les mêmes services en consommant moins. La sobriété consiste selon Négawatt à privilégier les usages les plus utiles, « restreindre les plus extravagants et supprimer les plus nuisibles » ; de beaux débats en perspective pour juger ce qui est utile ou nuisible... 2.9.2.2	Greenpeace  (Greenpeace, 2013), propose un scénario assez proche dans lequel, en 2050, la demande d’énergie primaire diminuerait de 63% et celle d’énergie finale de 52%. Les énergies renouvelables produiraient alors 92% des besoins, le nucléaire aurait disparu. La réduction de nos besoins proviendrait de transports plus efficaces, d’une baisse des distances parcourues, de l’isolation des logements, d’appareils plus efficaces... 2.9.2.3	Virage Energie L’association Virage Energie, propose pour diminuer la consommation : des lave-linge collectifs, une baisse des équipements électroménagers (moins de lave-vaisselles, de congélateurs, d’ordinateurs...), une baisse de l’utilisation des cosmétiques, de la consommation de vêtements, du tourisme de longue distance... On peut se demander si les changements préconisés par les 3 scénarios précédents sont compatibles avec la démocratie, les changements nécessaires impliquent en effet une baisse de niveau de vie si importante qu’il est probable qu’il faille les imposer par la force. 2.9.2.4	La troisième révolution industrielle La troisième révolution industrielle est une théorie de l’économiste américain Jeremy Rifkin. Elle repose sur les énergies renouvelables, les bâtiments producteurs d’énergie, le stockage d’énergie dans les bâtiments, les échanges d’énergie via un réseau intelligent et les véhicules électriques. Ce scénario, qui n’a décidément peur de rien, est également le seul à prétendre qu’on puisse atteindre 100% d’énergie renouvelable en 2050, mais aucun détail technique ne précise par quel miracle. 2.9.2.5	Agence de l’Environnement et de la Maitrise de l’Energie  L’ADEME, 2013), préconise dans son scénario "médian", pour diviser par 4 les rejets de gaz à effet de serre en 2050, une baisse de 47% de la consommation d’énergie finale. Les énergies renouvelables fourniraient alors 55 % des besoins, le reste étant assuré par le pétrole, le gaz et le nucléaire.  2.9.2.6	Agence Nationale pour la Coordination de la Recherche pour l'Energie  L'Agence Nationale pour la Coordination de la Recherche pour l'Energie (ANCRE) qui coordonne des organismes publics nationaux de recherche, a publié 3 scénarios permettant de diviser par 4 les rejets de CO2 : tout en développant largement les énergies renouvelables et sans sortir du nucléaire, les baisses de consommation d'énergie finale iraient de 27 à 41 % grâce à des efforts soutenus d'efficacité énergétique. L’ANCRE souligne que le facteur 4 ne pourra être atteint qu'avec des efforts importants et le recours à des technologies de rupture (stockage du CO2, stockage électrique, cogénération nucléaire..). Le scénario Negatep prévoit une division par 4 des rejets de CO2 malgré une baisse de seulement 18 % de la consommation d'énergie finale. Les énergies fossiles seraient très largement remplacées par les énergies renouvelables (+ 150%) et nucléaire (+ 46%) capables de produire de l'électricité décarbonée dont la production augmenterait de 61%. Ce scénario préconise donc d’augmenter le rôle de l’électricité puisqu’elle peut être produite sans émissions de CO2, en particulier avec le nucléaire. On constate qu'aucun scénario ne prétend qu'il soit possible de remplacer les énergies fossiles et nucléaires par des renouvelables sans diminuer beaucoup la consommation. Au regard des différents scénarios, il semble que le potentiel de production des énergies renouvelables soit, avec les technologies actuelles, d’environ 40 % de la consommation d’énergie française. Tous les scénarios préconisent une baisse non négligeable de la consommation d'énergie malgré une hausse de la population. Ils reposent en grande partie sur l'efficacité énergétique dont l'importance est donc cruciale. 2.9.3	Baisser la consommation d’énergie sera très compliqué Les 2 leviers permettant de diminuer la consommation sont l’efficacité et la sobriété énergétique. 2.9.3.1	Les limites physiques de l’efficacité Pour réduire le besoin d’énergie, le levier « efficacité » fait l’unanimité puisqu’il s’agir de consommer moins à service rendu égal grâce à la technologie. Il convient toutefois de rappeler qu’il existe des limites physiques à l’efficacité. Les lois de la physique impliquent la conservation de l'énergie. Cela signifie que la quantité d'énergie qui sort d'un système est forcément égale à la quantité qui y rentre. On ne peut donc que transformer l'énergie et non en créer. Si l'efficacité énergétique est utile et indispensable, elle ne sera pas suffisante. Pour réellement baisser la consommation d'énergie, il est nécessaire de modifier l'usage que l'on fait des appareils consommateurs. 2.9.3.2	Sobriété énergétique, problèmes et conséquences La sobriété énergétique qui consiste à privilégier les usages les plus utiles de l’énergie, « restreindre les plus extravagants et supprimer les plus nuisibles » (Négawatt, 2011), suppose de définir quels sont les usages utiles et les nuisibles. Est-il "utile" d’aller une journée à la mer, de partir en vacances, d'assister à des spectacles culturels ou des rencontres sportives ? Il est clair que tout le monde ne sera pas du même avis. 2.9.3.3	Conclusion, perspectives Aucun scénario de transition énergétique ne prétend qu’il soit possible de remplacer les énergies fossiles et nucléaires par les énergies renouvelables. Tous les scénarios font appel à une réduction importante de la consommation d’énergie. Le levier de l’efficacité énergétique fait l’unanimité puisqu’il s’agit de consommer moins à service rendu égal. Les lois physiques incontournables et l’histoire récente des évolutions technologiques montrent que ce levier nécessaire sera insuffisant. La sobriété énergétique est beaucoup plus complexe à développer car elle implique des changements considérables de modes de vie et d’organisation de la société. Moins d’énergie signifie moins de transports, moins de machines et moins de chaleur, donc probablement plus de travail, de tâches ingrates, moins de confort, de nourriture, de logements, de soins médicaux, voire de culture, d’éducation et de développement. Certes des innovations technologiques pourraient voir le jour et modifier la donne. Mais elles ne changeront pas les limites physiques et, à l’heure actuelle, on ne perçoit pas quelle technologie miraculeuse pourrait être prête suffisamment rapidement. Il y a urgence ! Trois possibilités s’offrent aux politiques : - manquer d’énergie. Cela nécessite une réorganisation complète de la société qui sera bien difficile à faire accepter à la population. Il paraît peu probable que des politiques puissent être élus démocratiquement en préconisant la sobriété.  - continuer à exploiter les énergies fossiles puisque les ressources existent, donc amplifier la pollution et le réchauffement climatique avec des conséquences telles que famines, inondations, tempêtes... - développer le nucléaire. Les inconvénients du nucléaire sont très médiatisés et font souvent plus peur que ceux du manque d’énergie ou des énergies fossiles. Pourtant, au regard des inconvénients des deux premières possibilités, le rapport bénéfice/risque lui est clairement favorable.  2.10	Transition énergétique : un observatoire pour vérifier l'atteinte des objectifs  2.10.1	Les retards s'accumulent: Selon l'Observatoire, la France n'a pas ou peu progressé. Elle a même parfois régressé. Sur les neuf principaux indicateurs, un seul est dans le vert : les émissions de gaz à effet de serre (GES) du secteur industriel sont inférieures de 0,8% au plafond fixé par le budget carbone français. Pour le reste, tous les plafonds d'émissions de CO2 inscrits dans la SNBC sont dépassés en 2017 : le plafond d'émissions de GES nationales est dépassé de 6,7%, celui de l'agriculture de 3,2%, celui du transport de 10,6% et celui du bâtiment de 22,7%... Le constat est similaire pour les objectifs de la PPE. En 2017, la consommation d'énergie s'écarte de 4,2% de la trajectoire menant à l'objectif de baisse de 7% entre 2012 et 2018 et la consommation d'énergie fossile dépasse de 4,5% le point de passage pour atteindre une baisse de 30% entre 2012 et 2030. Le retard par rapport au chemin menant à 23% d'énergies renouvelables en 2020 était de 12,8% en 2016.  2.11	La France bat son record d'exportation d'électricité (26 février 2019) Des dizaines de milliers de mégawatts ont été acheminés vers l'Italie et l'Espagne, où la production éolienne a été ralentie par les conditions anticycloniques. Vendredi en milieu d'après-midi, sous la double impulsion d'une météo très clémente pour la saison et d'un parc de production en ordre de marche pour passer l'hiver, la France a exporté de l'électricité comme jamais: une pointe de 17.415 mégawatts (MW) (environ le quart de la consommation instantanée en France) a été acheminée en priorité vers l'Italie et l'Espagne, selon les données communiquées par Réseau de transport d'électricité (RTE). Dans ces deux pays, les conditions anticycloniques ont considérablement ralenti la production éolienne. Pour compenser ce manque, et plutôt que de lancer leurs centrales thermiques, nos deux voisins ibérique et transalpin ont préféré se tourner vers la France et son électricité nucléaire meilleur marché.  Le levier de l’efficacité énergétique fait l’unanimité puisqu’il s’agit de consommer moins à service rendu égal, la sobriété énergétique est beaucoup plus complexe à développer car elle implique des changements considérables de modes de vie et d’organisation de la société. Parmi les différentes possibilités évoquées, celle prônant un développement du nucléaire est la plus réaliste, encore faut-il que le Président de la République ainsi que les ministres de la transition énergétique en soient convaincus. 3	La transition énergétique en Europe  3.1	La transition énergétique en Allemagne 3.1.1	Où en est l’Allemagne ? En 2011, l’Allemagne a décidé d’arrêter progressivement ses réacteurs nucléaires et de compenser la production d’électricité avec des énergies renouvelables. Jean-Marc Jancovici en analyse les conséquences : En chiffres ronds, de 1995 à 2014, l'Allemagne a investi 350 milliards d'euros dans des éoliennes, panneaux solaires, méthaniseurs et modifications du réseau électrique, pour faire passer de 4 à 26 % la part de sa production électrique provenant de sources renouvelables. 350 milliards, c'est plus que le coût de la reconstruction à neuf de la totalité du parc nucléaire fiançais, ou celui de la reconstruction - à neuf aussi - de l'ensemble du réseau ferré fiançais, ou encore l'investissement à consentir pour remplacer plus de la moitié des voitures françaises par des véhicules consommant 2 litres aux 100.  Or les chiffres nous disent que cet investissement n'a pas changé d'un iota l'évolution des émissions de CO2 de l'Allemagne, ni sa dépendance à l'énergie fossile importée. L'afflux massif d'électricité non pilotable combiné à la libéralisation du marché européen de l'électricité a créé un vaste bazar dans le monde de l'électricité, rendant plus compliquée que jamais la planification à long terme du système.  Comment expliquer le décalage en ce qui concerne cette Energiewende (« transition énergétique ») ?. La première chose qui est assurément une réalité outre-Rhin, c'est que la production d'électricité renouvelable a fortement augmenté depuis le début de la transition allemande, qui ne date pas de Fukushima, mais a démarré dans les années 1990. De 20 milliards de kilowattheures électriques renouvelables produits en 1996 (soit 4 % de la production allemande), essentiellement à partir de barrages, l'Allemagne est passée à un peu plus de 150 en 2014, dont environ 24 d'hydroélectricité, 55 d'éolien, 35 de solaire, et 35 à partir de méthaniseurs. Pour arriver à ce résultat, les Allemands ont installé, à fin 2014, une puissance de 38 gigawatts en solaire, 40 en éolien, de l'ordre de 9 en biogaz, et un peu plus de 4 en hydraulique, l'ensemble représentant donc plus de 90 gigawatts. Rappelons que la capacité nucléaire française est de l'ordre de 65 gigawatts. Mais les 65 gigawatts de nucléaire gaulois produisent un peu plus de 400 térawattheures d'électricité dans l'année, quand les 90 gigawatts de renouvelables teutons ne produisent « que » 150 térawattheures d'électricité sur la même durée. Par gigawatt installé, le nucléaire produit donc environ 4 fois plus que les renouvelables installées chez nos voisins. Aux États-Unis, les réacteurs nucléaires ont un facteur de charge de 90 % environ, car ils tournent toute l'année, les seuls arrêts étant ceux pour maintenance. En France, ces mêmes réacteurs sont plus proches de 70 à 75 %, car une partie de leur puissance ne sert que l'hiver, quand la consommation d'électricité augmente. Quand on passe aux renouvelables installées en Allemagne, ce facteur de charge baisse énormément : pour l'éolien, il varie entre 15 et 20 %, selon les années. Pour le solaire, ce facteur dépend beaucoup de la latitude : il double quasiment du nord au sud de l'Europe (il est légèrement inférieur à 10 % en Allemagne). Enfin pour le biogaz, qui produit tant que les méthaniseurs sont alimentés, le facteur de charge est plus proche de 60 %. Mais, comme le solaire et l'éolien dominent largement dans les capacités nouvelles en Allemagne, la moyenne pour l'ensemble du parc renouvelable est descendue de 40 à 20 % entre 1996 et 2014. Même avec un mauvais facteur de charge, la production renouvelable a fortement augmenté chez nos voisins. On devrait donc s'attendre à ce que la production faite avec le reste ait baissé, et en particulier la production à base de combustibles fossiles (gaz et charbon), puisque le développement des renouvelables est vu comme un moyen de faire baisser les émissions de CO2. Il n’en est rien Une première explication de ce paradoxe est qu'une bonne partie de la hausse des renouvelables est venue en plus de la production préexistante, et n'a donc rien substitué du tout. Entre 1995 et 2014, la production électrique allemande a ainsi augmenté d'environ 160 térawattheures, et cette hausse vient en totalité de l'accroissement du parc renouvelable. La deuxième raison qui explique la constance de la production fossile allemande est que, après être venu « en plus du reste » de 1995 à 2005, depuis 2005 la production allemande renouvelable supplémentaire a servi à baisser le nucléaire. Dans le contexte allemand, la baisse du nucléaire a donc été considérée comme prioritaire sur la baisse du charbon. L'histoire devra juger pourquoi nos voisins ont préféré diminuer le recours à une énergie qui présente des risques qui restent minimes et localisés, au profit d'une énergie qui, via ses émissions de CO2, contribue à la croissance des sécheresses et des inondations, au stress alimentaire, à la montée du niveau de l’océan et ses multiples conséquences sur les infrastructures de bord de mer, à la propagation des maladies, à l’augmentation de l’intensité des phénomènes extrêmes, sans même parler de la destruction directe d’écosystèmes causée par l’ouverture et l’extension des mines de lignite, de la pollution aux particules fines causée par les centrales à charbon, et des accidents dans les mines. 3.1.2	Extraction massive de charbon et de lignite En Rhénanie-du-Nord-Westphalie, non loin de Cologne, de titanesques mines à ciel ouvert dévorent le paysage. Champs, villages, autoroutes sont engloutis afin de satisfaire l’appétit des centrales électriques allemandes pour un médiocre charbon : le lignite. La plus vaste mine, celle de Garzweiler, est devenue synonyme de drame de l’expropriation, de destruction de terres agricoles, de pollution aux métaux lourds. Quant au lignite, il est une des causes majeures des pluies acides et des gaz à effet de serre… Les écologistes démontrent l’absence de pragmatisme de leur politique énergétique, ils privilégient l’arrêt des réacteurs nucléaires plutôt que l’arrêt de l’exploitation du lignite et voudraient en 2030 se passer du lignite, pour pallier le caractère intermittent des énergies renouvelables, il ne restera qu’un recours accru au charbon ou l’importation d’électricité éventuellement nucléaire !  3.1.3	La transition énergétique en Allemagne est un échec. Qui osera le dire ?  La transition énergétique en Allemagne est un échec économique et environnemental. Elle est aussi une menace pour le réseau européen d’électricité. Pas de vent, pas de soleil, pas d’électricité. Les Allemands semblent redécouvrir cette évidence dans la douleur. L’Agence Internationale des Energies Renouvelables (IRENA) affiche pour 2016 des parts respectives de l’électricité éolienne et solaire dans la production totale d’électricité du monde entier de 4,15 % et 1,2 %. Le fait que 13% des puissances électriques affichées ne produisent que 5.35 % de l’électricité tient bien sûr au caractère intermittent (et souvent aléatoire) des énergies renouvelables. L’étude de la situation en Allemagne, parfois présentée comme un modèle de vertu écologique, avec 20,1 % de part d’électricité solaire et éolienne (contre 5,5 % en France) est instructive. Les gigantesques investissements réalisés auraient dû conduire à une baisse de ses émissions globales de gaz à effet de serre. Or celles relevant de l’énergie (pas seulement de l’électricité) ont au contraire augmenté de 0.7 % de 2014 à 2015, et de 0.9 % de 2015 à 2016 ! L’objectif affiché de 18 % d’énergies renouvelables en 2020 ne sera pas tenu (il n’est passé de 14.5 % en 2015 qu’à 14.6 % en 2016 !). 3.1.4	Quand l'Allemagne importe son électricité de France  Si on étudie les échanges commerciaux tels que compilés par l'ENSTO-E (le réseau des opérateurs qui donne les statistiques pour la zone Europe de l'Ouest-Centre), on trouve que la France est exportatrice vers l'Allemagne de 10 TWh annuels. La raison principale de cette situation est à rechercher du côté de l'intermittence des productions renouvelables: quand le soleil brille, l'Allemagne voit sa production photovoltaïque monter de plus de 20 GW, et il faut pouvoir l'envoyer chez les voisins et quand le vent s'arrête, c'est l'Allemagne du Nord qui appelle de la puissance à travers la Hollande et la Belgique.  En matière d'émissions de CO2, c'est la France qui exporte son électricité "décarbonée" vers l'Allemagne. Rappelons que l'électricité produite en France émet environ 50 kg de CO2 par MWh alors que l'Allemagne émet près de dix fois plus. 3.1.5	Energies renouvelables : cette couleur « verte » qui ne veut rien dire  Si l’Union européenne voulait vraiment protéger le climat en réduisant les émissions de CO2, elle fixerait des objectifs sans imposer des moyens et des technologies.  Le temps est peut-être venu d’envisager des modifications dans la politique énergétique européenne et de remplacer le terme « énergie renouvelable » par « énergie propre » comme les États-Unis, l’Inde et la Chine. 3.1.5.1	Énergie renouvelable, charbon et nucléaire  L’Allemagne est à l’avant-garde du développement des sources d’énergie renouvelable intermittente (EnRI), en particulier éolien et solaire, mais ses émissions pour la production d’électricité sont 10 fois plus élevées par habitant que celles de la France qui utilise le nucléaire pour produire 75 % de son électricité. En 20 ans, la Pologne, dont l’essentiel de l’électricité est produite avec du charbon, a presque autant réduit ses émissions de CO2 que l’Allemagne, dont le total des investissements dans les énergies renouvelables a dépassé 250 milliards d’euros… Comment est-ce possible ? La réponse est simple : le développement de sources d’énergie intermittente ne réduit plus les émissions de CO2 lorsque leur production atteint un point de saturation dans le mix énergétique. Surfant sur la vague de l’idéologie verte anti-nucléaire, la France s’est pourtant engagée à réduire la part de l’énergie nucléaire à 50 % dans son mix électrique, tout en affirmant que la réduction des émissions de CO2 était primordiale. Néanmoins, probablement pour apaiser le lobby éolien, le président Macron a approuvé la construction de parcs éoliens en mer, avec un prix garanti trois à cinq fois plus élevé que celui de l’énergie nucléaire.  3.1.5.2	Le Saint Graal du stockage  L’électricité produite par les EnRI doit être utilisée immédiatement car les possibilités de stockage sont négligeables de production quand le vent ne souffle pas et quand le soleil brille peu à travers l’Europe, pendant plusieurs jours, voire plusieurs semaines. Mais il n’existe pas et rien ne permet de penser aujourd’hui qu’il existera un jour… Le réseau ne peut donc pas être alimenté uniquement à partir d’énergies renouvelables sans l’approvisionnement de sources stables et pilotables alimentées par des énergies fossiles ou par… du nucléaire. Et dans le cas de l’Allemagne, ces sources sont principalement des centrales au lignite, les plus gros émetteurs de CO2. Et pour les alimenter, l’Allemagne creuse de nouvelles mines de lignite à ciel ouvert… Elle reporte la fermeture de ses centrales au charbon et construit le gazoduc géant Nord Stream 2 avec la Russie. Le gaz reste la seule possibilité de réduction de ses émissions si elle ferme ses centrales nucléaires et… au charbon/lignite. Voilà pourquoi l’Allemagne est si déterminée à mener à bien le second tronçon du gazoduc Nord Stream. 3.2	La transition énergétique en Belgique  De nationalité belge, titulaire d'un Master en ingénierie électrique et mécanique, diplômé en physique et chimie nucléaire et bachelier en économie de l'Université de Louvain (Belgique), Jean-Pierre Schaeken Willemaers est président du Pôle énergie, climat, environnement de l’Institut Thomas More, évoque « L’utopie du tout renouvelable. » Alors que les centrales nucléaires n’émettent pas plus, voire moins, de gaz à effet de serre (GES) que la production éolienne ou photovoltaïque sur un cycle complet de vie et que, d’autre part, la roadmap 2050 de la Commission européenne prévoit toujours, à cette échéance, du nucléaire dans le parc électrique européen, le gouvernement belge a décidé, de sortir de cette forme de génération d’électricité entre 2022 et 2025. Les conséquences néfastes d’un mix électrique sans nucléaire, si cette décision était maintenue, viendraient s’ajouter aux dysfonctionnements causés par la priorité d’accès aux réseaux électriques concédée au renouvelable intermittent ainsi qu’aux subventions généreuses et autres avantages qui leur ont été accordés. La sortie totale du nucléaire ne se justifie ni par des raisons technique ou économique, ni d’un point de vue politique. 3.2.1	Quelle est la logique ?  D’autre part, sans capacité nucléaire, l’importation d’électricité va augmenter, soit en provenance de la France (essentiellement nucléaire) ou de l’Allemagne (principalement à partir de charbon et de lignite), donc des modes de production dont le gouvernement belge ne veut plus. Quelle est dès lors la logique qui sous-tend la dénucléarisation de la génération d’électricité? La sortie du nucléaire n’est pas non plus pertinente d’un point de vue économique. La pénétration croissante de l’éolien et du photovoltaïque et la fermeture des centrales nucléaires entraînent un gonflement du prix de l’électricité et partant une diminution de la compétitivité des entreprises et du pouvoir d’achat des ménages ainsi que de la sécurité d’approvisionnement électrique. Cette forte augmentation du prix de l’électricité résulte d’un certain nombre de facteurs dont: - le coût de la construction de nouvelles centrales au gaz (indispensables pour assurer l’équilibre du système) qui est nettement plus élevé que celui de la prolongation de la durée de vie des unités nucléaires; - de la rémunération de capacité nécessaire à convaincre les producteurs d’électricité d’investir dans de nouvelles centrales au gaz. En effet, celles-ci sont très loin d’être rentables si elles ne sont destinées qu’à compenser l’intermittence de l’éolien et du photovoltaïque jouissant d’une priorité d’accès au réseau; - du coût de stockage d’électricité essentiel pour mitiger les fluctuations de la génération renouvelable au-delà d’un certain niveau de pénétration - du coût de renforcement et d’extension des infrastructures de transmission et de distribution d’électricité requis, entre autres, par la dispersion de la production renouvelable; - et, bien entendu, des subventions accordées au renouvelable. La fermeture de toutes les centrales nucléaires n’est pas justifiée d’un point de vue technique. Des analyses approfondies réalisées dans le cadre des stress tests (BEST) sur toutes les unités nucléaires belges, sous la supervision de l’Agence Fédérale de Contrôle Nucléaire (AFCN), organisme indépendant, ont confirmé que ces dernières ainsi, d’ailleurs, que les bâtiments de stockage du combustible usé, sont conformes à toutes les réglementations nationales et internationales applicables, en ce compris, bien entendu, celles de sûreté. 3.3	La fermeture de tout réacteur nucléaire jugé sûr serait irresponsable  Les tensions annoncées sur les hydrocarbures, leurs émissions de CO2, la sécurité et l'indépendance énergétique, ainsi que le rôle stratégique qui s'offre à l'électricité sont autant d'éléments qui plaident pour s'interdire toute fermeture de réacteur jugé sûr par l'ASN.  Les efforts concernant l'efficacité énergétique peinent à compenser des besoins en progression constante. La consommation finale d'énergie de 2017 marque encore une augmentation de 0,9% sur celle de 2016. Depuis la « chasse au Gaspi » des années 1970 la consommation nationale d'électricité a triplé. L'électricité ne représente cependant que 23 % de la consommation finale d'énergie en France. Mais elle offre une alternative sérieuse aux énergies fossiles, notamment aux hydrocarbures, dont l'épuisement annoncé et les besoins exponentiels des pays émergents évoquent l'imminence d'une crise géostratégique majeure. Le parc électrique français, déjà décarboné pour plus de 90 % de sa production, permettrait du même coup une réduction des émissions de CO2 (eq). Par ailleurs, toutes les études concluent que l'économie digitale pèsera plus de 20 % de la consommation mondiale d'électricité en 2020. Selon France Stratégie, c'est même à une explosion de cette consommation, liée aux technologies disruptives que nous devons nous attendre à court terme. Imaginer que la consommation d'électricité pourrait décroitre est peu crédible. Prendre d'ores et déjà cette décroissance pour un fait acquis dans le dimensionnement de notre parc électrique est irresponsable. 3.3.1	Quelle filière privilégier ?  Pour permettre la fermeture de la moindre centrale pilotable, afin d'assurer l'indispensable adéquation de l'offre avec la demande, toute alternative doit pouvoir garantir une production minimale. Or le vent et le soleil se couchent. Et ce dernier disparait notamment bien avant les pics de consommation hivernaux de 19 heures, lesquels sont caractérisés par des grands froids, généralement anticycloniques. C'est-à-dire sans vent. Qu'on le veuille ou non, c'est la raison qui a interdit au parc de production d'électricité allemand de réduire du moindre MW sa puissance installée pilotable depuis 15 ans, tandis que 100 GW intermittents, éoliens et photovoltaïques, s'y sont développés en tant que doublon. 3.3.2	Quelle puissance de production ?  Pour passer les pics de consommation, plusieurs mécanismes permettent d'optimiser le dimensionnement du parc de production : - Le mécanisme d'effacement qui permet de rétribuer des clients afin qu'ils ne consomment pas lors des situations critiques - Les smart grids, qui permettent d'inciter l'adéquation de la consommation avec la production disponible - Les délestages ciblés, qui s'efforcent de minimiser les conséquences d'une rupture d'approvisionnement - La baisse de tension sur le réseau. Ce dernier mécanisme n'étant pas sans risque : celui de faire disjoncter en cascade les transformateurs par un effet domino en cas d'imprévu, tel qu'une variation brutale de la production éolienne. - Le stockage - Les importations, qui dépendent des interconnexions et de la disponibilité de la production des pays voisins 3.3.3	Le double malentendu  L'annonce d'une réduction de la part du nucléaire et de son remplacement par les énergies intermittentes que sont éolien et photovoltaïque repose sur un malentendu savamment entretenu : celui de fixer dans la loi (LTECV) des objectifs en termes de part d'électricité consommée. Et cela, indépendamment de la puissance installée des filières qui les produisent, et quel que soit le moment où cette électricité sera produite. Ce qui est insensé. Car le développement de l'intermittence implique l'augmentation des moyens pilotables dédiés au lissage de sa production. En France, le choix ne réside qu'entre de nouvelles centrales thermiques ou l'asservissement du parc nucléaire aux caprices de la production éolienne, lui imposant des régimes chaotiques et à coups de fonctionnement, ainsi que c'est déjà le cas lors des records éoliens. Ce qui accélère le vieillissement des composants des centrales, ainsi qu'une perte de rentabilité, pour un avantage sur lequel il est permis de s'interroger. L'exception nucléaire française permet à la plupart de nos réacteurs de suivre au plus près les besoins de la consommation. C'est cette flexibilité unique au monde qui a permis à notre parc électrique de réduire à l'extrême le recours aux centrales thermiques. Et c'est grâce à ce parc nucléaire que la Commission européenne attribue à la France une indépendance énergétique bien supérieure à celle de ses voisins, et notamment à celle de l'Allemagne. Les leçons du passé, ainsi qu'un regard objectif sur l'avenir, doivent mettre en lumière les dangers de l'actuelle fuite en avant liée à des engagements partisans. Leurs enseignements dénoncent l'irresponsabilité de toute fermeture volontaire de réacteur qui serait jugé sûre par l'autorité de sûreté nucléaire. En tout état de cause, aucune puissance intermittente n'est encore susceptible de remplacer une centrale pilotable. 3.4	Énergie : le suicide collectif européen  L’axe germano-russe a déjà placé ses pièces maîtresses. L’équilibre mondial des relations entre les nations est sous tendu par une guerre féroce, celle de l’accès à l’énergie. En ruinant son système électrique par manque de vision stratégique, l’Europe ne semble pas prendre la mesure des conséquences de son impéritie. 3.4.1	L’axe germano-russe  En butte aux pressions américaines, l’Allemagne recherche depuis longtemps un partenariat privilégié avec la Russie en développant un nouveau gazoduc, appelé « Nord Stream 2 », reliant directement l’Allemagne à la Russie en évitant l’Ukraine. L’enjeu est d’importance pour la Russie, mais aussi pour l ’Allemagne qui se prépare à tenir sur son sol les vannes du gaz européen à l’horizon 2035 qui permettrait à l’Allemagne de devenir exportateur net de gaz vers la République tchèque, l’Autriche, la Suisse, la France, la Belgique et les Pays-Bas. 3.4.2	Un parc nucléaire qui fait de l’ombre à l’Allemagne  Mais la France dispose encore d’un double avantage sur ses voisins grâce à son parc nucléaire : 1) une moindre dépendance énergétique (46% contre 61,9% en Allemagne selon la Commission européenne), 2) de faibles émissions de CO2, ce qui place l’économie française à l’abri de l’évolution de la taxe carbone. 3.4.3	L’enjeu de la taxe carbone  Un relèvement significatif de la taxe carbone est inacceptable pour l’Allemagne tant que la production électrique française reste à 75 % nucléaire, en raison de l’avantage considérable que celle-ci lui confèrerait. L’évolution du parc de production nucléaire en France influera sur la rentabilité du parc à charbon en Allemagne. Le nucléaire a un coût marginal plus faible que le charbon, si bien que sa production peut se substituer à celle des centrales à charbon lorsque qu’il reste des capacités d’interconnexion disponibles. À l’inverse, si des capacités nucléaires sont retirées du mix français, la compétitivité des centrales à charbon en Allemagne sera améliorée. 3.4.4	Rendez-vous en terre inconnue  La politique énergétique européenne, confondant objectifs et moyens, se focalise désormais sur le seul développement des énergies renouvelables pour construire un avenir sans combustible fossile. Ces énergies renouvelables se sont pourtant révélées parfaitement inefficaces pour atteindre les trois objectifs qui leur étaient assignés : réduire l’impact environnemental, renforcer la sécurité d’approvisionnement, et maîtriser les coûts. Malgré la multiplication de démonstrateurs hors de prix, aucune avancée technologique ne permet d’espérer stocker massivement l’énergie pour un coût acceptable par la collectivité. Ce stockage reste pourtant indispensable pour que les énergies intermittentes confèrent une valeur ajoutée au parc électrique français. Peut-on baisser la part du nucléaire et, simultanément, réduire les émissions de gaz à effet de serre puisque ce sont les deux objectifs poursuivis?  Nous avons, chez Carbone 4, compilé les objectifs des textes législatifs et réglementaires portant sur l'énergie qui ont été écrits depuis 2005 et examiné si le tout formait un système cohérent… La réponse est non. C'est mathématiquement impossible. Atteindre en même temps baisse du nucléaire, baisse du fossile, baisse de la consommation et baisse des émissions est possible… à la condition de réduire considérablement l'activité économique du pays. Et la puissance publique ne propose pas cela!  Il faut se souvenir que l'objectif de 50 % de nucléaire dans la production d'électricité - contre 75 % actuellement - est né un beau matin pendant la campagne présidentielle de François Hollande en 2012. Ce chiffre n'a été précédé d'aucune analyse sérieuse et véhicule un implicite, inexact au regard des faits, selon lequel le nucléaire serait le mode de production électrique le plus dangereux qui soit. La production électrique qui a le plus tué en France, c'est le charbon - accidents de mines compris - et l'hydroélectricité avec la rupture du barrage de Fréjus. L'essor du renouvelable, de plus en plus compétitif, ne peut-il pas compenser le repli du nucléaire?  Si «renouvelable» c'est uniquement solaire et/ou éolien, non: c'est trop gourmand en capitaux pour refaire un système complet, c'est-à-dire avec stockage, qui fournisse de l'électricité à la demande, et pas juste quand les conditions extérieures sont favorables. Prenons l'exemple de l'Allemagne: en 2002, la puissance installée pilotable, activable à tout moment, était de 100 GW. En 2017, elle est… de 100 GW. On a rajouté 100 GW supplémentaires d'éolien et solaire, sans supprimer le pilotable, car le pays demande de l'électricité y compris quand il n'y a ni vent ni soleil. Il y a des - mauvais - jours où la production de l'éolien allemand tombe à 2 % de la puissance installée (et le solaire à 0 toutes les nuits). La France n'échappera pas à la règle.  Si on développe massivement le solaire et l'éolien, on gardera notre nucléaire, qui est pilotable, mais on en baissera le facteur de charge, c'est-à-dire l'activité. On garderait un système à coûts fixes, dont les recettes baisseront, ce qui augmentera le risque! Et, à consommation constante, le coût global sera plus élevé. En plus, pour produire 1 MWh de nucléaire, vous importez 1 euro d'uranium. Pour produire 1 MWh d'éolien ou de solaire, vous importez 20 à 30 euros de composants. Le développement des énergies renouvelables électriques en France est donc, en fait, défavorable pour l'emploi global, sans aucun bénéfice pour le CO2. Quel intérêt pour la collectivité? Avec 500 milliards de kWh produits chaque année en France, les batteries resteront à jamais hors de portée pour du stockage d'une saison à l'autre, ce qui serait nécessaire car l'hiver la consommation augmente plus que la production de renouvelables. La capacité de toutes les batteries qui existent dans le monde, principalement dans les voitures, représente à peine 1 térawattheure, soit… une journée de consommation d'électricité en France! En outre, passer du nucléaire à un système «éolien + solaire + stockage» mobiliserait 10 à 100 fois plus de surfaces, consommerait 10 à 100 fois plus de métal… Peut-on réellement parler de bénéfice environnemental évident?  3.4.5	La France a dû agir jeudi pour éviter une panne électrique européenne  Le réseau de distribution d'électricité français était au bord de la rupture jeudi dernier, en raison d'un problème d'équilibre entre l'offre et la demande au niveau européen. Le système électrique européen est passé tout près de la rupture jeudi dernier en raison d'une production insuffisante qui a contraint la France à réduire la consommation de certains clients industriels, a annoncé la Commission de régulation de l'énergie (CRE). «Le 10 janvier vers 21h00, la fréquence du système électrique français et européen est passée très en-dessous de 50 Hertz. Or, quand la fréquence s'écarte trop de ce niveau, le système électrique pourrait connaître des coupures importantes, voire un ‘black-out'», a fait savoir le régulateur dans un communiqué diffusé samedi. RTE, organisme de transport d'électricité a en conséquence demandé immédiatement à de grands groupes industriels énergivores, dans l'acier par exemple, de réduire leur consommation d'électricité de plus de 1500 mégawatts (MW) pour faire remonter la fréquence, ce qui a permis d'éviter une rupture. Les six clients industriels ayant conclu avec RTE des contrats dits «d'interruptibilité» ont baissé leur consommation pendant des périodes de 20 à 45 minutes, a indiqué lundi le gestionnaire de réseau, qui a eu ainsi recours pour la première fois à ce dispositif mis en place en 2014. La France doit tirer des leçons de la politique énergétique de l’Allemagne qui a décidé d’abandonner le nucléaire dans les années 1990, malgré des investissements colossaux dans les énergies renouvelables, investissements qui seraient difficiles à faire en France à un tel niveau, celle-ci se trouve dans une situation inconfortable en attendant l’arrivée massive du gaz russe. Les émissions de CO2 n’ont pas décru et pour compenser l’intermittence des énergies renouvelables fait appel aux centrales fonctionnant au charbon et au lignite, n’hésitant pas à déplacer des villages pour étendre les zones d’extraction de ces combustibles polluants.  L’analyse de la politique énergétique en Belgique confirme les conclusions faites pour l’Allemagne, arrêter des réacteurs nucléaires surs va à l’encontre des intérêts de la nation concernée. La politique énergétique de nos voisins est inquiétante, le réseau de distribution d’électricité se fait au niveau européen, si la France ne veut pas subir les méfaits de la politique énergétique de nos voisins européens, elle doit être en mesure de leur fournir de l’électricité afin d’éviter un black-out au niveau de l’Europe. 4	Accidents nucléaires majeurs : 4.1	Accident nucléaire majeur de Three Mile Island Il est 4 heures du matin, ce 28 mars 1979, quand de petits incidents apparaissent dans le fonctionnement du réacteur nucléaire de Three Mile Island. La centrale est située dans une île au milieu de la rivière Susquehanna, en Pennsylvanie, à 15 km d’Harrisburg, une ville de 60.000 habitants au centre d’une région urbaine d’une population de 500 000. La centrale comporte deux tranches de réacteurs à eau pressurisée de 800 et 900 MWe, toutes deux de conception Babcock & Wilcox, pas très différente des ilots nucléaires Westinghouse des réacteurs construits en France à cette époque. La tranche dite TMI1, toujours en fonctionnement en 2009, a été mise en service en 1974 tandis que TMI2 l’a été fin 1978. Cette nuit-là, TMI1 est en fin d’arrêt pour rechargement et TMI2 fonctionne à 97% de sa puissance nominale. Les petits incidents signalés provoquent l’arrêt des pompes qui alimentent en eau les générateurs de vapeur. Les procédures de sécurité se déclenchent. Mais abusés par des indications ambigües des instruments de contrôle, les opérateurs de TMI2 interprètent mal ce qui se passe dans le réacteur. Ils prennent, deux heures durant, des mesures aggravantes qui transforment un incident banal en accident sérieux et conduisent à la destruction d’un tiers du cœur du réacteur. Ce n’est que 3 heures 20 après le déclenchement de l’accident que l’opérateur rétablira une injection d’eau, permettant de rétablir un certain refroidissement du cœur. Mais le mal était fait.  Les dégâts internes ont été considérables : le tiers du combustible a fondu, et un autre tiers a été endommagé. Plus de 2000 m3 d’eau radioactive se sont répandus dans l’enceinte par la brèche du circuit primaire et quelques bouffées de gaz rares se sont échappées dans l’atmosphère. Le cœur fondu est resté à l’intérieur de la cuve du réacteur et l’enceinte de confinement, troisième barrière entre la radioactivité et l’environnement, a tenu son rôle : toute la radioactivité est restée contenue à l’intérieur du bâtiment réacteur.  Néanmoins, l’accident de Three Mile Island a terrorisé l’Amérique. Pendant toute une semaine, on s’est demandé quel était le vrai degré de gravité de l’accident et s’il fallait procéder à une évacuation partielle ou totale des habitants du voisinage. Plus de 200 000 personnes ont fui la région. Et pourtant, cet accident n’a causé aucune victime et le seul relâchement de radioactivité dans l’environnement n’a consisté qu’en une émission de gaz rares sans activité biologique. […] L’accident a été riche d’enseignements : importance de la défense en profondeur, importance du facteur humain, dispositifs d’aide à l’opérateur, hiérarchisation des alarmes, et rôle essentiel, en dernier ressort, de l’enceinte de confinement, barrière ultime entre la radioactivité du cœur et le monde extérieur.  Tous les réacteurs du monde ont profité des enseignements tirés de l’accident de TMI2. On a pu estimer que la prise en compte de ces leçons a réduit d’un facteur 10 le risque de fusion de cœur dans les réacteurs occidentaux « de deuxième génération » 4.2	Accident nucléaire majeur de Tchernobyl  La centrale de Tchernobyl comptait quatre réacteurs de type RBMK de conception soviétique. Ce modèle de réacteur est modéré au graphite et est refroidi à l'eau. Le combustible est de l'oxyde d'uranium enrichi à 2% en uranium 235. Les spécialistes jugent que ce réacteur comportait des défauts de conception qui le rendait potentiellement dangereux pour les raisons suivantes : Le cœur du réacteur est instable en dessous de 700 MWth, c'est-à-dire à faible puissance (un peu moins de 25 % de la puissance nominale). Le coefficient de réactivité est positif ce qui signifie qu'une augmentation de température dans le cœur du réacteur provoque une nouvelle augmentation de celle-ci. La perturbation initiale se trouve rapidement et automatiquement amplifiée et le réacteur devient difficilement contrôlable. Les barres de contrôle, destinées à enrayer l'emballement du cœur du réacteur, sont en carbure de bore et équipées, à leur extrémité, d'un embout en carbone, qui, au début de l'insertion des barres, commence par ajouter de la réactivité au lieu d'en retirer. Par ailleurs, la vitesse d'insertion de ces barres de sécurité est très insuffisante (20 secondes contre moins de 2 secondes sur les réacteurs REP)  Le ralentissement des neutrons (modérateur) est assuré par 600 tonnes de graphite. Or, le graphite, porté à haute température, s'enflamme au contact de l'air. L'incendie vaporise les radionucléides contenus dans le réacteur et en favorise la dispersion dans l'atmosphère. Enfin, le réacteur RBMK est dépourvu de dispositif d'épuration des rejets gazeux et d'enceinte de confinement. 4.2.1	Déroulement de l'accident de Tchernobyl  Le 26 avril 1986, le réacteur n°4 est entièrement détruit par une explosion suivie d'un incendie au cours d'un essai de fonctionnement à faible puissance. Cette catastrophe est due, non seulement aux défauts de conception du réacteur, mais également aux erreurs du personnel, insuffisamment formé, et à la procédure de contrôle de fonctionnement, incomplète et imprécise.  Afin de tester le refroidissement du cœur, la puissance du réacteur est réduite le faisant ainsi travailler dans une zone de fonctionnement instable. Ignorant les signaux d'arrêt d'urgence émis par le système de sécurité, le personnel continue l'essai. Les vannes d'admission de la turbine sont fermées, en violation de la procédure normale, entraînant une augmentation de la pression de la vapeur. Les barres de contrôle descendent automatiquement mais sans effet notable. Le chef opérateur ordonne alors l'arrêt d'urgence et fait descendre la totalité des barres sans parvenir à stopper l'emballement du réacteur. En quelques secondes, le réacteur atteint une puissance de l'ordre de 100 fois sa valeur nominale provoquant l'échauffement du fluide caloporteur (eau) et une détérioration du combustible. L'eau, qui ne parvient plus à évacuer la chaleur, se vaporise en une fraction de seconde et produit une explosion de chaleur qui détruit le réacteur. La partie supérieure du réacteur est à l'air libre. Le graphite, porté à haute température, s'enflamme alors. Les nombreux foyers d'incendie et l'absence d'enceinte de confinement favorisent la dispersion dans l'atmosphère de produits radioactifs. 4.2.2	D'énormes quantités de radionucléides libérées dans l'environnement... Un dégagement considérable de radionucléides a eu lieu essentiellement pendant les dix jours qui ont suivi la catastrophe : on estime que près de 12 1018 Bq sont partis dans l'environnement. Le nuage radioactif, entraîné par les masses d'air jusqu'à dix mille mètres d'altitude et dérivant au gré des vents, a disséminé sur la plupart des pays d'Europe des radionucléides, essentiellement l'iode 131, l'iode 132/tellure 132, l'iode 133, le césium 134 et le césium 137.  4.2.3	Les maladies engendrées par la catastrophe de Tchernobyl Le principal effet détecté des rejets radioactifs est l'augmentation des cancers de la thyroïde, en particulier, chez les enfants et les adolescents. Suivant les régions, on a constaté une multiplication par 10 à 100 du taux de cancer de la thyroïde, maladie normalement très rare chez l'enfant.  Il existe manifestement une relation entre le niveau d'exposition à l'iode 131 et le risque de contracter un cancer de la thyroïde. Une augmentation de l'incidence du cancer de la thyroïde, de l'ordre de 3 à 4, a également été constatée chez les individus adultes dans les pays les plus affectés par les retombées radioactives. Les études ne montrent pas d'augmentation significative du taux de leucémies ni de cancers solides par rapport à la période antérieure à l'accident y compris dans les zones les plus contaminées. On doit accorder une place particulière aux « liquidateurs », autrement dit aux personnes qui sont intervenues dans les premières années qui ont suivi l'accident pour travailler au contact direct de la centrale. Environ six cent mille personnes sont titulaires de certificats spéciaux confirmant leur statut de liquidateur. Parmi elles, 240 000 environ étaient des militaires. Les tâches principales réalisées par les ouvriers de recouvrement comprenaient la décontamination du bloc réacteur, du site du réacteur et des voies ainsi que la construction du sarcophage et d'une ville pour le personnel du réacteur. Ces travaux ont été achevés en 1990. Trente employés de la centrale et vingt-huit pompiers de Tchernobyl sont morts dans les jours ou semaines qui ont suivi l'explosion du fait d'un syndrome d'irradiation aiguë, consécutif à des doses de plusieurs grays : ils ont travaillé trop longtemps, sans équipements de protection adaptés, dans des lieux dont le niveau de radioactivité était considérable. Des études internationales sont en cours pour quantifier les risques de leucémies chez les liquidateurs. On estime que 3 000 des 600 000 personnes ayant travaillé au contact direct de la centrale mourront des suites de l'exposition aux radiations. Ces constatations suggèrent que la faible augmentation des cancers de la thyroïde, en France et en Europe en général, s'explique par à un meilleur dépistage clinique et par une amélioration des techniques d'investigation médicale. D'autre part, selon une étude menée par le Centre International de Recherche sur le Cancer sur la période 1980 - 1997, aucun excès de leucémie en France ne peut être attribué à l'accident de Tchernobyl. 4.3	Accident nucléaire majeur de Fukushima  4.3.1	Centrale de Fukushima Daiichi  L'accident nucléaire de Fukushima est un accident industriel majeur qui a débuté le 11 mars 2011 au Japon, à la suite du séisme et du tsunami de 2011. Il s'agit de la plus grave catastrophe nucléaire du 21eme siècle, classée au niveau 7, le plus élevé sur l'échelle internationale des événements nucléaires (INES), au même degré de gravité que la catastrophe de Tchernobyl (1986), en particulier par le volume important des rejets radioactifs.  Quatre centrales nucléaires se situent sur la côte nord orientale et se sont arrêtées automatiquement à la suite des premières secousses : les centrales de Fukushima Daiichi, de Fukushima Daini, d’Onagawa et de Tokai. Ces centrales sont équipées de réacteurs nucléaires de types « réacteurs à eau bouillante » (La centrale nucléaire de Fukushima Daiichi est située à 145 km de l’épicentre. Elle comporte six réacteurs : le réacteur 1 a une puissance électrique brute de 460 MWe, les réacteurs 2 à 5 une puissance de 784 MWe et le réacteur 6 une puissance de1100MWe. Trois des six réacteurs étaient en service lors du séisme (les réacteurs 1, 2 et 3) et fonctionnaient à pleine puissance. Les réacteurs 4, 5 et 6 étaient à l’arrêt pour maintenance. La détection des premières secousses provoque l'arrêt des réacteurs 1, 2 et 3 (soit 30 secondes avant les secousses principales qui ont duré près d’une minute). Le tremblement de terre entraine en outre la destruction des six lignes d’alimentations électriques externes des réacteurs et le démarrage des douze groupes électrogènes de secours à moteur diesel pour faire fonctionner des pompes de refroidissement. Cinquante-et-une minutes après la première secousse, la première vague du tsunami, d'une hauteur de 15 mètres, atteint la centrale nucléaire de Fukushima Daiichi. Elle est suivie de plusieurs autres vagues de moindre importance. L'installation ayant été bâtie pour résister à un séisme de magnitude 8 et à un tsunami de 5,7 mètres de haut, elle est entièrement inondée. Le tsunami a eu pour conséquences une dégradation des prises d’eau en mer conduisant à la perte de la source froide, puis à la perte des Diesels de secours des réacteurs 1 à 4. Les réacteurs 5 et 6, construits postérieurement aux quatre premiers réacteurs, sur une plate-forme située à une dizaine de mètres plus haut, n'ont quant à eux pas été atteints. À la suite de la perte des Diesels, un système d'ultime secours permettant de faire circuler l'eau contenue dans les tores situés en partie inférieure des bâtiments, au pied des cuves des réacteurs, s'est mis en marche puis s'est arrêté par défaillance des batteries électriques. Il n'y avait dès lors plus de moyens de refroidissement disponibles. Les cœurs des réacteurs 1 à 3 ont très probablement fondu plus tôt qu'initialement annoncé, et le corium aurait percé les cuves des réacteurs pour au moins en partie s’épandre sur le socle en béton (de huit mètres d'épaisseur) du bâtiment Le samedi 12 mars à 15 h 36, une forte explosion avec projection de débris et émission d’un panache blanc de fumée ou de vapeur d’hydrogène se produit dans le bâtiment du réacteur no 1 de Fukushima Daiichi. La partie haute du bâtiment (murs et toiture) s’est effondrée à la suite d’une explosion d’hydrogène induite par la surchauffe du réacteur à la suite de la baisse du niveau d’eau de refroidissement Le lundi 14 mars à 11 h 1, une seconde explosion se produit, cette fois au niveau du réacteur no 3 de Fukushima Daiichi, soufflant le toit du bâtiment. Onze personnes sont blessées. D’après l’opérateur, ni le réacteur ni la salle de commandes n’ont été endommagés. L’Agence japonaise de sûreté nucléaire explique que ces explosions sont provoquées par de l’hydrogène rejeté volontairement pour faire baisser la pression. Le mardi 15 mars à 6 h 10, une troisième explosion, cette fois-ci au réacteur 2 sur Fukushima I, a lieu et serait due à de l’hydrogène évacué. La possibilité d'une fusion du cœur où les tubes de combustion seraient détruits, est avancée. À 6 h 14, TEPCO annonce qu'une partie du bâtiment du réacteur no 4 est endommagé. À partir de ce stade des rejets massifs vont se produire dans l'atmosphère et l'environnement et l'ensemble des acteurs vont devoir gérer la phase post-accidentelle : l'exploitant va tenter de refroidir les installations puis de réduire les émissions tout en n'exposant pas trop les travailleurs. Les autorités vont prendre des mesures pour tenter de protéger la population. 4.3.2	Centrale de Fukushima Daini  On a beaucoup moins parlé de la crise qui a affecté Fukushima Daini, sa centrale sœur, à environ 10 kilomètres au sud ; elle aussi a essuyé d’importants dommages, mais a échappé au sort de Daiichi. Dans une situation aussi imprévisible, aucune des règles classiques liées à la prise de décision et au comportement organisationnel ne s’appliquent. Mais le directeur du site, Naohiro Masuda, ainsi que les 400 employés de Daini ont su se frayer un chemin dans le chaos de la situation, et la centrale s’en est tirée sans fusion ni explosion. Ce tremblement de terre de magnitude 9 fut le plus important jamais enregistré dans l’histoire du Japon ; les vagues qu’il a provoquées étaient trois fois plus hautes que celles auxquelles la centrale, dans sa conception, était supposée résister. Seuls un groupe électrogène diesel et une ligne électrique étaient restés intacts. Cette unique ligne électrique alimentait les salles des commandes, où les opérateurs de la centrale pouvaient contrôler le niveau d’eau, la température, la pression et autres mesures vitales de chaque réacteur et enceinte de confinement. Mais l’alimentation en électricité de trois des quatre réacteurs était alors insuffisante pour faire fonctionner une composante essentielle de leurs systèmes de refroidissement. Quand les eaux ont commencé à baisser, quelques heures plus tard, Masuda a appris que trois des quatre réacteurs avaient perdu leurs fonctions de refroidissement. Malgré l’arrêt du réacteur avant le tsunami, les crayons combustibles à l’intérieur de chaque cœur ont continué à produire de la chaleur qui normalement aurait été évacuée par le système de refroidissement et absorbée par la mer. Les opérateurs pouvaient toujours injecter de l’eau froide dans chaque cœur des réacteurs, mais Masuda craignait que même si les cœurs avaient conservé leur intégrité, une augmentation de la pression de la vapeur pouvait mettre en péril l’enceinte de confinement.  Heureusement, celle-ci a résisté ! 4.3.3	Centrale d'Onagawa  La centrale nucléaire d'Onagawa était la centrale nucléaire la plus proche de l'épicentre du séisme de Mars 2011, deux fois plus proche que celle de Fukushima Daiichi. Les trois réacteurs de la centrale ont résisté avec succès au tremblement de terre et au tsunami, démontrant la capacité d'une installation nucléaire bien conçue à résister, même à l'un des plus puissants séismes et aux tsunamis jamais enregistrés, et à s'arrêter en toute sécurité, sans incident. La centrale aurait même servi de refuge à la population locale contre le tsunami. La centrale d’Onagawa est constituée de trois réacteurs nucléaires à eau bouillante (REB):les trois tranches ont été mises en service respectivement en juin 1984 ; juillet 1995;et janvier 2002. Le site a été excavé pour pouvoir placer les bâtiments de la centrale sur un support consolidé (lit de roches et rochers artificiels). A la suite du séisme du 11 mars 2011, un incendie s'était déclaré dans un bâtiment de la centrale abritant une turbine mais, selon la compagnie électrique Tōhoku et selon les autorités, sans qu'aucune fuite radioactive n'ait été détectée dans les heures ayant suivi les premières. Le dimanche 13 mars; l’Agence de sûreté nucléaire japonaise affirme que le système de refroidissement de la centrale d’Onagawa fonctionne normalement. L'AIEA confirme des mesures de radioactivité excédant les niveaux autorisés autour de l'usine d'Onagawa. . Il s'agirait, selon les autorités japonaises, de retombées en provenance de l'usine de Fukushima Daiichi. Jeudi 7 avril 2011 dans la soirée, un nouveau séisme de 7,1 sur l'échelle de Richter survient dans la région, avec une alerte au tsunami, qui sera levée après une heure. Les trois tranches nucléaires d'Onagawa étaient alors toujours en arrêt à froid. Le refroidissement des réacteurs et piscines de combustible usagé était entretenu par des pompes alimentées par une électricité apportée par le réseau extérieur à la centrale. Environ deux cents personnes, comptant parmi les nombreuses familles ayant perdu leurs maisons détruites par le tsunami du 11 mars étaient provisoirement abritées dans les locaux de la centrale nucléaire. Le port d’Onagawa est situé sur une étroite bande littorale, au pied de collines escarpées qui ont bloqué la progression de la vague géante. L’eau a ainsi atteint une hauteur de 20 mètres, bien supérieure à celle que l’on a observée ailleurs. Le tsunami a détruit tous les édifices du centre-ville, y compris la gare, et provoqué la mort ou la disparition de 827 personnes. Le constat est clair: Les 4 réacteurs qui n'ont pas résisté au séisme et au tsunami sont les plus anciens construits au Japon. Ils datent de 1971 à 1979. Les réacteurs d'Onagawa ont été construits entre 1984 et 2002. Même s'ils sont de même conception, ils ont beaucoup mieux résisté. Il faut aussi noter que l'exploitant n'est pas Tepco mais Tohoku. On peut également noter que Tepco a falsifié des rapports d'inspection de ses réacteurs nucléaires entre la fin des années 1980 et les années 1990. Cette fraude a été révélée le 29 août 2002 par l'agence de sûreté nucléaire industrielle japonaise. 4.3.4	Mesures qu’il aurait fallu prendre  L’accident est un accident de refroidissement comme celui survenu en 1979 à Three Mile Island aux Etats-Unis. Il n'y a pas eu d'explosion atomique ! Les réacteurs se sont arrêtés automatiquement lors du tremblement de terre et avec eux les fissions nucléaires. Mais les désintégrations radioactives continuent de dégager de la chaleur. Il est impératif de refroidir. Or la vague du tsunami a endommagé et inondé les circuits de refroidissement et installations de secours, conduisant à une perte totale des alimentations électriques et des moyens de refroidissement principaux durant de longues heures. A ces pannes multiples s’ajoutent des conditions d’intervention dramatiques. Villes et villages de la côte ont été dévastés par le tsunami, les routes sont impraticables. Les premières équipes doivent intervenir alors que leurs vies ont été bouleversées et que les familles sont à la recherche de proches disparus. L’accident est la preuve que les scénarios extrêmes peuvent arriver, avec la concomitance de multiples pannes. La conduite à tenir dans de telles circonstances n’avait pas été envisagée et la gestion de la crise et de ses multiples rebondissements s’est effectuée "au doigt mouillé". On peut jeter a posteriori un regard effrayé sur cette gestion. Cependant, les dispositifs existants quoique insuffisants ont porté leur fruit et atténué l’accident. Les enceintes de confinement ont joué leur rôle ; le gros de la radioactivité est resté dans ces enceintes ; quatre jours se sont écoulés avant le principal rejet de radioactivité donnant le temps de mettre à l’abri les populations.  Les cœurs des trois réacteurs accidentés de la centrale de Fukushima-Daiichi sont restés de longues heures sans apport d’eau. De ce fait les barres de combustibles se sont découvertes dans les cuves des réacteurs. Insuffisamment refroidies, leur température a dépassé 1000°C. Les gaines enrobant le combustible nucléaire ont perdu de leur étanchéité et ont réagi avec de la vapeur en dégageant de l’hydrogène. Ce gaz s’est retrouvé dans les étages supérieurs des réacteurs 1 et 3 où il a explosé au contact de l’air. Le déroulement de l’accident est extrêmement complexe avec toute une suite de rebondissements. C’est ainsi par exemple que les débris de l’explosion du toit du réacteur N°3 obligèrent d’interrompre le refroidissement de secours du réacteur N°2 voisin causant dans ce réacteur une explosion tardive qui aggrava l'accident. Si le refroidissement du N°2 n'avait pas été interrompu, la pollution de l’environnement serait restée probablement faible.  Quelles sont les responsabilités humaines ? Soyons d'abord reconnaissants au dévouement des équipes qui se sont battues pour maîtriser l’accident dans des conditions difficiles et n'oublions pas l'adage antique. Ceci dit, les responsabilités des dirigeants sont lourdes. Un rapport du parlement japonais juge sévèrement la collusion en matière de régulation du gouvernement d'alors et de l'exploitant. Le financier l'a emporté sur l'ingénieur, la rentabilité sur la sûreté. Des avertissements ont été ignorés, les risques de tsunami minimisés. Située au nord du Japon, la centrale nucléaire d’Onagawa, la plus proche de l'épicentre du tremblement de terre et soumise à des secousses encore plus violentes, n'a pas subi de dommages majeurs car conçue avec des marges de sécurité suffisantes. La centrale d'Onagawa a enregistré des secousses sismiques qui ont dépassé sa capacité nominale, et le sous-sol de l'un de ses bâtiments des réacteurs a été inondé. Mais l'usine a maintenu sa capacité de refroidissement, ses réacteurs se sont arrêtés sans dommages à leurs cœurs ni dommages importants aux systèmes de sécurité. Si l’exploitant de la centrale, TEPCO, avait érigé une digue plus élevée, prévu des alternateurs et des réserves d’eau à l’abri des inondations, installé les recombineurs d’hydrogène préconisés par l’AIEA, il aurait évité la perte de trois réacteurs, sa ruine peut être. Il aurait surtout évité les contaminations radioactives nécessitant l’évacuation de 170 000 personnes autour de la centrale. Si les pertes en vies humaines dues à la radioactivité seront probablement minimes, les conséquences sont lourdes pour la société et l'économie japonaise. Il y a d'abord le coût humain des évacuations et des déracinements, celui des décontaminations. Puis du fait de l'arrêt des réacteurs japonais (il est question de les remettre en service en partie), il a fallu importer de grandes quantités de gaz et de pétrole pour produire de l'électricité. En avril 2014, le déficit commercial du Japon avait quadruplé. Enfin, le recours aux centrales thermiques accroit l'effet de serre et le réchauffement climatique. L’accident de Tchernobyl était prévisible et prévue du fait de l’instabilité du réacteur à faible puissance, les expériences hasardeuses entreprises le jour de l’accident n’auraient jamais été autorisés par une Autorité de Sureté Nucléaire digne de ce nom. Les rejets massifs de produits radioactifs dans l’atmosphère ont été dus à la combustion de 600 tonnes de graphite du cœur du réacteur et à l’absence d’enceinte de confinement. Le nombre de décès chez les liquidateurs aurait pu être réduit si des mesures de radioprotection plus sévères avaient été mises en place.  4.4	Retour d’expérience de l’accident de Fukushima 4.4.1	Le parc français des centrales nucléaires  Les 19 centrales nucléaires actuellement en fonctionnement en France ont été globalement construites sur le même mode. Tous leurs réacteurs utilisent la même technologie, dans laquelle de l’eau sous pression sert à transporter la chaleur produite par les réactions nucléaires. Cette standardisation du parc électronucléaire a permis à EDF ainsi qu’à l’ASN d’accumuler une solide expérience du fonctionnement des réacteurs à eau sous pression. En France, les 19 centrales nucléaires totalisent en effet 1300 ans de fonctionnement. Mais cette situation présente aussi un inconvénient. Si un défaut de conception fondamental apparaît sur l’une des installations, les autres peuvent être potentiellement concernées. Les centrales nucléaires regroupent un total de 58 réacteurs dont 34 produisent chacun une puissance électrique de 900 Mégawatt (MWe) – 900 MWe permet d’alimenter près de 500 000 foyers. A cela s’ajoutent 20 réacteurs de 1300 MWe, tandis que les quatre derniers délivrent 1450 MWe. Un 59ème réacteur est actuellement en construction à Flamanville, dans la Manche. Il développera une puissance électrique de l’ordre de 1600 MWe. Actuellement, ces installations produisent près de 80% de l’électricité produite en France. 4.4.2	Recommandations de l’autorité de sureté nucléaire L’ASN, en charge du contrôle des installations nucléaires françaises, a demandé le 5 mai 2011 aux exploitants d’engager des évaluations complémentaires de sûreté (ECS) de leurs installations à la suite de l’accident survenu au Japon le 11 mars 2011. Le processus, qui consiste en un retour d’expérience approfondi de cet événement, s’étalera sur plusieurs années, comme ce fut le cas après les accidents de Three Mile Island et de Tchernobyl. A l’issue des ECS, dans son avis du 3 janvier 2012, l’ASN soulignait qu’elle allait imposer aux exploitants un ensemble de dispositions pour renforcer la prévention des risques naturels ou liés aux autres activités industrielles et assurer la maitrise des situations accidentelles qui pourraient en résulter. Ces prescriptions imposent notamment à EDF :  La mise en place d’un « noyau dur » constitué d’un nombre limité d’équipements permettant d’assurer les fonctions de sûreté en situations extrêmes. Ce "noyau dur" doit être aussi indépendant que possible des dispositifs existants. Le 21 janvier 2014, le collège de l’ASN a adopté 19 décisions qui précisent les objectifs et les éléments constituant ce "noyau dur". EDF propose de mettre en place ce noyau dur en deux phases : -	une première phase comportant la mise en place des éléments fondamentaux du noyau dur, notamment, pour chaque réacteur, un diesel d’ultime secours de grande capacité; -	une seconde phase venant compléter la première pour améliorer le taux de couverture des scénarii d’accidents potentiels pris en compte ;  -	le déploiement de la « Force d’action rapide nucléaire » (FARN), qui permet d’apporter un secours à un site comportant 4 réacteurs accidentés ; -	la mise en œuvre d’un ensemble de dispositions temporaires ou mobiles visant à renforcer la prise en compte des situations de perte totale de la source froide ou de perte des alimentations électriques transitoires. A Three mile Island comme a Fukushima, le pire accident s’est produit la fusion partielle du cœur du réacteur. A Three Mile Island, sans explosion due à un dégagement d’hydrogène, l’enceinte de confinement a rempli son rôle et les rejets de radioactivité ont été faibles. Au Japon quatre centrales ont été soumises à un séisme exceptionnel qui a entrainé l’arrêt de tous les réacteurs en fonctionnement suivi d’un tsunami qui a à peu près tout détruit à l’exception des réacteurs, malheureusement les alimentations extérieures en eau et électricité des réacteurs ont été endommagées empêchant le refroidissement des réacteurs Fukushima Daiichi. L’échauffement du cœur du réacteur a entrainé la dissociation de l’eau en hydrogène qui a provoqué l’explosion des réacteurs et les importants rejets de radioactivité dans l’environnement. Il est à noter que la centrale d’Onagawa, la centrale nucléaire la plus proche de l'épicentre du séisme et de conception plus récente n’a subi que des dommages mineurs. Les mesures proposées par l’ASN suite à l’accident de Fukushima devraient permettre en renforçant en particulier les réseaux d’alimentation en électricité et en eau rendre invulnérables des réacteurs soumis à de forts séismes ou inondations. 4.5	Evaluation comparative des retombées radioactives de l’accident de Tchernobyl et des essais nucléaires atmosphériques  La question de la comparaison des impacts sur l’environnement des retombées radioactives de l'accident de Tchernobyl et des essais nucléaires atmosphériques de 1945 à 1980 mérite une réponse qui présente, entre autres, l’intérêt de fournir des éléments de référence de nature à permettre une appréciation indirecte, facile et correcte de l’impact sanitaire de l’accident par rapport à celui, déjà vécu et perçu comme insignifiant, des essais nucléaires atmosphériques. En deçà d’une certaine distance à la source de l’accident, l'impact sanitaire de celui-ci est naturellement plus important que l'impact des essais. Mais, au-delà de cette distance, la retombée de l'accident devient rapidement négligeable devant la retombée globale due à la totalité des essais nucléaires aériens. Cette distance critique est de l'ordre de 1 500 km pour les principaux produits de fission et de quelques centaines de kilomètres pour les actinides. Un ordre de grandeur de l’impact sanitaire final des différentes retombées peut, en outre, être apprécié simplement si l’on considère que les engagements d'équivalent de dose efficace individuelle provenant de tous les radionucléides libérés dans l’environnement par les essais de 1945 à 1980 correspondent approximativement et en toutes régions à une année moyenne supplémentaire de radioactivité naturelle.  Les opposante à l’énergie nucléaire se focalisent sur les réacteurs nucléaires, sur Tchernobyl et Fukushima mais oublient les essais nucléaires atmosphériques russes, américains, anglais, français, chinois, effectués de 1945 à 1980.  L’accident de Tchernobyl s’est produit sur un réacteur très différent de ceux en service aux Etats Unis ou en Europe occidentale. Ce réacteur avait des zones d’instabilité de fonctionnement qui ont été explorées lors de l’accident du réacteur, ce qui a provoqué l’emballement du réacteur qui de plus ne possédait pas d’enceinte de confinement. L’incendie du cœur en graphite a propagé une énorme quantité de produits radioactifs dans la haute atmosphère, comme c’était le cas lors des essais aériens de bombes atomiques. Le nuage de Tchernobyl a fait couler beaucoup d’encre, bien plus que les nuages issus des essais aériens de bombes atomiques. Pourtant, la radioactivité cumulée de ces essais est très supérieure à celle due au réacteur de Tchernobyl. Les accidents de Three mile Island et Fukushima se sont produits sur des réacteurs de conception identique à ceux utilisés en Europe. L’accident grave de fusion du cœur du réacteur de TMI2 a été très médiatisé et a terrorisé les habitants proches du réacteur qui a été sévèrement endommagé. Cependant il n’y a eu aucune victime et les rejets de radioactivité dans l’environnement ont été faibles. L’accident de Fukushima a été dû à un séisme de très forte intensité, accompagne d’un tsunami qui a ravagé habitations, routes, voies ferrées et surtout lignes électriques. Quatre centrales ont été affectées par le séisme, toutes ont été arrêtées dès les premières secousses. Trois des centrales ont subi des dégâts mineurs en particulier la centrale de conception récente d’Onagawa, centrale la plus proche de l’épicentre du séisme. La centrale de Fukushima Daiichi a vu les alimentations en eau et électricité externes au réacteur s’arrêter, l’échauffement des réacteurs dû à la radioactivité résiduelle a entraina dans les jours suivants des dégagements d’hydrogène qui  ont conduit à de violentes explosions qui ont détruit les réacteurs et dispersé une importante radioactivité dans l’atmosphère et dans la mer. Les autorités de surete nucléaire ont tiré les leçons de ces deux accidents et en particulier demandé à EDF de rendre invulnérables les installations externes d’alimentation en eau et électricité des réacteurs.  4.6	Etats-Unis : vers une extension de la durée des réacteurs nucléaires à 80 ans ?  Si le gouvernement américain a réaffirmé en 2015 ses ambitions de développement en matière d’énergies renouvelables, dans les secteurs éolien et solaire notamment, il n’entend pas pour autant se désengager du nucléaire, considéré outre-Atlantique comme une énergie bon marché et créatrice d’emploi. Les Etats-Unis envisageraient même de porter la durée d’exploitation de leurs centrales à 80 ans selon un document examiné actuellement par la NRC, l’autorité de sûreté nucléaire américaine.  4.6.1	Les Etats-Unis : premier parc nucléaire au monde Plus grand parc nucléaire au monde devant la France, les États-Unis comptent actuellement 99 réacteurs en activité représentant près de 20% de la production électrique nationale. Grâce à une puissance cumulée de 98,7 GW, le secteur nucléaire américain a généré 797 TWh d’électricité en 2014, soit environ 19,5% des besoins en électricité du pays sans émissions de CO2. Les centrales nucléaires américaines garantissent près de 60 milliards de dollars au produit intérieur brut des États-Unis tout en maintenant des coûts de production de l’électricité très faibles. Elles assurent plus de 400.000 emplois à temps plein et éviteraient, selon les estimations du cabinet d’études Brattle Group, le rejet annuel de plus de 573 millions de tonnes de CO2dans l’atmosphère. 4.6.2	Evolution de la demande d’électricité et perspectives de croissance  Selon le Département de l’Énergie américain (DOE), les besoins en électricité des États-Unis devraient augmenter de 25 % d’ici 2030. Le pays nécessitera donc l’équivalent de 35 nouvelles centrales nucléaires afin de maintenir tant dedecrié aurait sauveles 20 % de production d’électricité assurés par l’énergie nucléaire. 4.6.3	Une durée d’exploitation étendue à 80 ans ? Les États-Unis ont débuté le développement de leur parc nucléaire dans les années 60-70, octroyant des licences d’exploitation pour une durée de 40 ans, avec possibilité de reconduction de 20 ans. Or, 81 des 99 réacteurs évoqués ont déjà obtenu le droit de poursuivre leur exploitation jusqu’à 60 ans, et pourraient d’étendre la durée d’exploitation des réacteurs de 60 à 80 ans. Les réacteurs américains déjà concernés par le scénario des 80 ans sont similaires aux 34 réacteurs de 900 MW français.  Rôle bénéfique du Nucléaire  L'énergie nucléaire est souvent présentée comme une source à faible émission de carbone qui atténue les émissions de combustibles fossiles et les dommages pour la santé et les décès causés par la pollution atmosphérique. Mais est-il possible de fournir des estimations et de quantifier réellement ces effets ? C'est ce qu'affirme un nouvel article du Goddard Institute de la NASA, dans la revue Environmental Science and Technology. Les auteurs présentent le chiffre frappant de 1,8 million de vies sauvées en remplaçant les sources d'énergie fossiles par l'énergie nucléaire. Ils estiment également que l'énergie nucléaire pourrait sauver jusqu'à 7 millions de vies au cours des quatre prochaines décennies et réduire considérablement les émissions de carbone en remplaçant à grande échelle l'utilisation de combustibles fossiles. En outre, l'étude conclut que l'expansion proposée du gaz naturel ne serait pas aussi efficace pour sauver des vies et prévenir les émissions de carbone et beaucoup plus de décès qu'elle n'en a causé.  Les réacteurs américains sont très voisins des réacteurs français et sont programmés pour une durée de fonctionnement de 60 ans, voire de 80 ans. Il serait souhaitable que durée de fonctionnement des réacteurs français soit prolongée et que leur arrêt soit décidé par l’ASN. Enfin le nucléaire, tant décrié, aurait sauvé de très nombreuses vies humaines en se substituant aux énergies fossiles eet devrait en sauver beaucoup plus dans les décennies à venir.. 5	Accidents industriels  5.1	Accidents dans l’industrie chimique: 5.1.1	Seveso Le 10 juillet 1976, un sifflement se fait entendre dans l’usine de produits chimiques Icmesa de Meda située à 20 km de Milan. Un nuage blanc, très dense, se propage au dehors du bâtiment, en direction de Seveso qui abrite 17 000 âmes. Icmesa affirme que les concentrations de produits enregistrées sont à des niveaux sans danger pour l’homme, tout en n’évoquant par la dioxine. Ce n’est que dix jours après l’accident que Givaudan, maison-mère d’Icmesa, reconnaît que de cette substance toxique a été trouvée autour de l’usine. Entre temps, plus d’une douzaine d’enfants ont été hospitalisés. Le scandale éclate le 21 juillet. Le directeur technique et le directeur de production d’Icmesa sont arrêtés. Après quelques jours d’atermoiements, on procède à des évacuations. A la fin du mois, 730 personnes ont quitté leur domicile Le bilan de la catastrophe est impressionnant : sept communes touchées dont quatre sévèrement, 358 hectares contaminés, 77 000 têtes de bétail abattues, des récoltes brûlées et des activités agricoles interrompues… Pendant l’été, environ 450 personnes souffrent de lésions apparentes, en majorité des enfants. Parmi elles, 193 sont atteintes de chloracné, une altération grave de la peau dont beaucoup garderont des séquelles. 5.1.2	Bhopal  Dans la nuit du 2 au 3 décembre 1984 une cuve de produits chimiques explose dans une usine de pesticides à Bhopal, 800.000 habitants, au centre de l’Inde. Ce sont 42 tonnes de gaz mortels qui s’échappent, asphyxiant en premier lieu le bidonville de Khasi Camp où les populations les plus pauvres sont agglutinées, et provoquent la mort de 3.800 personnes le 3 décembre, puis de 8.000 la première semaine, et de 25.000 personnes un peu plus tard dans d’atroces souffrances. Mais il y a aussi de très nombreux blessés, malades et plus de 200.000 personnes qui sont maintenant gravement handicapées à vie et autant de personnes qui sont nées par la suite avec des malformations importantes.  5.1.3	Usine AZF de Toulouse  C'est la plus grave catastrophe industrielle d'après-guerre en France. L'explosion de plusieurs centaines de tonnes de nitrate d'ammonium dans l'usine pétrochimique AZF, le 21 septembre 2001 à Toulouse, a tué 31 personnes et blessé 2500 autres.  5.1.4	Tianjin, l’une des pires catastrophes industrielles de la Chine Le 12 août 2015, une terrible explosion secoue le port de Tianjin et ses 15 millions d’habitants, à 120 km de la capitale chinoise, laissant flotter un menaçant nuage orangé au-dessus du quartier de Binhai. Des dizaines de pompiers, sont envoyées pour maîtriser le sinistre. Une centaine d’entre eux vont y laisser leur vie La société Rui Hai stockait, de manière totalement illégale, plus de 3 000 tonnes de produits chimiques dont 700 tonnes de cyanure, alors que l’entrepôt se trouve à côté d’une zone résidentielle. Fin août, le bilan officiel fera état de 165 morts et plus de 800 blessés. 5.2	Ruptures de barrages  5.2.1	1802 : la rupture du barrage de Puentes en Espagne, première grande catastrophe due à l'homme  Le barrage de Puentes, construit de 1785 et 1791 pour irriguer la région de Murcie. Le 30 avril 1802, à 15h00, le barrage cède et laisse échapper les eaux qui atteignent la ville de Lorca causant la mort de 608 personnes. 5.2.2	1864 : le réservoir de Dale Dyke en Grande-Bretagne inonde la ville de Sheffield  Construit pour alimenter ville de Sheffield dans le South-Yorkshire, le barrage en remblai de Dale Dyke se rompt lors de sa mise en eau le 11 mars 1864. Le réservoir de 3 000 000 m3 d'eau se vide et les eaux envahissent la ville de Sheffield provoquant la mort d'environ 240  5.2.3	1923 : le barrage de Gleno en Italie, un désastre inévitable : Construit de 1919 à 1923 en Lombardie, le barrage du Gleno situé dans la vallée du Scalve, mis en eau en août 1923, il cède le 1er décembre, il laisse échapper les 6 000 000 m3 d'eau, dévastant sur 25 km, villages et usines et provoquant la mort d'environ 500 personnes.  5.2.4	1959 : la ville de Fréjus dévastée par la rupture du barrage de Malpasset Envisagé juste après la seconde guerre mondiale, le barrage de Malpasset situé près de Fréjus est inauguré en 1954. Le 2 décembre, le barrage cède sous la pression laissant passer une vague de 40 mètres s'engouffre dans la vallée et dévaste la ville de Fréjus, provoquant la mort de 423 personnes. 5.2.5	1963: 1.900 morts dans la catastrophe du barrage de Vajont en Italie Situé au pied du mont Toc dans la province de Belluno à 100 km de Venise, le barrage de Vajont, est mis en service en 1960 malgré plusieurs alertes sur les risques de glissement de terrain. Le 9 octobre, plus de 260 000 000 m3 de terre et de roche se déversent à plus de 90 km/h dans la retenue d'eau provoquant deux énormes vagues de 25 millions m3 d'eau vers l'amont et l'aval du barrage. La vague d'aval haute de 150 m saute le barrage et se déverse dans la vallée créant un phénomène de pression d'air dévastateur suivi d'un torrent d'eau qui achève de détruire les villes de Langarone, Pirago, Rivalta, Villanova et Faè. Le bilan humain de la catastrophe est extrêmement lourd avec plus de 1.900 morts. 5.2.6	2011 Rupture du barrage de Fujinuma  Le barrage Fujinuma était un barrage du Japon situé à Sukagawa, dans la préfecture de Fukushima. Construit en 1949, il avait principalement un rôle tampon pour l'irrigation. Le barrage s'est écroulé le 11 mars 2011 lors du séisme qui a entrainé la catastrophe de Fukushima. 5.2.7	2019 : Rupture du barrage Brumadinho au Brésil  Les télévisions brésiliennes ont diffusé vendredi 1er février une impressionnante série d'images filmées par les caméras de sécurité montrant le moment exact de la rupture du barrage à proximité de la ville de Brumadinho, une catastrophe survenue le 25 janvier et qui a fait 121 morts et plus de 200 disparus. 5.2.8	Des milliers de morts dans le monde  Les accidents de ruptures de barrages sont nombreux dans le monde, certains terriblement meurtriers comme celui de South Fork aux Etats-Unis qui fait 2.200 morts en 1889 ou celui d'Iruhaike au Japon qui provoque la mort de 1.200 personnes en 1868. L'Inde connaît une terrible succession de catastrophes liées au barrage: Tigra en 1917 (1.000 morts) Panshet en 1961 (1.000 morts), Khadakwasla en 1961 également (1.000 morts) et Machu en 1979 (2.000 morts). 5.3	Catastrophes liées à l’exploitation et au transport d’hydrocarbures Les nappes de pétrole issues de naufrages ont été nombreuses ces 50 dernières années : 5.3.1	Mars 1967 - Torrey Canyon  Le Torrey Canyon, un navire libérien, s'échoue à proximité des îles Scilly (Grande-Bretagne) et déverse dans la mer 121.000 tonnes de brut, atteignant la Bretagne (ouest de la France). 5.3.2	Mars 1978 - Amoco Cadiz  Le naufrage du supertanker libérien Amoco Cadiz provoque la fuite de 227.000 tonnes de brut sur environ 400 km de côtes françaises au large du Finistère (nord-ouest). 5.3.3	Juillet 1979 - Atlantic Empress/Aegean Captain  La collision de deux navires battant pavillon grec, l'Atlantic Empress et l'Aegean Captain, au large de Tobago, provoque le déversement de 287.000 tonnes de pétrole, en plus de causer la mort de 30 marins. 5.3.4	Août 1983 - Castillo de Bellver  Le Castillo de Bellver, pétrolier espagnol transportant 250.000 tonnes de pétrole léger, explose et coule en deux temps: d'abord l'arrière du navire près des côtes d'Afrique du Sud, puis l'avant au large après remorquage. 5.3.5	Novembre 1988 - Odyssey  L'Odyssey, navire britannique transportant 132.000 tonnes de pétrole, sombre dans l'Atlantique à environ 1.300 km des côtes canadiennes avec les 27 membres de l'équipage. 5.3.6	Avril 1991 - Haven  Un pétrolier chypriote, le Haven, sombre dans le Golfe de Gênes (Italie) après plusieurs incendies qui détruisent une grande partie de sa cargaison de 144.000 tonnes. Le reste du pétrole forme une marée noire qui pollue les côtes de Ligurie et de Provence. 5.3.7	Mai 1991 - Abt Summer  Un pétrolier libérien, l'ABT Summer, explose à environ 1.300 km au large de l'Angola. Il brûle pendant trois jours avant de couler avec sa cargaison de 260.000 tonnes de pétrole. 5.3.8	Autres naufrages D'autres naufrages de pétroliers, au volume d'hydrocarbures moins élevé, ont causé d'importantes catastrophes naturelles comme les marées noires de l'Exxon Valdez en Alaska (1989), du Sea Empress au Pays de Galles (1996), de l'Erika en France (1999) ou du Prestige en Espagne (2002).  5.3.9	1966 Raffinerie de Feyzin  La raffinerie de Feyzin, dans le département du Rhône a explosé le 4 janvier 1966. Cette catastrophe a fait 18 morts dont 11 pompiers, et 84 blessés.  5.3.10	1958 Incendies de dépôts pétroliers en France en 1958  Dans l'intention de s'opposer au référendum sur l'établissement de la cinquième république, le FLN a réalisé de nombreux attentats en métropole entre le 25 août 1958 et le 30 septembre. Pour la seule journée du 25 août, différents incendies ont été déclenchés sur des installations pétrolières de Marseille et Narbonne : incendie des dépôts pétroliers à Lavéra, La Mède, Saint-Louis, les Aygalades, Cap Pinède, Port de Marseille, Mourepiane où l’incendie le plus important s’est produit. Toulouse : 2 cuves de supercarburant incendiées soit 1.200.000 litres. Port La Nouvelle: 10 cuves contenants 8 millions de litres de fuel sont la proie des flammes. Frontignan : tentative d'incendie de la raffinerie Mobil Oil. 5 bombes découvertes. Le Havre : sabotage et incendie à la raffinerie ESSO de Notre Dame de Gravenchon. Alès (Gard) : incendie de dépôt de carburant. 5.3.11	1988 Piper Alpha au large d'Aberdeen en Écosse Le 6 juillet 1988, au large de l'Écosse, sur le champ pétrolier et gazier de Piper, la plate-forme Piper Alpha, de la multinationale Occidental Petroleum Corporation, sombrait sous le coup de plusieurs explosions et de violents incendies emportant 167 hommes sur les 231 personnes présentes sur la plate-forme, beaucoup de survivants sont gravement brûlés. 5.3.12	Rejets d’hydrocarbures en mer Les deux rejets d’hydrocarbures en mer les plus importants de l’histoire sont liés à deux éruptions de puits en cours de forage (Ixtoc I en 1979 et Macondo en 2010). 5.3.12.1	Plate-forme de forage offshore Ixtoc 1 Le 3 juin 1979, dans le golfe du Mexique, en baie de Campêche, une éruption de pétrole souffle la plate-forme de forage offshore Ixtoc 1, cette éruption ne sera stoppée que le 23 mars 1980, après 295 jours d'efforts, au cours desquels le jaillissement aura d'abord été réduit de 4200-4300 tonnes/jour à 1400-1500 tonnes/jour, par le creusement de conduits de dégagement abaissant la pression dans le puits en cause. La quantité totale de pétrole déversée ainsi ne sera jamais exactement connue : 470 000 tonnes selon les estimations les plus prudentes, peut-être jusqu'à 1 500 000 tonnes. Entre le tiers et la moitié de ce pétrole a brûlé, provoquant une vaste pollution atmosphérique. Le reste s'est répandu à travers le golfe du Mexique sous forme de nappes dérivantes. 5.3.12.2	Explosion de la plate-forme Deepwater Horizon Le 20 avril 2010, une gigantesque explosion la plate-forme de forage Deepwater Horizon provoque le décès. Onze personnes perdent la vie. Deux jours plus tard, la plate-forme coule à quelque 70 kilomètres des côtes, au large de La Nouvelle-Orléans, en Louisiane Depuis l'accident, le pétrole s'échappe en continu du puits situé à 1 500 mètres sous la surface du golfe du Mexique. Les experts estiment qu'entre 20 000 et 40 000 barils de brut (de 3,1 à 6,3 millions de litres) se sont écoulés chaque jour. Début juin, la marée noire s'étend sur un rayon de 320 km.  Le 30 avril, les premières nappes atteignent les côtes de Louisiane. Des galettes de pétrole sont également repérées dans le Mississippi et l'Alabama. Près de deux mois après l'explosion, les quantités déversées sont mal connues : de 100 millions à 215 millions de litres. BP est parvenu à colmater la fuite principale aux alentours du 15 juillet 2010, près de 90 jours après l'explosion de la barge. Mais une fuite souterraine ne sera colmatée que le 18 septembre, soit près de cinq mois après le début de la catastrophe.  5.4	Victimes et pollution liées à l’exploitation du charbon 5.4.1	Victimes et pollution en Europe La combustion du charbon relâche outre de grandes quantités de CO2, des particules fines ainsi que des éléments toxiques tels que le soufre, l’arsenic, le mercure et le plomb qui peuvent être la cause de maladies respiratoires. Le charbon entraîne 23 000 morts prématurées en Europe chaque année : En France, quelque 1 200 décès prématurés seraient dus à l’exploitation de centrales à charbon, principalement celles des pays voisins, Allemagne, Pologne, Royaume-Uni, Espagne Trente centrales, rebaptisées « les 30 toxiques », ont été identifiées comme les plus meurtrières d’Europe par les ONG, dont neuf au Royaume-Uni, six en Allemagne, cinq en Pologne ou encore cinq en Roumanie. Elles sont responsables de la moitié des morts prématurées en Europe. 5.4.2	Exploitation des mines de charbon en Chine Quelque 1.049 personnes sont mortes sur un site de production houillère selon un bilan officiel du Bureau national chargé de la sécurité du travail publié ce lundi 6 janvier 2014. En Chine, une estimation évoque le nombre de 366 000 morts prématurées annuellement Plusieurs organismes indépendants estiment que ce bilan est minoré car de nombreux accidents seraient passés sous silence pour éviter des fermetures.  Au mois de juillet, l'ONG China Labour Bulletin rapportait par exemple qu'une mine située dans la province nord-est de Jilin avait régulièrement caché des accidents et des morts au cours des deux dernières années. L'organisation pointe régulièrement le fait que les chiffres officiels sur le nombre de morts ne font pas état des "millions de mineurs qui ont contracté des pneumonies et d'autres maladies mortelles des poumons en travaillant dans les mines". Malgré le nombre important de victimes, des pollutions gigantesques, les écologistes si prompts à demander l’arrêt des réacteurs nucléaires, sont beaucoup plus discrets pour demander l’arrêt des forages en mer qui provoquent d’énormes pollutions ou d’usines utilisant ou fabricant des produits extrêmement toxiques. . Malgré toutes ces catastrophes industrielles qui ont occasionné de nombreuses victimes ou (et) des pollutions gigantesques endommageant gravement l’environnement, peu d’écologistes se sont manifestés pour réclamer l’arrêt de ces activités. Ainsi Dominique Voynet, si tenace pour obtenir l’arrêt de Superphénix, ne s’est pas sentie très concernée par la marée noire de l’Erika alors qu’elle était ministre de l’environnement. 6	Devenir des déchets nucléaires : 6.1	Position de l’IRSN  L’IRSN considère que la séparation/transmutation ne constitue pas une alternative au stockage géologique. En dépit de l’avancée des recherches qui se poursuivent aujourd’hui, il est vraisemblable que ces opérations ne seront pas réalisables à l’échelle industrielle dans un proche avenir ni applicables aux déchets déjà produits. Par ailleurs, la transmutation nécessite de déployer un parc de réacteurs dits de quatrième génération dont la conception est encore à l’étude. En termes de sûreté, de radioprotection et de gestion des matières et déchets radioactifs, le bilan entre les gains et les contraintes apportés par la transmutation est très déséquilibré, les gains apparaissant faibles en regard des fortes contraintes induites sur le cycle du combustible.  6.2	Projet d’enfouissement des déchets nucléaires Cigeo 6.2.1	Projet Cigeo à Bure: Un dossier globalement «très bon» mais reste la question des déchets bitumineux L’Autorité de sûreté nucléaire (ASN), le gendarme du nucléaire français, a rendu public son avis définitif sur le « dossier d’options de sûreté » du Centre industriel de stockage géologique (Cigéo) à Bure. C’est là, dans la Meuse, sous une épaisse couche d’argile que la France via l’Andra (Agence nationale pour la gestion des déchets radioactifs) souhaite enterrer 85.000 m3 de ses déchets radioactifs les plus dangereux. Les MA-VL, comme déchets de moyenne activité à vie longue, et les HA-VL, comme déchets de haute activité à vie longue, nocifs sur des centaines de milliers d’années. 6.2.2	« L’Andra nous a soumis un très bon dossier »  Le rapport rendu public ce lundi par l’ASN est une étape importante dans la validation technique du projet. Pierre-Franck Chevet, président de l’ASN, le rappelle ce lundi dans une interview au Monde. « L’Andra nous a soumis un très bon dossier, commence-t-il par indiquer au quotidien. Ce dossier confirme que la zone argileuse retenue possède les caractéristiques géologiques requises. Et il marque des avancées significatives en termes de sûreté. » 6.2.3	Le risque des déchets bitumineux Les déchets bituminés sont issus d’une ancienne technique de conditionnement de boues radioactives dans des matrices en bitume. « Ces produits de moyenne activité à vie longue représentent un peu plus de 40.000 « colis », soit environ 18 % des conteneurs destinés à Cigéo ». Le hic, c’est que le bitume peut s’enflammer dans certaines conditions notamment lorsqu’il est soumis à des fortes chaleurs. Or, ces déchets radioactifs sont susceptibles de monter en températures par réaction chimique. Cette éventualité d’un départ de feu dans les sous-sols de Cigéo, avec derrière, le risque d’un emballement thermique propageant l’incendie dans les alvéoles souterraines de stockage, « doit pouvoir être totalement écartée », estime le directeur de l’ASN.  Pour la grande majorité des déchets prévus dans Cigéo (plus de 80 %), l’ASN a considéré que les options de sûreté sont satisfaisantes. » 6.3	Alternative au procédé de traitement des déchets moyenne activité à vie longue Depuis la mise en service des usines de retraitement, les déchets liquides, issus de ces usines, à forte teneur en sodium inactif, sont traités par un procédé d’insolubilisation des éléments radioactifs, les boues contenant les éléments radioactifs issues de ce procédé étaient ensuite conditionnées dans une matrice bitume et le sont à ce jour dans une matrice ciment. Une alternative à ce procédé est de traiter le déchet liquide par évaporation, le distillat, après contrôle et respect des normes de rejet, est rejeté dans l'environnement et le concentrat contenant tous les sels actifs et inactifs doit être stocké en formation géologique, en raison de l'activité des radionucléides à vie longue (actinides, césium, strontium). . Des travaux, menés dans le cadre d'un contrat européen, permettent d'extraire les radioéléments à vie longue des concentrats acides à haute teneur en sodium afin de diminuer fortement le volume des déchets à stocker en formation géologique. Dans ce cas, seuls les radioéléments à vie longue après vitrification sont destinés à un stockage de type Cigeo. Les éléments inactifs et les radioéléments à vie courte, après conditionnement dans une matrice ciment peuvent être adressés au centre de stockage de surface de l'Aube.  6.4	Composition des déchets nucléaires  Un combustible à base d’uranium enrichi à 3,5% en 235U, pour un taux de combustion de 33 GWj/t, contient après les opérations de retraitement des actinides mineurs et de faibles quantités d’uranium et de plutonium (1,7%), des lanthanides (essentiellement cérium, praséodyme, néodyme, samarium, europium, gadolinium) et yttrium (18,2%), des métaux nobles (ruthénium, rhodium, palladium) (7,3%), métaux de transition (niobium, molybdène, technétium) (18,9%), alcalins et alcalino-terreux (rubidium, césium, strontium, baryum) (9,5%), chalcogènes (sélénium, tellure) (1,1%), et des éléments ajoutés lors des opérations de retraitement (43,2%). 6.4.1	Le tri des déchets radioactifs offre des avantages Les opérations de retraitement pratiqués de façon industrielle à l’usine de la Hague, se limitent à la récupération dans le combustible usé des réacteurs de l’uranium et du plutonium considérés comme des matières valorisables (procédé PUREX). Cette séparation offre des avantages. En enlevant l’uranium peu radioactif qui représente plus de 90 % de la masse du combustible usé, on réduit le volume des déchets. Le plutonium peut être brûlé en réacteur pour produire de l’énergie. Sa récupération diminue la toxicité radioactive et la chaleur dégagée du déchet. Restent les actinides mineurs qui constituent la quasi-totalité des éléments radioactifs à vie longue. 6.4.1.1	Séparation des lanthanides L’option de séparer les actinides mineurs à partir de la solution issue du procédé PUREX a été démontrée technologiquement à l’échelle de la dizaine de kilogrammes de combustible usé, en 2005, en vue de leur transmutation ultérieure. Elle pourrait s’accompagner de la récupération des lanthanides présents dans les produits de fission qui ont des propriétés chimiques très proches des actinides et qui sont très utilisés dans les nouvelles technologies, mettant le marché sous forte pression. Le seul élément problématique est le samarium qui possède un isotope à vie longue (151Sm de période 88,8ans). Pour mémoire, on retrouve des terres rares (lanthanides plus scandium, yttrium et lanthane) dans les batteries de voitures électriques et hybrides, dans les LED, les puces de smartphone, les écrans d'ordinateurs portables, les panneaux photovoltaïques, les éoliennes...  6.4.1.2	Séparation des platinoïdes Les quantités des trois métaux du groupe du platine, le palladium, le rhodium et le ruthénium, présents dans le combustible nucléaire irradié sont suffisantes pour constituer une ressource utile de ces métaux importants et rares. C'est particulièrement vrai pour le rhodium, qui revêt actuellement une grande importance stratégique et économique en raison de son utilisation dans les catalyseurs afin de réduire les émissions des véhicules. Des progrès ont été réalisés dans la mise au point de méthodes chimiques d'extraction des métaux du groupe platine des déchets nucléaires, mais la complexité chimique et la forte radioactivité des matériaux concernés rendent très difficile l'élaboration d'un procédé économiquement intéressant à ce jour. Même s'ils étaient complètement séparés chimiquement des autres produits de fission, les métaux du groupe platine dérivés du combustible nucléaire demeureraient intrinsèquement radioactifs. En revanche du fait de la décroissance radioactive, ces éléments auraient une activité négligeable dans 50 ans. 6.5	Capacité de retraitement de l’usine de la Hague  L’accord, signé vendredi, prévoit le retraitement du combustible nucléaire usé dans l’usine de la Manche jusqu’en 2040 ! Il assure ainsi la pérennité du site et de ses 3 000 emplois. Le spécialiste du recyclage des déchets nucléaires a signé un accord historique avec EDF. Celui-ci garantit le retraitement de 1 050 tonnes de combustibles usés par an, à partir de 2010 et jusqu’en... 2040 ! Environ 33 kg de produits de fission sont produits par tonne de combustible. Ils proviennent de la fission de l'uranium 235 et de celle du plutonium formé durant l’irradiation. Une partie des produits de fission a atteint la stabilité quand le réacteur est déchargé, mais le reste est très radioactif, d’où un stockage du combustible dans les piscines de la Hague en moyenne pendant 8 ans avant retraitement. Avec le retraitement de 1050 tonnes de combustible environ 35 tonnes de produits de fission peuvent être récupérées chaque année et plus si on utilisait des surrégénérateurs. 6.6	Le thorium, futur combustible nucléaire On peut faire fonctionner un réacteur nucléaire avec du thorium. Le déploiement de réacteurs brûlant du thorium repose cependant sur le fonctionnement des réacteurs actuels car le thorium lui-même n’est pas fissile. Il faut le transformer d’abord en 233U, qui est fissile, et on ne peut le produire au départ que dans des réacteurs à uranium. Les recherches se développent en Inde et en Chine, Les ressources en uranium sont telles qu’elles suffisent actuellement à l’industrie nucléaire. Mais il est clair qu’en cas de besoin le thorium pourrait contribuer grandement à l’approvisionnement énergétique de la planète. Une caractéristique intéressante des réacteurs au thorium est que les déchets produits ne contiennent pas d’actinides mineurs et ne produisent pas de plutonium, ce qui est un avantage dans la gestion à long terme des déchets. Des stocks importants de thorium résultant en particulier de l’exploitation des terres rares, auxquelles il est généralement associé, existent déjà dans le monde. Le projet de stockage des déchets radioactifs, à l’exception des déchets bitumeux dans les couches profondes Cigeo satisfait l’ASN. Ces déchets très décriés à cause des actinides mineurs à vie longue contiennent des éléments  qui pourraient intéresser les générations futures, il s’agit de certaines terres rares et de platinoïdes dont le rhodium extrêmement rare. 7	Rappel de l’intérêt des réacteurs à neutrons rapides 7.1	Pour une gestion durable des matières: pourquoi les réacteurs à neutrons rapides?  Les réacteurs à neutrons rapides (RNR) présentent plusieurs atouts déterminants vis-à-vis de la gestion des matières en complémentarité des filières existantes: • les RNR peuvent utiliser sans limitation le plutonium produit par les réacteurs à eau (ou par eux-mêmes) en tirant ainsi parti de son potentiel énergétique, assurant par là une gestion plus rationnelle et pérenne; • en permettant de valoriser dans son ensemble l’uranium extrait du sous-sol (tous ses isotopes, dont l’238U, isotope largement majoritaire), les RNR multiplient par un facteur voisin de 100, l’énergie que l’on peut extraire d’une masse donnée d’uranium naturel.  • les RNR ont la capacité, une fois constitué le stock nécessaire à leur démarrage, de se passer totalement d’uranium naturel. Ils n’ont besoin que d’un appoint d’238U (l’isotope non fissile de l’uranium, aujourd’hui non valorisé par les réacteurs à eau, et très majoritairement présent dans l’uranium appauvri issu des opérations d’enrichissement). Ainsi, alors que le parc nucléaire français consomme environ 8000 tonnes d’uranium naturel chaque année et laisse de côté 7000 tonnes d’uranium appauvri, un parc de RNR de puissance équivalente ne nécessiterait chaque année qu’environ 50 tonnes d’uranium appauvri (ou d’uranium issu des opérations de retraitement des combustibles MOX ou URE). Le stock d’uranium appauvri dont dispose la France sur le seul site de Pierrelatte, soit environ 250 000 t, lui assurerait une indépendance énergétique quasi inépuisable pour un parc de RNR; • le spectre des neutrons rapides ouvre aussi la possibilité de transmuter les actinides mineurs et permet donc d’envisager, si cela était décidé, une réduction de l’inventaire de ces radionucléides dans les déchets et de limiter par-là l’emprise du site de stockage profond des déchets nucléaires. Les RNR apparaissent donc comme un maillon essentiel d’une stratégie de cycle fermé, en permettant de tirer parti de la façon la plus aboutie des matières présentes dans les combustibles usés. 7.2	Les réacteurs à neutrons rapides de 4èmegénération Le Forum International «Génération IV» (GIF) a jeté les bases de la réflexion sur les systèmes nucléaires avancés au début des années 2000. Les principaux critères ont été définis (sûreté, économie, résistance à la prolifération et «durabilité», laquelle pointe l’intérêt du recyclage en RNR) et six systèmes identifiés comme particulièrement prometteurs. Il faut noter que la maturité technologique des concepts retenus par le GIF est très variable.  Pour le CEA, au vu des objectifs qui lui ont été assignés par la loi de 2006, l’effort se concentre en premier lieu sur les technologies de réacteurs à neutrons rapides refroidis au sodium (RNR‐Na), qui allient une maturité significative et un important potentiel de progrès. Le Groupe permanent d’experts pour les réacteurs nucléaires du 10 avril 2014 a confirmé qu’«à ce jour, parmi les différents systèmes nucléaires envisagés par le GIF, seul le système RNR-Na présente une maturité suffisante pour que la réalisation d’un prototype industriel de réacteur de 4ème génération soit envisageable dans la première moitié du XXIème siècle.» Sur la base des enseignements tirés des réacteurs précédents en France et à l’international, les acteurs français CEA, AREVA et EDF ont établi en 2007 un programme de recherche et développement visant à renforcer les points forts et à réduire les points de faiblesse de cette filière par des innovations technologiques importantes, ce qui a permis de lancer en 2010 les études de conception du démonstrateur technologique Astrid de RNR‐Na de 4ème génération. 7.3	Quel avenir pour le nucléaire ? Edouard Brézin, Physicien théoricien, membre de l'Académie des sciences A l'échelle mondiale, les prévisionnistes s'accordent à penser que la demande énergétique, du fait de l'accroissement de la démographie et de la demande des pays émergents (Chine, Inde, Brésil…), aura doublé à l'échéance 2050, même dans l'hypothèse où des pays comme le nôtre réussiraient par leurs mesures d'économie à réduire leur consommation. Simultanément, la réduction des gaz à effet de serre, impérative pour l'avenir de la planète, conduit à une équation impossible. Sans énergies renouvelables, telles l'éolien et le solaire, mais aussi sans énergie nucléaire, autant annoncer que le pire des scénarios de réchauffement devient inéluctable, avec son cortège de désertification, de montée des océans et d'événements climatiques de plus en plus catastrophiques. Il faut donc bien conserver de l'énergie nucléaire, mais celle-ci n'est compatible qu'avec des régimes politiques stables et pacifiques, et à la condition de disposer d'ingénieurs et de techniciens bien formés. L'Allemagne et l'Italie appartiennent bien à cette catégorie, et leurs choix énergétiques récents ne font pas que privilégier les énergies renouvelables par nature intermittentes, puisqu'ils impliquent également un recours massif au charbon et au gaz naturel. Il convient ensuite de se demander, en supposant que le nucléaire reprenne la croissance anticipée avant l'accident de Fukushima, si nous ne sommes pas menacés à brève échéance d'un épuisement des réserves d'uranium, principal composant actuel du combustible. Avec la technologie présente, les ressources minières disponibles seraient effectivement limitées à peut-être moins d'une centaine d'années. Mais avec celles, dites de «Génération IV», avec neutrons rapides, les ressources en uranium et en thorium connues dans le monde, permettraient de couvrir les besoins sur plusieurs milliers d'années. En effet plus de 99 % de l'uranium naturel, et l'intégralité de cet autre minerai qu'est le thorium, plus abondant que l'uranium, ne sont pas fissiles mais fertiles : ils ont la capacité d'absorber un neutron rapide et de se transmuter alors en produit fissile. Dans un réacteur à neutrons rapides on introduit donc ces éléments a priori inertes, et simultanément un émetteur de neutrons rapides pour les fertiliser. C'est ainsi que la France dispose déjà sur son sol des ressources nécessaires pour mettre en œuvre cette technologie avec l'uranium appauvri, aujourd'hui simple résidu inutilisé des opérations d'enrichissement, et avec le plutonium (émetteur de neutrons rapides) issu du retraitement des combustibles usés. De tels réacteurs produisent à peu près autant de plutonium qu'ils n'en consomment : ils se contentent donc de «brûler» l'uranium appauvri. Ces réserves énergétiques pourraient, sans aucune extraction minière, nous approvisionner en électricité pendant des siècles sans émission de gaz à effet de serre. Pour cette quatrième génération, de nouvelles idées pour renforcer la sûreté sont à l'étude, de même que sa capacité éventuelle à incinérer les déchets radioactifs les plus nocifs : c'est du domaine de la recherche qu'il est, à notre sens, urgent d'entreprendre pour assurer notre avenir énergétique pour la deuxième moitié du siècle. 7.4	Le programme Astrid Le démonstrateur technologique Astrid est destiné en premier lieu à démontrer à une échelle suffisante les avancées technologiques obtenues en qualifiant au cours de son fonctionnement les options innovantes, notamment dans les domaines de la sûreté et de l’opérabilité. Astrid est un démonstrateur d’intégration technologique, d’une puissance électrique de 600 MWe environ, permettant une démonstration de sûreté et de fonctionnement à l’échelle préindustrielle de RNR‐Na de 4èmegénération.  L’objectif est une mise en service au cours de la décennie 2020, en fonction des décisions qui seront prises par les Pouvoirs publics. L’exploitation d’Astrid pendant une dizaine d’années doit ensuite permettre le déploiement de réacteurs commerciaux, que l’on peut envisager au plus tôt au cours de la décennie 2040. Grâce aux innovations identifiées sur Astrid, il est possible d’atteindre des objectifs de sûreté équivalents à ceux fixés aux réacteurs EPR, tout en tenant compte du retour d’expérience de Fukushima et des spécificités liées à l’utilisation du sodium.  Contrairement aux réacteurs précédents (Phénix et Superphénix), Astrid ne sera pas surgénérateur mais iso-générateur, sans couvertures fertiles radiales, de manière à stabiliser le stock de plutonium sans l’accroître. 7.5	Collaborations internationales La plupart des grands pays nucléaires s’intéressent fortement à la technologie des réacteurs à neutrons rapides refroidis au sodium, sans forcément se positionner sur des critères de sûreté de 4ème génération. Ainsi, l’Inde devrait mettre en service dans les prochains mois un réacteur de puissance 500 MWe, et la Russie a démarré en juin 2014 un réacteur de 800MWe. La Chine est encore en retrait, mais affiche des ambitions importantes dans le domaine. Pour une gestion durable des matières: pourquoi les réacteurs à neutrons rapides?  La France était en tête de peloton dans le domaine des réacteurs à neutrons rapides, grâce à mesdames Lepage et Voynet et à monsieur Jospin elle est loin derrière la Russie, la Chine et l’Inde qui possèdent de tels réacteurs. Pourtant ces réacteurs ont un double intérêt, permettre la transmutation des actinides mineurs qui possèdent des isotopes à vie longue et réduire la durée de la nocivité des stockages. Autre intérêt de ces réacteurs, ils permettent d’utiliser le 238U présent à plus de 99% dans l’uranium naturel et appauvri dont les stocks sont abondants, assurant la production d’énergie pour la France pendant plusieurs centaines d’années. 8	Balance commerciale de la France et du Japon  8.1	Balance commerciale de la France en 2017  La Balance commerciale de la France est déficitaire depuis des décennies et se creuse ces dernières années, qu’en serait-il pour l’approvisionnement énergétiques du pays, si le nucléaire ne se substituait pas au gaz ou au pétrole ? : L'année 2017confirme la tendance observée en 2016 d'un déficit commercial qui se creuse pour la France, après une amélioration constatée depuis 2011. Le solde commercial en novembre avait atteint 5,7 milliards d'euros, contre 5,3 milliards le mois précédent. Sur douze mois, le déficit cumulé de la France a atteint 62,6 milliards d'euros, contre 48,2 milliards en 2016, année qui avait marqué un coup d'arrêt. 8.2	Balance commerciale du Japon après l’accident de Fukushima Un an après la catastrophe de Fukushima, le commerce extérieur japonais ne s’est pas encore relevé. Le Japon a déploré un déficit commercial record pour l'année budgétaire suivant le séisme du 11 mars 2011 : le solde de la balance commerciale a atteint un plus bas depuis 1979. La catastrophe, doublée de l'accident nucléaire de Fukushima avait conduit à stopper la plupart des réacteurs et obligé les compagnies à importer davantage d'hydrocarbures. Les comptes du commerce extérieur du japon ont affiché un solde négatif historique (près de 42 milliards d'euros) pour la période d'avril 2011 à mars 2012. Le commerce extérieur japonais, qui dégage généralement un excédent substantiel, a enduré un déficit durant huit des douze mois considérés, avec un niveau historique en janvier 2012, période de l'année qui est souvent déficitaire mais l'a cette fois été comme jamais. Les importations ont bondi de 10,5% au cours des 12 mois à mars. Pour l'ensemble de l'année d'avril 2011 à mars 2012, les importations du Japon ont augmenté de 11,6% par rapport à celles de l'an précédent, à 658 milliards d'euros, à cause d'un bond du montant parfois record des achats de pétrole brut, produits pétroliers et gaz naturel liquéfié, carburants nécessaires pour faire turbiner les centrales thermiques et compenser l'absence d'électricité d'origine nucléaire. 8.3	La France prône une fabrication 100% hexagonale  Difficultés d'approvisionnement et de qualité, la délocalisation de la fabrication des principes actifs des médicaments en Asie suscite l'inquiétude en France. Les fabricants de matières premières appellent à relocaliser, tandis que les autorités sanitaires veulent renforcer les contrôles des sites étrangers.  80% des principes actifs des médicaments occidentaux sont fabriqués en Chine, en Inde et au Brésil. Sur les 20% restants, 30 à 40% viennent en France. Le reste venant principalement des autres pays européens. Une situation qui inquiété au point de pousser l'Académie nationale de Pharmacie et les industriels fournisseurs de matières premières de médicaments à tirer le signal d'alarme. 8.3.1	Des problèmes de qualité et d'approvisionnement  Mais les acteurs français s'inquiètent. Car cet éclatement de la chaîne de production rend difficile le suivi de la fabrication des matières premières par les laboratoires pharmaceutiques ou les autorités sanitaires. Il pose surtout des problèmes de qualité. Ainsi, sur 20 sites s'étant vus refusés ou retirés par l'Europe leur certificat de bonnes pratiques de fabrication, 75% seraient des fournisseurs indiens ou chinois. Ils posent aussi des problèmes d'approvisionnement. Au premier semestre, l'autorité française du médicament (Afssaps) a alerté sur 31 risques ou ruptures de stock, contre 4 un an auparavant et 2 au premier semestre 2009. L’arrêt des réacteurs nucléaires, en 2011 suite à la catastrophe de Fukushima, a entrainé un déficit de la balance commerciale du Japon, alors qu’elle est régulièrement excédentaire. Sans énergie nucléaire à combien séleverait le déficit de la balance commerciale de la France ? 9	Le problème des métaux rares et des terres rares  Les ressources naturelles sont une source de dynamisme industriel pour les pays producteurs, tandis que les pays consommateurs sont entrés dans une consommation compétitive. C'est pourquoi je propose, sans tarder, de revoir ce que devrait être, selon moi, une doctrine nationale sur les matières premières minérales avant de discuter d'un scénario lié à la politique énergétique allemande. 9.1	Définitions Trois éléments forment la base d'une doctrine nationale sur les produits de base : l'indépendance énergétique, l'autosuffisance alimentaire et l'indépendance minérale. L'absence de l'un d'eux empêche le développement économique durable. 9.1.1	Qu'est-ce qu'une ressource critique ? Il s'agit d'une ressource pour laquelle les risques industriels associés à une pénurie d'approvisionnement sont élevés et pour laquelle il n'existe aucune substitution possible. Un sujet sera critique dans une industrie mais pas dans une autre, dans un pays mais pas dans un autre et cela évolue avec le temps. 9.1.2	Qu'est-ce qu'une ressource stratégique ? C'est une ressource indispensable pour la politique de l'État ou la défense nationale. Là encore, un sujet sera stratégique dans un pays, mais pas dans un autre, et cela évolue avec le temps. En France, il n'y a pas de matière stratégique sauf l'uranium. Au niveau européen, pas de politique commune ou de défense commune qui justifierait cette liste. La Chine, les États-Unis, la Corée et le Japon ont une liste de métaux stratégiques. c) Quelles industries consomment ces matériaux ? L'exemple des aimants permanents à base de terres rares illustre une consommation croissante. Composés principalement de néodyme, de dysprosium et de praséodyme, leurs exigences étaient de quelques grammes dans les ordinateurs, mais elles sont maintenant de 200 grammes pour un vélo électrique, de 1-2 kg pour une voiture électrique et de près de 200 kg/MW pour les éoliennes à entraînement direct. 9.1.3	Pourquoi l'offre de métaux critiques ne répond-elle pas immédiatement à la demande ? Dans les prévisions de production, le raisonnement simpliste tient compte des ressources disponibles dans la croûte terrestre sans égard aux réserves économiques à découvrir ou aux modèles d'extraction. Bien que parfois ces métaux ne soient pas rares, ils sont des coproduits d'autres métaux importants et certaines de ces chaînes de production sont opaques.  Parfois, les mines de métaux majeurs sont insuffisantes, ou en fin de vie, et le renouvellement minier n'a pas été préparé : les futurs gisements n'ont pas été recherchés, donc pas encore découverts, une mine nécessite 10 à 20 ans de travail avant production. Le recyclage de ces métaux dans le cycle industriel est l'étape la plus simple. Ensuite, une attente de parfois 20 ans précédera le recyclage des produits porteurs. De plus, sur ces derniers, les dépôts de matériaux sont parfois si minces, les alliages si complexes ou les teneurs si faibles, voire toutes à la fois, que nous ne pourrons pas bien les récupérer. Le recyclage à lui seul ne suffira donc pas à satisfaire les besoins des consommateurs. Le dynamisme des sociétés énergétiques et minières se mesure par leurs investissements dans l'exploration et/ou l'acquisition de nouveaux gisements. L'industrie minière française est décevante. Faute de vision, elle est restée prostrée, petite et figée pendant que des géants miniers naissaient ailleurs.  Un nouveau point de départ sur notre territoire serait encore possible. L'ouverture de petites mines par des PME innovantes d'exploration dans les Pyrénées, le Massif Central et la Bretagne pour le cuivre, le zinc et l'étain à partir du tungstène permettrait la production moderne de co-produits " métaux stratégiques " tout en respectant l'environnement. Par ailleurs, à l'exception des bassins miniers, l'horizon géologique français n'est pas connu en dessous de 100 mètres. Des mines sont exploitées en Europe à des profondeurs allant jusqu’à 1000 mètres, voire 4000 mètres en Afrique du Sud. En France, le contexte géologique de la Bretagne, du Massif Central et des Vosges est favorable, une exploration profonde du sous-sol peut permettre de découvrir des gisements plus importants. Le premier obstacle à la prospection en France est qu'aujourd'hui nous n'écoutons plus la parole de l'ingénieur. La seconde est administrative : le nouveau code minier adoptera le principe des enquêtes publiques du code de l'environnement, mais ces innovations n'ont pas encore été formalisées. En outre, l'activité minière est isolée au sein du ministère de l'Environnement et n'est pas intégrée au ministère de l'Industrie 9.1.4	Stocks stratégiques Qui a des actions ? La Chine, le Japon, la Corée du Sud, les États-Unis, mais aussi les États du Moyen-Orient ou d'Asie pour l'alimentation...... La France avait constitué un stock stratégique de métaux, mais il a été vendu au cours de la dernière décennie du XXe siècle. On dit que les règles d'engagement ont été oubliées et que les marchés publics ont été l'un des dividendes de la paix après la chute du mur de Berlin. La guerre économique n'avait pas été anticipée. 9.2	Indépendance énergétique de l’Allemagne En 2011, l'Allemagne dispose d'une puissance installée d'environ 102 GW et d'un mix électrique composé à 58% de carbone (lignite, charbon, gaz), 20% d'énergies renouvelables et 21% nucléaire. D'ici 2022, elle prévoit de fermer ses 21 centrales nucléaires, tout en réduisant la consommation et en augmentant la part du charbon, du gaz et des énergies renouvelables (35 %), en particulier l'énergie éolienne. A l'avenir, les éoliennes surpuissantes seront majoritaires : en 2009, 60 % des éoliennes étaient inférieures à 2 MW ; en 2012, 70 % sont supérieures à 2MW. Les grandes éoliennes offshore sont en plein développement et chacune d'entre elles utilise des terres rares qui permettent des nacelles compactes et une maintenance réduite. L'Allemagne prend conscience de sa dépendance à l'égard des métaux critiques et, l'an dernier, un petit explorateur minier a été formé par de grands groupes allemands pour découvrir et réserver des gisements futurs de trois éléments (terres rares, tungstène, coke de charbon). Le gouvernement allemand financera l'exploration minière, mais les sociétés seront responsables de l'exploitation. Deux questions s'imposent : Comment gérer le dépannage des éoliennes offshore en cas de tempête hivernale ? Combien cela coûtera-t-il ? Avec 35 % d'énergie renouvelable, nous sommes dans le ruban électrique et non plus dans la dentelle. Le junior allemand fera-t-il face au nationalisme des ressources naturelles des pays qu'il prospectera ? Deux idées ouvrent deux discussions. Dans l'esprit de certains, voitures électriques, éoliennes ou panneaux solaires signifient une indépendance partielle ou totale vis-à-vis de l'uranium, du charbon, du pétrole ou du gaz. Mais ils ne se rendent pas compte qu'ils deviennent dépendants du lithium, de l'indium, du gallium, des terres rares, etc.  Deuxièmement, je voudrais poser une question  à dire lentement et à méditer longuement : s'agit-il d'une politique énergétique plus risquée que l'énergie nucléaire de fonder son développement économique sur des énergies renouvelables encore immatures, notamment l'énergie éolienne, avec des modèles météorologiques qui deviennent obsolètes avec les changements climatiques ? Une réponse est évidemment le rejet du bipolaire - avec ou sans énergie nucléaire, avec ou sans énergie renouvelable - et l'acceptation du multipolaire : l'énergie renouvelable doit progresser, surtout l'énergie solaire, et l'atome conserve un avenir qui est dans l'atome lui-même. S'il n'y avait que deux éléments à retenir, ce serait l'indépendance et l'accès aux ressources. Si la consommation française de métaux critiques augmente, la France devra devenir indépendante, prendre en charge et ouvrir des mines sur son territoire. Le secteur minier de demain sera caractérisé par de nouvelles campagnes d'exploration, des teneurs plus faibles, des coûts plus élevés en raison d'une consommation accrue d'énergie et d'eau et des règlements environnementaux plus stricts. En France, nous avons l'énergie, l'eau, les infrastructures et l'écologie. Dans notre pays, les mines seront principalement des emplois, elles seront profondes, non polluantes et elles proposeront une solution pour le renouvellement de l'industrie. Si les mines françaises sont insuffisantes, il faudra accéder aux ressources à une nouvelle profondeur géologique. La France doit se préparer dès à présent à une éventuelle pénurie de métaux en lançant des campagnes d’exploration sur l’ensemble de son territoire en particulier en prospectant à des profondeurs plus importantes, mais aussi en améliorant le recyclage des métaux. 10	Réduction des énergies carbonées dans le chauffage des habitations  Près de 50 % de l’énergie primaire provient des combustibles fossiles, en particulier du pétrole dont il faudra réduire la consommation pour atteindre les objectifs de la loi sur la transition énergétique :  10.1	Consommation d’énergie dans des bâtiments  Le secteur du bâtiment (résidentiel-tertiaire) pèse pour 44% dans la consommation énergétique finale française, tout secteur confondu (transports, agriculture, sidérurgie, industrie) : 68,7 MTep en 2012, sur 154,4 MTep d’énergie finale consommée, à climat normal. La part de chaque énergie consommée dans le résidentiel-tertiaire est la suivante : 37% d’électricité, 32% de gaz, 16% de pétrole, 15% d’énergies renouvelables thermique et déchets (la valorisation énergétique des déchets est comptée comme étant à moitié renouvelable et moitié non renouvelable, le terme “EnRt et déchets” inclut donc la totalité de la valorisation énergétique des déchets) 10.2	Le remplacement du chauffage au fioul des habitations par le chauffage électrique est un moyen drastique de réduire les rejets de CO2 dans les villes :  La réduction des émissions de gaz à effet de serre conformément à l’accord de Kyoto et à la politique de l’Union européenne, passe sans aucun doute par la limitation des émissions directes de dioxyde de carbone (CO2) des ménages. Ainsi, les 2 sources principales de ces émissions sont, par ordre d’importance décroissante, les logements et les navettes vers le lieu de travail. Les logements émettent en moyenne 3.150 kg de CO2 par an, voire 4.200 kg de CO2 par an sous les climats montagnard et semi-continental. […] Les maisons individuelles des pôles urbains, souvent anciennes et chauffées au fioul, émettent plus de CO2 que celles du périurbain, plus récentes et souvent dotées d’un chauffage 100 % électrique. À l’inverse, les émissions liées aux navettes sont plus importantes dans le périurbain, où les besoins de transport sont importants mais l’offre de services de transports réduite. Pour une maison individuelle, le chauffage au fioul émet 7 fois plus de CO2 que le chauffage électrique 10.3	Inconvénients liés à l’utilisation du fioul pour le chauffage des habitations : Le fioul reste le recours majoritaire des Français pour le chauffage domestique individuel. Pourtant, il présente un bilan sanitaire et écologique inquiétant. C’est pourquoi le gouvernement prévoit d’accompagner la transition des ménages souhaitant remplacer leur chaudière par des moyens alternatifs de chauffage. 10.3.1	Des contraintes sérieuses pour la santé et l’environnement  La combustion du fioul rejette des quantités importantes de CO2 (300 g par kWh), avec les conséquences sur le climat qu’on connait. Mais il dégage aussi durant sa combustion des oxydes de soufre, des oxydes d’azote et des particules fines, toxiques à la fois pour l’homme et l’environnement. 10.3.2	Les alternatives émergentes : le chauffage au bois et la pompe à chaleur  Le chauffage au bois est une alternative populaire pour remplacer sa chaudière au fioul. mais la combustion du bois est tout de même très polluante. Comme n’importe quel combustible, le bois qui brûle crée de la pollution :  Une autre alternative pour chauffer un logement est la Pompe à chaleur (PAC). Si ces appareils sont relativement récents, et à ce titre présentent encore un coût d’installation élevé, ils n’en sont pas moins le moyen le plus écologique et le plus économique pour se chauffer en France. La PAC air/air, qui capte l’énergie à l’extérieur de l’habitation, et la PAC géothermie, qui capte l’air souterrain, pour l’injecter à l’intérieur du bâtiment afin de réguler la température. L’électricité consommée par une PAC sert principalement à faire fonctionner le compresseur, et produit entre 2 et 4 fois plus de chaleur que l’énergie électrique nécessaire à son fonctionnement. Le chauffage des habitations exige beaucoup d’énergie, actuellement beaucoup de fioul et de gaz, pour réduire les rejets de CO2, de divers polluants et de particules fines, la solution réside dans l’utilisation de pompes à chaleur, relativement onéreuses. 11	Réduction des énergies carbonés et de la pollution dans les transports 11.1	Empreinte carbone de différents types de transport L’empreinte carbone permet de mesurer le taux d’émissions de gaz à effet de serre (GES) d’un trajet, ce taux correspond aux gaz émis lors du trajet en lui-même, mais englobe également toute l’énergie dépensée pour sa mise en œuvre (l’amortissement d’une voiture, l’entretien d’un train, etc.). Un avion rejette en moyenne 360 g équivalents CO2 pour 1 km, contre 150 g/eqCO2 pour une voiture et 11 g/eqCO2 pour un train. Contrairement à ce qui se fait en France depuis de nombreuses années, il serait intéressant de développer et d’électrifier le réseau ferroviaire, même si l’investissement pour ces opérations est élevé. 11.2	Pollutions dues aux navires 11.2.1	Electrification des navires à quai  A Marseille, après La Méridionale, c’est au tour de la compagnie Corsica Linea d’équiper ses navires d’un système d’alimentation électrique de courant à quai. Ce système, permet aux navires d’être branchés à quai 30 minutes après le débarquement des passagers et débranchés 2 heures avant l’appareillage : ainsi alimentés en électricité, le recours aux moteurs au fioul, ressource fossile polluante, n’est donc plus nécessaire. Il faudrait 100 mégawatts pour connecter tous les navires en même temps L’installation de ce système a nécessité une enveloppe budgétaire de plus de 8.5 millions d’euros : 5 millions ont été nécessaires pour financer les installations portuaires et 3,5 millions d’euros ont été investis dans l’équipement des navires. Ce système électrique innovant a permis de réduire de 30% la consommation de carburant de la flotte en un an. Les économies réalisées sont évaluées entre 2 et 4 tonnes de fioul par ferry et par escale quotidienne. Autres moyens de réduire la pollution des navires : A quai, les navires stationnant plus de deux heures non équipés d’un système d’alimentation électrique de courant à quai sont tenus de passer au diesel marin contenant un taux de 0,1% de SOx ce qui représente encore un taux 100 fois plus élevé que le diesel des voitures (0.001% de soufre). Quant aux émissions de noir de carbone et de NOx, elles restent très élevées et elles ne sont pas couvertes par la réglementation. De plus, les bateaux basculent au fuel lourd dès leur sortie du port.  Selon l'institut de recherche néerlandais CE Delft, l'approche la plus écologique pour un navire consiste à installer des filtres à particules et des systèmes de réduction catalytique sélective (SCR). Ces SCR convertissent les émissions de NOx en azote et en eau. Ces équipements peuvent être combinés à l'utilisation de combustibles moins polluants tels que le gaz naturel liquéfié (GNL) ou le diesel marin.  11.2.2	Des mesures ''low tech''  Les solutions ne sont pas seulement technologiques. Ralentissement des navires à l'entrée des ports, pilotage plus efficace et économe en carburant, les exemples de bonnes pratiques abondent. A Long Beach et au port de Los Angeles, les frais de stationnement sont réduits de 25% pour récompenser la vitesse réduite à l'approche. 11.2.3	Créer une zone de protection de l'air en Méditerranée En France, le ministère de la transition écologique et solidaire se veut en pointe sur le sujet. Il a lancé une étude sur l'opportunité d'instaurer des zones de protection contre le soufre et les oxydes d'azote dans les eaux du Sud de l'Europe, pilotée par l'Institut national de l'environnement industriel et des risques (Ineris).  Neuf navires porte-conteneurs propulsés au GNL ont été commandés par la compagnie CMA-CGM. Corsica Linea envisage de convertir ses ferries au gaz, considéré comme un carburant de transition.  Poursuivre l’électrification des navires à quai, imposer aux bateaux de s’équiper en SCR et d’utiliser des carburants à faible teneur en soufre, ces mesures devraient être imposées aux armateurs rapidement. 11.3	Le Trolleybus : Connu, Opérationnel... Mais avec des fils Le trolleybus est un véhicule électrique qui ne rejette donc aucun gaz nocif. En prenant en compte l’impact de la production d’électricité, et de la bi modalité optionnelle du matériel, on peut estimer la production moyenne de CO2 d’un trolleybus à 4 g / km / voyageur contre 40 pour un autobus et 60 pour une automobile. […] 11.3.1	Un véhicule puissant adapté aux profils urbains  La chaîne de traction électrique procure des performances supérieures à celles des moteurs thermiques sur les itinéraires difficiles à fortes pentes : en rampe de 10 %, les trolleybus modernes dépassent les 40 km/h alors que les autobus thermiques de puissance équivalente atteignent environ 30 km/h. Les trolleybus présentent donc un avantage déterminant sur les réseaux de villes à la topographie tourmentée faite de collines et de vallons, en améliorant la vitesse commerciale. Les trolleybus sont également adaptés aux itinéraires très urbains comprenant des arrêts fréquents et des vitesses de pointes basses, plages dans lesquelles la consommation de gasoil des autobus est maximale. Les accélérations sur des trolleybus modernes concilient souplesse et performance : sur une séquence de démarrage de 15 secondes, un trolleybus parcourt une distance supérieure de 30% à celle d’un autobus. Ainsi, le parc nécessaire en trolleybus serait inférieur de 5 à 7% à celui requis par un service en autobus. Le rendement énergétique du trolleybus s'élève, d'après une étude réalisée sur le réseau canadien de Vancouver, à 9,8 Mégajoules/km-véhicule contre plus de 24 pour l'autobus. La consommation d'énergie atteint en moyenne 25 kWh par place-kilomètre offerte contre 75 pour les derniers autobus produits. […] 11.3.2	Un véhicule fiable et durable La durée de vie moyenne d’un trolleybus est de l’ordre de 25 ans, soit le double de celle d’un autobus. […] Autre avantage du trolleybus, notamment par rapport aux autobus électriques : il s’affranchit des batteries, qui constituent non seulement un poids mort, mais aussi de la question de leur renouvellement. Sur une carrière de 25 ans, le trolleybus n’a pas réellement besoin de modifications lourdes de sa chaîne de traction. Les seules batteries dont il a besoin sont d’abord liées aux auxiliaires (éclairage, chauffage, climatisation…). Souplesse d’exploitation Bien que dépendant de lignes aériennes d’alimentation, le trolleybus peut circuler librement : la capacité de déport par rapport à l’axe de la ligne est de l’ordre de 4 mètres ce qui lui permet d’éviter un obstacle. […] 11.3.3	Le trolleybus, à quel coût ?  Le trolleybus est un mode de transport routier dont la capacité horaire de transport varie, selon le type de véhicules et la fréquence de l’offre, entre 800 et 2000 places / heure / sens, c’est à dire en dessous du seuil de pertinence du tramway. Le coût d’acquisition d’un trolleybus est certes deux fois supérieur à celui d’un autobus diesel, mais sa durée de vie est également deux fois plus longue. Par rapport à un autobus électrique, l’écart devient marginal, et il s’affranchit de l’achat - ou de la location - des batteries.  Le trolleybus moderne est équipé d’un système de freinage à récupération d’énergie ce qui lui permet de réinjecter du courant dans les lignes aériennes : alors que l’autobus transporte sa propre source d’énergie, le trolleybus mutualise l’énergie disponible et cette mise en réseau est source d’économie : sur les lignes desservant le plateau croix-roussien à Lyon, trois trolleybus descendant fournissent par la récupération l’énergie nécessaire à un véhicule montant. Dans une approche qualitative globale de l’environnement urbain, la présence de ligne aérienne est compensée par une réduction importante des nuisances sonores et olfactives ainsi que l’absence de rejets de particules. Le métro, le tramway, l’autobus sont les moyens de transport utilisés dans les villes. Les deux premiers moyens de transport présentent l’inconvénient de nécessiter de gros investissements énergivores lors de leur construction. L’autobus doit être électrifié si on désire réduire fortement les émissions de CO2, mais cela nécessite l’utilisation pour leur fonctionnement de batteries qui nécessitent beaucoup d’énergie lors de leur production. Le trolleybus, ne nécessite pas de gros investissements ni l’utilisation de batteries, en revanche il présente l’inconvénient de nécessiter des réseaux de câbles peu esthétiques. Pour réduire l’empreinte carbone, il est important d’utiliser des moyens de transport directement reliés au réseau électrique.  12	Voitures du présent et du futur 12.1	Automobile : la course sans fin à la puissance Jamais les voitures vendues sur les marchés français et européens n'ont eu autant de chevaux. Une tendance très présente dans le haut de gamme. En 2015, jamais les véhicules vendus sur le marché français n'auront été aussi puissants. Ils développent désormais, en moyenne, 113 chevaux, contre 110 l'année dernière et 91 il y a quinze ans à peine... Le temps est loin où les blocs de moins de 60 chevaux - aujourd'hui disparus - représentaient encore le quart du marché français, comme en 1996 ! La tendance est encore plus nette au niveau européen : les voitures vendues en 2015 y développent en moyenne 126 chevaux. Avec des pics au Royaume-Uni (133 chevaux) ou en Allemagne (143), voire la Suisse (160). 12.2	L’Allemagne tait le nombre d'accidents sur les autoroutes à vitesse libre  Berceau des constructeurs de grosses cylindrées, l'Allemagne redouterait en réalité que les données d'accidentalité soient une contre-publicité pour la vitesse. Les antiradars, les pourfendeurs des vitesses libres ne jurent que par l'Allemagne. Notre voisin d'Outre-Rhin est la preuve vivante, selon eux, que la vitesse n'est pas cause d'accidents. La limitation n'existe pas sur leurs autoroutes et il y a moins d'accidents, assurent-ils.  En réalité, sur l'ensemble du réseau allemand, il n'y a qu'un faible tronçon où l'on peut rouler sans devoir surveiller le compteur. 388 km exactement. L'Allemagne garde jalousement ses données d'accidentalité, notamment celles portant sur ces fameux 388 km…. Car le nombre de sinistres recensés sur ces 388 km a finalement été divulgué par l’ ancien délégué interministériel à la sécurité routière Sur ce segment où la vitesse est libre, l'accidentalité est trois fois plus forte que celle en France. 12.3	Des voitures alourdies Les raisons de cette course aux chevaux sont multiples. « L'évolution du poids des véhicules est un facteur important. Equipements de sécurité, électronique embarquée, systèmes de dépollution, électrification de la chaîne de traction (batteries)... Les voitures se sont alourdies du fait d'ajouts incessants d'équipements. D'où l'intégration de moteurs toujours plus puissants pour permettre de déplacer avec agilité ces mastodontes, parfois proches des 2 tonnes. Si depuis deux-trois ans, les constructeurs, mis sous pression par les normes environnementales, ont réellement commencé à alléger les modèles, la tendance n'est pas encore massive, d'autant que les clients plébiscitent les carrosseries plus volumineuses (cross over, SUV...), qui nécessitent des puissances embarquées en hausse. 12.4	Voitures économes en énergie La voiture électrique est une voiture onéreuse du fait de l’utilisation de batteries sophistiquées. Avant que son utilisation se généralise et atteigne des prix abordables, il serait judicieux, plutôt que de fabriquer des voitures inutilement performantes, d’assurer la transition en fabriquant des véhicules fonctionnant avec une très faible consommation de carburants et si possible de biocarburants. Alors qu’en France aucun véhicule particulier n’est censé dépasser la vitesse de 130 km/h, les catalogues des constructeurs offrent des véhicules qui, tous, absolument tous même les « bas de gamme », sont capables de vitesses très supérieures à cette limite. Certains peuvent même rouler à deux fois la vitesse limite absolue imposée ! Pour une vitesse max de 140 km/h par exemple, une voiture de type Peugeot 308 pourrait se « contenter » d’un moteur de 43 CV (32 kW) ; afin qu’elle soit capable de monter aisément les côtes, sa puissance pourrait être de 50 kW (70 CV). On imagine sans peine les économies de carburant et de coût qu’il serait possible de réaliser … En effet, la conception des véhicules de transition hybrides ou tout électriques doit tenir compte des possibilités de la technologie des batteries et des infrastructures nécessaires au rechargement: La capacité spécifique globale des batteries lithium-ion pour l’automobile est actuellement de 100 Wh /kg, en tenant compte du poids des cellules, du contenant, des accessoires de mise en œuvre et de contrôle, et des pièces de renforcement de la carrosserie pour supporter le surpoids de la batterie. Pour une voiture tout électrique il n’est pas possible de consacrer plus de 300 kg au poids de la batterie, ce qui limite sa capacité à 30 kWh. Le transfert de cette énergie vers les roues du véhicule se réalise avec un rendement de l’ordre de 85 %. L’énergie transférable est donc de 25,5 kWh environ avant épuisement de la batterie. Une voiture de type Peugeot 308 a besoin de 25 KW pour rouler à 130 km/h. Si elle était équipée en tout électrique avec une batterie de 30 kWh son autonomie serait donc limitée à 1,2 h à cette vitesse, soit 156 km. On retrouve le même problème sur la Renault ZOE, tout électrique équipée d’une batterie de 22 kWh, dont 20 kWh utilisables. Elle a besoin également d’environ 25 kW pour rouler à 130 km/h, son autonomie à cette vitesse sera donc de 50 minutes, soit 108 km. Ceci démontre que la voiture tout électrique n’est pas un véhicule routier. Elle le deviendra le jour où l’on pourra produire l’électricité à bord avec une pile à combustible.  Ce problème d’autonomie limitée par la capacité de la batterie a conduit les constructeurs à limiter la vitesse max de leurs autos électriques pour conserver une autonomie décente. Et donc de limiter également la puissance des moteurs électriques à la valeur que nous avons calculée plus haut, autour de 50 kW. Cette unanimité autour de 60 kW, imposée par la faible capacité spécifique des batteries, pourrait devenir la norme aussi pour les voitures à moteurs thermiques.  12.5	La voiture "zéro émission" est encore une illusion La voiture "zéro émission" est encore une illusion. Que ce soit au moment de sa fabrication ou à l'usage, le véhicule électrique a une incidence sur l'environnement. Il déplace en fait la pollution plus qu'il ne la supprime. Ce n'est pas parce qu'elle n'émet pas de CO2 en roulant qu'elle ne pollue pas. La voiture électrique n'est pas aussi propre que pourraient le laisser croire le bonus écologique. 12.5.1	Une pollution déplacée mais pas éliminée : Les experts de l’ADEME n’éludent pas la pollution générée pendant sa phase de fabrication. Ils écrivent ainsi dans un rapport publié en 2016 : "La voiture électrique consomme moins d'énergie que la voiture thermique car sa chaîne de traction présente un excellent rendement énergétique. Malgré cela, sur l’ensemble de son cycle de vie, la consommation énergétique d’un véhicule électrique est globalement proche de celle d’un véhicule diesel." Il faut en effet deux fois plus d'énergie pour construire (matière première, transport des pièces détachées, assemblage) une voiture électrique qu'une voiture thermique. En cause : la fabrication des batteries extrêmement énergivore.  Les méthodes d'extraction du lithium et du cobalt, utilisées pour fabriquer les batteries peuvent poser problème non seulement sur le plan environnemental mais aussi sur le plan éthique. Produire du lithium, essentiellement en Amérique du Sud, nécessite d'utiliser une grande quantité d'eau et d'introduire des produits chimiques dans les sols. En République démocratique du Congo, qui a fourni en 2017 les deux tiers des exportations mondiales de cobalt, les mines sont parfois exploitées dans des conditions déplorables par une main d'œuvre notamment composée d'enfants : 12.5.2	Réchauffement climatique : le bilan carbone des batteries La voiture électrique réduit la contribution de l'automobile au réchauffement climatique même si rouler à son bord implique de rejeter des gaz à effet de serre non pas quand le moteur tourne mais pour alimenter les batteries. Sur l'ensemble de son cycle de vie, le véhicule électrique émet l'équivalent de 9 tonnes de CO2 contre 22 tonnes pour un véhicule thermique, selon l'ADEME. Ces chiffres sont donnés pour la France où l’électricité, qui provient aux trois-quarts du nucléaire, est peu carbonée (contrairement à celle issue des centrales à charbon). 12.5.2.1	Qualité de l'air : la formation de particules même sans pot d'échappement Si la voiture électrique n'émet pas quand elle roule de composés organiques volatils (COV) ou d'oxyde d'azote même sans pot d'échappement, elle émet des particules fines issues de l'usure des pneus, des plaquettes de frein, des routes. Cette abrasion est responsable de 41% des émissions du secteur du transport routier.  12.5.2.2	Fabrication des batteries : la question de l'extraction des métaux rares Les méthodes d'extraction du lithium et du cobalt, utilisés pour fabriquer les batteries Li-on, peuvent poser problème non seulement sur le plan environnemental mais aussi sur le plan éthique. Produire du lithium, surtout en Amérique du Sud, nécessite d'utiliser une grande quantité d'eau et d'introduire des produits chimiques dans les sols. Les mines de cobalt, surtout en Afrique, sont quant à elles parfois exploitées dans des conditions déplorables par une main d'œuvre notamment composée d'enfants.  La France et le Royaume-Uni ont annoncé leur intention d'interdire les ventes de voitures à moteur à combustion à horizon 2040. La Ville de Paris bannit les vieux diesels. Mais il y a des obstacles : -	le premier est la batterie, car la voiture électrique nécessite des métaux qui jouent un rôle clef dans leur fabrication. Le prix du lithium a triplé en trois ans, celui du cobalt a pratiquement doublé en un an. Quel sera le prix de la batterie si toutes les voitures sont équipées de moteurs électriques ? Cobalt et lithium présentent deux autres caractéristiques ennuyeuses. D'abord, leurs ressources ne sont pas infinies. Avec ce qui est relativement accessible, il y a de quoi équiper le parc mondial une ou deux fois... mais pas au-delà. Ensuite, leur production consomme beaucoup d'énergie, tout comme leur recyclage. Selon Jean-Marc Jancovici , une voiture électrique qui roulera 200.000 kilomètres aura émis 50 grammes de CO2 au kilomètre... avant même d'avoir roulé le premier mètre ! Pour réduire les émissions de C02, il faut que l'énergie employée pour produire la batterie soit elle-même décarbonée. Pas évident : la première grande usine de batteries en Europe est prévue en Pologne, là où le charbon pèse le plus lourd dans la production électrique. -	le deuxième qu'est la production d'électricité. Car la charge des batteries en exige d'énormes quantités. Un ordre de grandeur : pour charger 1 % du parc français la nuit, pendant que les automobilistes dorment, il faut pratiquement la production d'une tranche nucléaire. Comme c'est un moment de la journée où le soleil ne tombe plus dans le panneau, et où le vent est souvent tombé, il faudra construire de nouvelles centrales nucléaires... ou carbonées.  -	le troisième est le transport de cette électricité. La borne de recharge n'est que le petit bout de la lorgnette. Un dépôt de 200 bus à charger la nuit demande la puissance de 50 immeubles de cinq étages.  12.6	Imposer la technologie du véhicule électrique est une folie, estime Carlos Tavares  Carlos Tavares décrit une logique qui permettait aux constructeurs de "faire la différence sur une trouvaille technologique, une innovation pour atteindre ces seuils pour le coût le plus bas et l’efficacité la plus forte".Or, depuis 2 ans, dans le sillage du "Dieselgate" les gouvernements ont pris des positions de plus en plus radicales qui changent la nature des réglementations. "On est en train d’évoluer vers un monde où on nous instruit d’aller dans la direction du véhicule électrique", a dit Carlos Tavares. Si la feuille de route de PSA qui prévoit que 50% de la gamme sera électrifiée en 2020 et 80% en 2023 montre qu’il n’a pas d’état d’âme en tant que dirigeant, il s’en inquiète "en tant que citoyen" : "Qui traite la question de la mobilité propre dans sa globalité ? Comment est-ce que nous allons produire plus d’énergie électrique propre ? Comment faire pour que l’empreinte carbone de fabrication d’une batterie du véhicule électrique ne soit pas un désastre écologique ? Comment faire en sorte que le recyclage d’une batterie ne soit pas un désastre écologique ? Comment trouver suffisamment de matière première rare pour faire les cellules et les chimies des batteries dans la durée ? Qui aujourd’hui est en train de se poser la question de manière suffisamment large d’un point de vue sociétale pour tenir compte de l’ensemble de ces paramètres  "Toute cette agitation, tout ce chaos, va se retourner contre nous parce que nous aurons pris de mauvaises décisions dans des contextes émotionnels, pas suffisamment réfléchies et pas avec suffisamment de recul", a dit le patron de PSA. "Le fait qu’on nous donne l’instruction d’aller dans une direction qui est un choix technologique qui appartient aux autorités c’est un gros tournant". "Je ne voudrais pas que dans 30 ans on ait découvert les uns et les autres quelque chose qui n’est pas aussi beau que ça en a l’air sur le recyclage des batteries, l’utilisation des matières rares de la planète, sur les émissions électromagnétiques de la batterie en situation de recharge", a-t-il ajouté. Outre d’éventuelles conséquences sanitaires qui ne sont pas prises en compte, il y aura également en Europe des conséquences économiques à l’arrêt des véhicules thermiques.  "Pendant un siècle les Chinois ont couru après le moteur à combustion interne en versant des royalties à l’occident. Là, ils ont trouvé le point de rupture et maintenant ils prennent le lead sur le véhicule électrique qui est le symétrique pour le prochain siècle de ce qu’ils ont vécu au cours du précédent", a dit Carlos Tavares. Plutôt que décider d’interdire les voitures à moteurs diesel, il serait plus pertinent de favoriser voire d’imposer aux constructeurs des voitures de faible puissance, peu consommatrices en carburant, viser la production de voitures consommant 2 litres par 100 km, avec un double avantage, réduction de la pollution en CO2 et du nombre d’accidents. Elles auraient sans doute une empreinte carbone inférieure à celle des voitures électriques pénalisée par la fabrication des batteries. Avant de se lancer dans le tout électrique pour les voitures, il faudrait s’assurer que les réserves en lithium et cobalt sont suffisantes pour assurer une production durable de ces voitures, se préoccuper des aujourd’hui du recyclage de ces métaux, de la mise en place d’un réseau de distribution d’électricité…  13	Impact des événements sportifs Les sports dont l’empreinte écologique est la plus importante sont les jeux olympiques et la coupe du monde de football, manifestations qui se déroulent tous les quatre ans ? La France n’a aucune influence sur leur impact écologique, sauf lorsque la France est le pays organisateur. Le cyclisme est un sport « écologique » et pourtant, le Tour de France génère une empreinte carbone et écologique qui est à la hauteur du 3e événement sportif au monde, après les Jeux Olympiques et la Coupe du Monde de football! La longue boucle compte des centaines de voitures suiveuses, des hélicoptères, et surtout 10 à 12 Millions de spectateurs qui se déplacent pour admirer la course. 13.1	Impact du Paris Dakar La 40e édition du rallye Dakar (ex Paris Dakar) commence samedi 6 janvier avec un départ de Lima, au Pérou. Plus de 500 pilotes d'autos, de motos, de quads, ou de camions vont parcourir près de 9 000 km à travers le Pérou, la Bolivie et l'Argentine où l'arrivée se fera le 20 janvier à Cordoba. Le Dakar fait l'objet de nombreuses critiques en matière d'environnement. "Le rallye Dakar provoque directement et indirectement des dégâts qui sont de plusieurs ordres. Le Dakar va émettre directement près de 40 000 tonnes de CO2", explique sur franceinfo Stéphen Kerckhove, délégué général d'Agir pour l'environnement. C'est évidemment l'influence que peut avoir ce spectacle médiatique sur le dérèglement climatique mais aussi sur les écosystèmes directement au travers du passage de ces fous du volant avec des voitures et des camions qui empruntent des milieux fragiles. Il y a l'impact direct : le Dakar va émettre directement près de 40 000 tonnes de CO2 et indirectement au travers de l'influence que va avoir ce rallye sur les actes d'achats des téléspectateurs qui vont avoir tendance à aller mimer les fous du volant en achetant des véhicules surdimensionnés par rapport à l'usage qu'ils en feront au quotidien. Il est regrettable que ce rallye, qui a été imaginé aux confins des Trente Glorieuses dans les années 1970, continue à avoir une telle influence sur les radios et sur les télés. On sait pourtant très bien que nous sommes entrés dans l'ère du dérèglement climatique et qu'il serait souhaitable que les spectacles mis en avant soient au diapason de la contrainte climatique. Est-ce qu'il y a des dégâts sur l'environnement des pays traversés ? Les années précédentes, l'impact direct, on le constate avec effroi, ce sont des décès d'enfants et de personnes qui traversent les rues de leurs villages et qui subissent les vitesses inouïes de ces véhicules. Quand le Dakar est passé au Chili il y a quelques années près de 180 sites archéologiques ont été détruits ou endommagés par les véhicules passant. Des fresques qui dataient de plusieurs centaines d'années ont été détruites. Cette épreuve française qu’on a imposé aux africains  et qu’on impose aux sud-américains devrait être purement et simplement supprimé. 13.2	Impact de la Route du Rhum 13.2.1	Calcul l’impact environnemental du class40 Leyton d’Arthur Le Vaillant Dans le cadre de leur engagement sur la 40ème Route du Rhum 2018, l’entreprise Leyton et son skipper, Arthur Le Vaillant, ont souhaité quantifier les impacts carbone et environnementaux de leur bateau. Ils ont fait appel à E6 pour réaliser cette mission, et le bateau s’est lancé le weekend end dernier pour la 40ème Route du Rhum. Le bateau sera également engagé lors de la Transat Jacques Vabre 2019. 13.2.2	Le class40 Un Class40 est une catégorie de voilier monocoque hauturier de course et de croisière dont la longueur est de 40 pieds soit 12,19 m. Le class40 Leyton est fabriqué à la Trinité sur Mer. La fabrication du Class40 génère de l’ordre de 25 tonnes eq CO2, dont 90% de l’empreinte carbone est liée à la fabrication des matières premières. Lors de son utilisation, les émissions associées à la course correspondent à 150 kg éq CO2 (consommations d’énergie pour la génératrice), donc un ordre de grandeur beaucoup plus faible. 13.2.3	Quelles solutions pour réduire l’impact ? L’impact carbone généré par la fabrication du Class40, son utilisation en course et à posteriori sa fin de vie ne sont pas neutres. Les émissions de CO2 dégagées ne pourront pas être annulées à court terme mais pour lutter contre le changement climatique, LEYTON souhaite compenser ces émissions de gaz à effet de serre. Pour aller au-delà, il faudra engager des démarches d’éco conception dans la voile, pour travailler sur les matériaux mis en œuvre. L’impact écologique de ces courses étant essentiellement dû à la construction des bateaux, il serait pertinent que la durée de vie de ces bateaux soit prolongée 13.3	L’impact de la formule 1 sur l’environnement 13.3.1	La formule 1, un vilain petit canard ? Dès qu’on pense à un Grand Prix de F1, on pense pollution. Une chose est certaine : elles polluent beaucoup. Un Grand Prix, c’est une vingtaine de ces bolides qui crachent une quantité féroce de CO2, le tout dans un fracas motorisé digne des pires enfers. La FOTA a comptabilisé quelques 9900 tonnes de CO2 recraché par course. En comparaison, un avion qui voudrait recracher une telle quantité de CO2 devrait effectuer au moins 10 fois un aller-retour Paris-New-York. Quand on pense que quelques 918 courses ont été disputées depuis 1950, dans le seul cadre d’un Grand Prix (on ne comptabilise donc pas les multiples courses et essais) on dresse vite le constat de l’impact que la pratique de la course en formule 1 peut avoir sur l’environnement. Cependant, malgré une consommation de 75l de carburant par 100km, la formule 1 mérite-t-elle vraiment d’être considérée comme le sport le plus polluant au monde. Autre épreuve à supprimer d’urgence. 13.4	Prix de Formule E: Les écologistes de Paris réclament le «coût écologique» Le groupe écologiste de Paris a demandé jeudi à la maire PS Anne Hidalgo «des comptes sur le coût écologique et financier» du ePrix de Formule E (monoplaces électriques), organisé depuis 2016 dans la capitale :  «Mettre du bitume sur des kilomètres dans Paris pour seulement quelques heures, écologiquement, ce n'est pas bon du tout», a précisé le groupe, qui s'était déjà par le passé opposé à la tenue de cette course. La mairie de Paris a assuré que le prix n'était «pas financé par la Ville mais par ses organisateurs. »Sur l'empreinte carbone de l'événement, tout est fait pour la limiter: le matériel est acheminé par bateau, l'asphalte est réutilisée dans Paris.  En 2016, on a pu voir des bolides entièrement électriques foncer à 200km/h dans les rues de la capitale. Le circuit avait été asphalté en conséquence, le goudronnage du quartier des Invalides, a été vécu par certains comme un véritable désastre écologique.  Ces épreuves pourraient se dérouler sur des circuits bitumés, cela éviterait  ces opérations de bitumage et de débitumage qui dégagent des produits toxiques. 13.5	Le vrai impact écologique du Tour de France Le vélo ne pollue pas ? Détrompez-vous. Dès 2009, Génération Ecologie dénonçait « l’irresponsabilité environnementale des organisateurs du Tour de France ». Ils étaient alors pointés du doigt pour ne pas s’imposer de précautions en matière d’environnement et de pollution. Qu’en est-il en 2016 ? Quelque deux cents coureurs cyclistes, des centaines de voitures suiveuses, des camions techniques (service d’ordre, secours, presse…), des bus qui parcourent des milliers de kilomètres le long de la « Grande Boucle », des hélicoptères, des avions, sans compter les 10-12 millions de spectateurs qui se déplacent, en camping-cars ou en voitures, pour admirer la course le long des routes : l’empreinte écologique du tour est énorme et cette célèbre course illustre bien la difficulté à gérer les effets environnementaux d’événements sportifs majeurs.  13.5.1	Le Tour de France, une caravane de cadeaux et de déchets Le Tour est une immense fête populaire retransmise à près de 3,5 milliards de téléspectateurs à travers 190 pays dans le monde. Une belle course à vélo au gré de paysages magnifiques, mais sur le terrain, son empreinte carbone et écologique est à la hauteur du 3e événement sportif au monde, après les Jeux Olympiques et la Coupe du Monde de football. 13.5.2	La caravane passe… et laisse des traces L’une des attractions préférées du public, c’est la distribution de cadeaux par la caravane publicitaire : des « pognes » pleines de cadeaux, de porte-clés, d’échantillons, de confiseries qui sont jetés au public pendant le Tour. Au total, environ 14 millions de petits objets, les goodies, validés par l’organisation du Tour de France, sont distribués, jetés depuis des véhicules en mouvement. Il s’agit le plus souvent des gadgets en plastique, de basse qualité, de la plus faible valeur possible et fabriqués en Chine, la plupart du temps donnés sous blister, un emballage en plastique transparent parfois arraché et jeté sur place par les spectateurs les moins scrupuleux. La réduction de l’impact écologique pourrait passer par la suppression de la caravane publicitaire et de la distribution d’objets et de friandises de piètre qualité. Les organisateurs pourraient éviter les départs de tour de France de pays lointains, d’avoir un parcours continu, éviter les transports par avion pour les coureurs et leur suite 13.6	Impact écologique de la neige artificielle 13.6.1	Réchauffement climatique : la neige artificielle pointée du doigt La Cour des comptes critique la gestion des domaines skiables, de plus en plus vulnérables au réchauffement climatique. Après une première mise en garde il y a sept ans, la Cour des comptes s’est de nouveau alarmée il y a quelques jours de la « vulnérabilité croissante » des stations de ski des Alpes du Nord face au réchauffement climatique. Dans leur rapport annuel, les magistrats dénoncent les réponses inadaptées des gestionnaires des domaines skiables. Entre 2015 et 2017, la Cour a contrôlé la gestion de dix-sept domaines skiables, dont Chamonix, Megève, Courchevel et Tignes. Le rapport constate « l’aggravation de certains déséquilibres » liés à un modèle de développement « ayant atteint ses limites ». Pointant des investissements « privilégiant le court terme », elle dénonce notamment la généralisation de l’enneigement artificiel, présenté comme une solution « partielle et onéreuse ». Confrontées à une pénurie de neige ces dernières années, les stations y ont eu abondamment recours, ce qui pose des problèmes d’approvisionnement en eau. Actuellement, 30 millions de m3 d’eau sont utilisés chaque année pour fabriquer de la neige de culture pour les canons. « Pour préparer leur domaine skiable, les stations commencent à enneiger les pistes avec leurs canons dès le 15 novembre en pompant dans leurs retenues collinaires, qui captent l’eau de ruissellement de la pluie. Mais certaines stations se sont retrouvées dans le passé avec des réservoirs à sec avant Noël et se sont vu autoriser par le préfet de pomper dans les cours d’eau alors qu’ils étaient déjà à un niveau très bas.  13.6.2	Les stations de ski « accros » à la neige artificielle Le recours à la neige artificielle n’a cessé de se renforcer en France ces dernières années. Au risque d’oublier que le ski, à l’origine, est un sport de nature. La neige est au rendez-vous pour les vacances de février. Mais le début de saison a été catastrophique. Pour faire plaisir aux skieurs, on a même vu un ballet d’hélicoptères apporter 100 tonnes de neige sur les pistes de la station savoyarde de Sainte-Foy-Tarentaise en décembre dernier. « Dans les stations de moyenne montagne, faute d’enneigement suffisant, seules les stations bénéficiant d’un équipement en neige de culture ont pu ouvrir à Noël », relève Laurent Reynaud, le directeur général de Domaines skiables de France, le syndicat des remontées mécaniques. 13.6.3	Une solution miracle ? Pas vraiment Reste que le recours de plus en plus systématique à ce palliatif soulève de nombreuses questions. Considérée parfois comme une garantie pour assurer la saison, la neige artificielle – qui nécessite de lourds investissements – ne peut être cependant utilisée comme la solution miracle. « Pour produire de la neige, il faut des températures négatives, À +2 °C, on ne sait pas faire. » Or, le manque de neige naturelle est souvent associé à des températures trop douces pour la saison.  13.6.4	La question polémique de l’eau L’utilisation d’additif ayant été écartée, la neige de culture ne génère pas de pollution. « Nous n’utilisons que de l’eau, de l’air et du froid ». Mais cette production n’est pas sans impact sur l’environnement car elle est fortement consommatrice d’énergie et surtout d’eau, à un moment où les besoins augmentent tous en même temps : besoin de fournir de l’eau potable aux touristes mais aussi besoin de la fonction d’épuration naturelle assurée par les cours d’eau en aval des stations de traitement des eaux usées. Pour éviter des conflits autour de la ressource en eau, les nivoculteurs ont trouvé la parade : la multiplication de retenues collinaires, qui stockent l’eau de pluie ou de ruissellement depuis la saison précédente. « Ces retenues d’altitude fournissent 60 % de l’eau utilisée pour fabriquer la neige de culture, le pompage direct dans les ruisseaux compte pour 30 % et le trop-plein dans les réseaux d’eau potable pour les 10 % restants . Malgré le coût important de l’enneigement artificiel, les stations sont de plus en plus nombreuses à s’équiper pour garantir à leurs visiteurs un enneigement de bonne qualité. Cette augmentation de l’enneigement artificiel a plusieurs conséquences sur l’environnement : • l’utilisation des ressources en eau  • une consommation d'énergie très importante (les 10.000 canons à neige français consomment 108 millions de kWh) • une pollution éventuelle par les additifs ajoutés dans l’eau  • une érosion supplémentaire due à la quantité de neige produite. Cette neige artificielle est 50 fois plus dure et 4 fois plus dense que la neige naturelle, ce qui favorise l’érosion La conclusion revient aux Sages de la Cour des comptes qui réaffirment l’importance du développement économique en montagne, ils appellent les gestionnaires de domaines skiables à envisager au plus vite « un futur où le ski et les sports de neige ne seront plus l’unique ressource.   Lors de la campagne électorale, suite un accord avec les Verts, François Hollande avait annoncé son engagement de faire chuter de 75 % à 50 % la part du nucléaire dans la production d'électricité à l’horizon 2025. Ségolène Royal a décidé de fermer la centrale de Fessenheim quinze jours avant le premier tour de l’élection présidentielle de 2017afin de tenir la promesse faite par François Hollande. Cette décision a été prise sans tenir compte de l’avis de l’Académie des Sciences, ni de celui de l’Académie des Technologies, en contradiction avec l’avis du GIEC et de plusieurs scientifiques qui jugent irréaliste la baisse de la production d’électricité d’origine nucléaire. Du fait de l’intermittence des énergies renouvelables et de l’impossibilité de stocker massivement l’énergie électrique, il faudra faire appel à des énergies carbonées pour assurer une production suffisante d’électricité. Jean Marc Jancovici a démontré l’impossible pari de remplacer l’énergie d’origine nucléaire par des énergies renouvelables. La seule politique raisonnable consiste à prolonger la vie des réacteurs qui fonctionnent de façon satisfaisante et permanente. Continuer à développer les énergies renouvelables alors que le problème du stockage de l’électricité n’est pas résolu est une hérésie, il serait en revanche important de lancer des recherches pour augmenter la durée de vie de ces énergies et surtout pour réduire la quantité de terres rares nécessaires au fonctionnement des éoliennes. L’énergie nucléaire est un moyen de production massive d’électricité qui est pilotable et qui ne contribue pas au réchauffement climatique ni à la pollution de l’atmosphère. Le charbon autre moyen de production massive d’électricité présente l’inconvénient de relâcher dans l’environnement de grandes quantités de CO2, mais aussi des oxydes d’azote et de soufre, des particules fines et des composés organiques toxiques qui provoquent beaucoup plus de décès que le nucléaire lors de l’accident de Tchernobyl. Au contraire de l’énergie nucléaire qui produit des déchets extrêmement radioactifs, le charbon produit d’énormes quantités de déchets difficiles à gérer.  Il est curieux que l’ADEME financé par l’Etat ne soit pas objective et émette des rapports qui attirent de sévères critiques d’organismes compétents. Ce n’est pas étonnant de la part d’un organisme dirigé par un ancien « Verts »  et sous la tutelle d’un Ministère dirigé depuis des décennies par des écologistes. Il serait temps de mettre à la tête de ce Ministère et de l’ADEME des personnes compétentes et objectives. L’hydrogène est un vecteur énergétique et non pas une source d'énergie car il n'existe pratiquement pas à l'état naturel. Le procédé le plus courant de fabrication de l'hydrogène est le reformage du gaz naturel par de la vapeur d'eau surchauffée, ce procédé présente l’inconvénient de produire du CO2. L’hydrogène est aussi fabriqué par électrolyse de l'eau. Le rendement est de 50 % pour obtenir de l’hydrogène sous pression à 700 bars et de 40% pour obtenir de l’ l’hydrogène liquide. Son stockage est difficile et surtout son large domaine d’inflammabilité le rend très dangereux. L’expérience MYRTE conduite en Corse n’est pas concluante pour le stockage d’énergie, et n’est pas pertinente pour la production d’électricité, du fait du coût prohibitif de stockage de cette énergie. Le gouvernement s’abrite derrière la loi de transition énergétique pour promouvoir les véhicules à essence au détriment des véhicules diesels. La fiscalité dite « écologique » est indexée sur les émissions de CO2, le gouvernement favoriserait les véhicules à essence plus émetteurs de ce gaz afin d’augmenter les rentrées fiscales. PPE et respect des accords de Paris Pour des raisons « bassement » électorales, les « Verts » incitent le gouvernement à arrêter 14 réacteurs nucléaires d’ici 2035 pour les remplacer par des énergies renouvelables intermittentes. Le doublement du coût du kWh depuis les années 2000 est dû aux taxes, en particulier à la CSPE qui sert essentiellement à financer les énergies intermittentes. Les subventions à l’éolien et au photovoltaïque coûtent chaque année à la France 2 réacteurs EPR.  Plusieurs organismes ont élaboré pour la France des scénarios de transition énergétique, parmi les plus connus, Negawatt et Negatep. Le scénario Negawatt préconise que 90% de nos besoins soient assurés en 2050 par les énergies renouvelables essentiellement grâce à la biomasse, à l’éolien et au photovoltaïque. Un recours temporaire au gaz permettrait de fermer progressivement la totalité des réacteurs nucléaires. Un tel scénario envisage une production éolienne de 209 TWh en 2050, contre 15 TWh en 2012, les problèmes d’intermittence étant réglés par la production d’hydrogène et de méthane. Ce scénario est irréaliste D’autant plus qu’il faudrait réduire la demande en énergie primaire de 66% alors que la population augmenterait de 15%. Cette réduction devrait venir de l’efficacité et de la sobriété énergétique.  Le scénario Negatep prévoit une division par 4 des rejets de CO2 malgré une baisse de seulement 18 % de la consommation d'énergie finale. Les énergies fossiles seraient très largement remplacées par les énergies renouvelables et le nucléaire capables de produire de l'électricité décarbonée dont la production augmenterait de 61%. Aucun scénario ne prétend qu'il soit possible de remplacer les énergies fossiles et nucléaires par des renouvelables sans une diminution drastique de la consommation. Tous les scénarios préconisent une baisse de la consommation d'énergie malgré une hausse de la population en misant sur l'efficacité énergétique dont l'importance est donc cruciale. L’efficacité énergétique fait l’unanimité puisqu’il s’agit de consommer moins à service rendu égal. La sobriété énergétique est beaucoup plus complexe à développer car elle implique des changements considérables de modes de vie et d’organisation de la société. En 2011, l’Allemagne a décidé d’arrêter progressivement ses réacteurs nucléaires et de compenser la production d’électricité avec des énergies renouvelables. De 1995 à 2014, l'Allemagne a investi 350 milliards d'euros dans des éoliennes, panneaux solaires, méthaniseurs et modifications du réseau électrique, pour faire passer de 4 à 26 % la part de sa production électrique provenant de sources renouvelables.  Or cet investissement n'a pas changé l'évolution des émissions de CO2 de l'Allemagne, ni sa dépendance à l'énergie fossile importée. La production d'électricité renouvelable a fortement augmenté depuis les années 1990. De 20 milliards de kilowattheures électriques renouvelables produits en 1996 (soit 4 % de la production allemande), essentiellement à partir de barrages, l'Allemagne est passée à un peu plus de 150 en 2014, dont environ 24 d'hydroélectricité, 55 d'éolien, 35 de solaire, et 35 à partir de méthaniseurs. Pour arriver à ce résultat, les Allemands ont installé, à fin 2014, une puissance de 38 gigawatts en solaire, 40 en éolien, de l'ordre de 9 en biogaz, et un peu plus de 4 en hydraulique, soit plus de 90 gigawatts. La capacité nucléaire française est de l'ordre de 65 gigawatts qui produisent un peu plus de 400 térawattheures d'électricité par an, quand les 90 gigawatts de renouvelables allemands ne produisent « que » 150 térawattheures d'électricité sur la même durée. Par gigawatt installé, le nucléaire produit donc environ 4 fois plus que les renouvelables installées chez nos voisins. Aux États-Unis, les réacteurs nucléaires ont un facteur de charge de 90 % environ, car ils tournent toute l'année. En France, ces mêmes réacteurs sont plus proches de 70 à 75 %, car une partie de leur puissance ne sert que l'hiver. En Allemagne, ce facteur de charge baisse énormément : pour l'éolien, il varie entre 15 et 20 %, selon les années. Pour le solaire, ce facteur dépend beaucoup de la latitude il est légèrement inférieur à 10 % en Allemagne. Enfin pour le biogaz, le facteur de charge est plus proche de 60 %. Mais, comme le solaire et l'éolien dominent largement dans les capacités nouvelles en Allemagne, la moyenne pour l'ensemble du parc renouvelable est descendue de 40 à 20 % entre 1996 et 2014. On devrait donc s'attendre à ce que la production faite avec le reste ait baissé, et en particulier la production à base de combustibles fossiles puisque le développement des renouvelables est vu comme un moyen de faire baisser les émissions de CO2. Il n’en est rien Une première explication de ce paradoxe est qu'une bonne partie de la hausse des renouvelables est venue en plus de la production préexistante, et n'a donc rien substitué du tout.  La deuxième raison est due au fait que la production allemande renouvelable supplémentaire a servi à baisser le nucléaire. La baisse du nucléaire a donc été considérée comme prioritaire sur la baisse du charbon. L'histoire devra juger pourquoi nos voisins ont préféré diminuer le recours à une énergie qui présente des risques qui restent minimes et localisés, au profit d'une énergie qui disperse dans l’atmosphère massivement du CO2, différents polluants et des particules fines. Dans certaines régions d’Allemagne, des villages sont déplacés pour permettre l’extraction du charbon et du lignite. L’électricité produite par les EnRI doit être utilisée immédiatement car les possibilités de stockage sont négligeables quand le vent ne souffle pas et quand le soleil ne brille pas. Le réseau ne peut donc pas être alimenté uniquement à partir d’énergies renouvelables sans l’approvisionnement de sources stables et pilotables alimentées par des énergies fossiles ou par… du nucléaire acheté en France. La restructuration du système électrique belge, de manière générale, et du mix électrique, en particulier, agite beaucoup le monde politique belge ces derniers temps. Alors que les centrales nucléaires n’émettent pas plus, voire moins, de gaz à effet de serre (GES) que la production éolienne ou photovoltaïque sur un cycle complet de vie et que, d’autre part, la roadmap 2050 de la Commission européenne prévoit toujours, à cette échéance, du nucléaire dans le parc électrique européen, le gouvernement belge a décidé, de sortir de cette forme de génération d’électricité entre 2022 et 2025. Les conséquences néfastes d’un mix électrique sans nucléaire, viendraient s’ajouter aux dysfonctionnements causés par la priorité d’accès aux réseaux électriques concédée au renouvelable intermittent ainsi qu’aux subventions généreuses et autres avantages qui leur ont été accordés. La sortie totale du nucléaire ne se justifie ni par des raisons technique ou économique, ni d’un point de vue politique. D’autre part, sans capacité nucléaire, l’importation d’électricité va augmenter, soit en provenance de la France (essentiellement nucléaire) ou de l’Allemagne (principalement à partir de charbon et de lignite), donc des modes de production dont le gouvernement belge ne veut plus. Quelle est dès lors la logique qui sous-tend la dénucléarisation de la génération d’électricité? La sortie du nucléaire n’est pas non plus pertinente d’un point de vue économique. La pénétration croissante de l’éolien et du photovoltaïque et la fermeture des centrales nucléaires entraînent un gonflement du prix de l’électricité et partant une diminution de la compétitivité des entreprises et du pouvoir d’achat des ménages ainsi que de la sécurité d’approvisionnement électrique. Cette forte augmentation du prix de l’électricité résulte d’un certain nombre de facteurs dont: - le coût de la construction de nouvelles centrales au gaz indispensables pour assurer l’équilibre du système. - de rémunération pour convaincre les producteurs d’électricité d’investir dans de nouvelles centrales au gaz qui sont très loin d’être rentables si elles ne sont destinées qu’à compenser l’intermittence des énergies renouvelables - du coût de stockage d’électricité essentiel pour mitiger les fluctuations de la génération renouvelable au-delà d’un certain niveau de pénétration - du coût de renforcement et d’extension des infrastructures de transmission et de distribution d’électricité requis, entre autres, par la dispersion de la production renouvelable; - et, bien entendu, des subventions accordées au renouvelable. Imaginer que la consommation d'électricité pourrait décroitre est peu crédible. Prendre d'ores et déjà cette décroissance pour un fait acquis dans le dimensionnement de notre parc électrique est irresponsable. L'électricité ne représente cependant que 23 % de la consommation finale d'énergie en France, penser qu’elle peut décroitre est irréaliste, la production d’électricité d’origine renouvelable ou nucléaire doit croitre pour se substituer à celle produite par les énergies carbonées. De plus le développement même très progressif de la voiture électrique, l’essor de l'économie digitale qui pèsera plus de 20 % de la consommation mondiale d'électricité en 2020, le remplacement du chauffage au fioul par des pompes à chaleur… nécessiteront également un accroissement de la production d’électricité. Enfin, l'intermittence des énergies renouvelables en expansion exige une production pilotable d’électricité qui ne peut provenir que des énergies hydraulique ou nucléaire, si on exclut les énergies carbonées émettrices de C02. Car le développement de l'intermittence implique l'augmentation des moyens pilotables dédiés au lissage de sa production. En France, le choix ne réside qu'entre de nouvelles centrales thermiques ou l'asservissement du parc nucléaire aux caprices de la production éolienne, lui imposant des régimes chaotiques et à coups de fonctionnement, ainsi que c'est déjà le cas lors des records éoliens. Ce qui accélère le vieillissement des composants des centrales, ainsi qu'une perte de rentabilité, pour un avantage sur lequel il est permis de s'interroger. Les énergies renouvelables se sont pourtant révélées parfaitement inefficaces pour atteindre les trois objectifs qui leur étaient assignés : réduire l’impact environnemental, renforcer la sécurité d’approvisionnement, et maîtriser les coûts. Avec 500 milliards de kWh produits chaque année en France, les batteries resteront à jamais hors de portée pour du stockage d'une saison à l'autre, ce qui serait nécessaire car l'hiver la consommation augmente plus que la production de renouvelables. Malgré la multiplication de démonstrateurs hors de prix, aucune avancée technologique ne permet d’espérer stocker massivement l’énergie pour un coût acceptable par la collectivité. Ce stockage reste pourtant indispensable pour que les énergies intermittentes confèrent une valeur ajoutée au parc électrique français. C'est la flexibilité unique au monde qui a permis à notre parc électrique de réduire à l'extrême le recours aux centrales thermiques. Et c'est grâce à ce parc nucléaire que la Commission européenne attribue à la France une indépendance énergétique bien supérieure à celle de ses voisins, et notamment à celle de l'Allemagne. L'objectif de 50 % de nucléaire dans la production d'électricité - contre 75 % actuellement est né pendant la campagne présidentielle de François Hollande en 2012. Ce chiffre n'a été précédé d'aucune analyse sérieuse n’a tenu aucun compte de l’avis de l’Académie des sciences ou de l’Académie des technologies ou de la Cour des comptes. Cet objectif a été émis uniquement pour des motifs de basse politique. Le 28 mars 1979 est survenu l’accident de Three Mile Island, centrale située, à 15 km d’Harrisburg, une ville de 60.000 habitant. Malgré la fusion partielle du cœur l’enceinte de confinement a tenu son rôle, la quasi-totalité de la radioactivité est restée contenue à l’intérieur du bâtiment réacteur. Et pourtant, cet accident n’a causé aucune victime et le seul relâchement de radioactivité dans l’environnement n’a consisté qu’en une émission de gaz rares sans activité biologique. Tous les réacteurs du monde ont profité des enseignements tirés de l’accident de TMI2. La prise en compte de ces leçons a réduit d’un facteur 10 le risque de fusion de cœur dans les réacteurs occidentaux « de deuxième génération » La centrale de Tchernobyl comptait quatre réacteurs de type RBMK de conception soviétique. Ce modèle de réacteur est modéré au graphite et est refroidi à l'eau. Le combustible est de l'oxyde d'uranium enrichi à 2% en 235U. Les spécialistes jugent que ce réacteur comportait des défauts de conception qui le rendait potentiellement dangereux car le cœur du réacteur est instable en dessous de 700 MWth, c'est-à-dire à faible puissance. Du fait de son instabilité à faible puissance le réacteur, suite à des essais périlleux, le réacteur s’est emballé et a atteint une puissance de l'ordre de 100 fois sa valeur nominale provoquant la vaporisation de l’eau refroidissant le réacteur et produit une explosion de chaleur qui détruit le réacteur. Les 600 tonnes de graphite du cœur, s'enflamment. L’intensité d'incendie et l'absence d'enceinte de confinement favorisent la dispersion dans l'atmosphère de grandes quantités de produits radioactifs. Le principal effet détecté des rejets radioactifs est l'augmentation des cancers de la thyroïde, en particulier, chez les enfants et les adolescents. Des études internationales sont en cours pour quantifier les risques de leucémies chez les liquidateurs. On estime que 3 000 des 600 000 personnes ayant travaillé au contact direct de la centrale mourront des suites de l'exposition aux radiations. Cet accident a été exploité par les adversaires du nucléaire alors que ce réacteur n’a rien de commun avec les réacteurs en service  en France. Le nuage radioactif est encore évoqué, entraîné par les masses d'air jusqu'à dix mille mètres d'altitude et dérivant au gré des vents, a disséminé sur la plupart des pays d'Europe des produits radioactifs. Il est à noter que malgré un important relâchement de produits radioactifs dans l’atmosphère, la radioactivité due à l’accident de Tchernobyl est très inférieure à celle dégagée lors des essais nucléaires aériens effectués de 1945 à 1980. En deçà d’une certaine distance de Tchernobyl, l'impact sanitaire dû à l’accident est naturellement plus important que l'impact des essais. Mais, au-delà de cette distance, la retombée de l'accident devient rapidement négligeable devant la retombée globale due à la totalité des essais nucléaires aériens. L'accident nucléaire de Fukushima est un accident industriel majeur qui a débuté le 11 mars 2011 au Japon, à la suite d’un séisme de force 9 et d’un tsunami en résultant d’une violence exceptionnelle. Il s'agit de la plus grave catastrophe nucléaire du 21eme siècle, classée au niveau 7, le plus élevé sur l'échelle internationale des événements nucléaires (INES), au même degré de gravité que la catastrophe de Tchernobyl (1986), en particulier par le volume important des rejets radioactifs.  Quatre centrales nucléaires se situent sur la côte nord orientale et se sont arrêtées automatiquement à la suite des premières secousses : les centrales de Fukushima Daiichi, de Fukushima Daini, d’Onagawa et de Tokai. La détection des premières secousses provoque l'arrêt des réacteurs 1, 2 et 3 Fukushima Daiichi (soit 30 secondes avant les secousses principales qui ont duré près d’une minute). Le tremblement de terre entraine la destruction des six lignes d’alimentations électriques externes des réacteurs et le démarrage des douze groupes électrogènes de secours à moteur diesel pour faire fonctionner des pompes de refroidissement. Cinquante-et-une minutes après la première secousse, la première vague du tsunami, d'une hauteur de 15 mètres, atteint la centrale nucléaire de Fukushima Daiichi. Elle est suivie de plusieurs autres vagues de moindre importance. Le tsunami a eu pour conséquences une dégradation des prises d’eau en mer conduisant à la perte de la source froide, puis à la perte des Diesels de secours des réacteurs 1 à 4. À la suite de la perte des Diesels, un système d'ultime secours permettant de faire circuler l'eau contenue dans les tores situés en partie inférieure des bâtiments, au pied des cuves des réacteurs, s'est mis en marche puis s'est arrêté par défaillance des batteries électriques. Il n'y avait dès lors plus de moyens de refroidissement disponibles. Entre le 12 mars et le 15 mars les réacteurs 1, 3 et 2 sont successivement détruits suite à des explosions ^produites par des dégagements d’hydrogène. À partir de ce stade des rejets massifs vont se produire dans l'atmosphère et l'environnement et l'ensemble des acteurs vont devoir gérer la phase post-accidentelle : l'exploitant va tenter de refroidir les installations puis de réduire les émissions tout en n'exposant pas trop les travailleurs. Les autorités vont prendre des mesures pour tenter de protéger la population. L’accident est un accident de refroidissement comme celui survenu en 1979 à Three Mile Island aux Etats-Unis.  Les réacteurs se sont arrêtés automatiquement lors du tremblement de terre et avec eux les fissions nucléaires. Mais les désintégrations radioactives continuent de dégager de la chaleur. Il est impératif de refroidir. Or le séisme de force 9 et la vague du tsunami ont endommagé et inondé les circuits de refroidissement et installations de secours, conduisant à une perte totale des alimentations électriques et des moyens de refroidissement principaux durant de longues heures. A ces pannes multiples s’ajoutent des conditions d’intervention dramatiques. Villes et villages de la côte ont été dévastés par le tsunami, les routes sont impraticables. Ce tsunami a engendré plus de 18 000 morts et disparus, des blessés et des destructions considérables. Les premières équipes doivent intervenir alors que leurs vies ont été bouleversées et que les familles sont à la recherche de proches disparus. L’accident est la preuve que les scénarios extrêmes peuvent arriver, avec la concomitance de multiples pannes. La conduite à tenir dans de telles circonstances n’avait pas été envisagée et la gestion de la crise et de ses multiples rebondissements s’est effectuée de façon approximative, On peut jeter a posteriori un regard effrayé sur cette gestion. Cependant, les dispositifs existants quoique insuffisants ont porté leur fruit et atténué l’accident. Les enceintes de confinement ont joué leur rôle ; le gros de la radioactivité est resté dans ces enceintes ; quatre jours se sont écoulés avant le principal rejet de radioactivité donnant le temps de mettre à l’abri les populations.  Si les pertes en vies humaines dues à la radioactivité seront probablement minimes, les conséquences sont lourdes pour la société et l'économie japonaise. Il y a d'abord le coût humain des évacuations et des déracinements, celui des décontaminations.  On a beaucoup moins parlé de la crise qui a affecté Fukushima Daini, sa centrale sœur, à environ 10 kilomètres au sud ; elle aussi a essuyé d’importants dommages, mais a échappé au sort de Daiichi. Le directeur du site, ainsi que les 400 employés de Daini ont su se frayer un chemin dans le chaos de la situation, et la centrale s’en est tirée sans fusion ni explosion. Située au nord du Japon, la centrale nucléaire d’Onagawa, la plus proche de l'épicentre du tremblement de terre et soumise à des secousses encore plus violentes, n'a pas subi de dommages majeurs car conçue avec des marges de sécurité suffisantes. La centrale d'Onagawa a enregistré des secousses sismiques qui ont dépassé sa capacité nominale, et le sous-sol de l'un de ses bâtiments des réacteurs a été inondé. Mais l'usine a maintenu sa capacité de refroidissement, ses réacteurs se sont arrêtés sans dommages à leurs cœurs ni dommages importants aux systèmes de sécurité. Tous les réacteurs du monde ont profité des enseignements tirés de l’accident de Three Mile Island. La prise en compte de ces leçons a réduit le risque de fusion de cœur dans les réacteurs de deuxième génération. L’ASN a, suite à l’accident de Fukushima, demandé à EDF d’effectuer des travaux en particulier afin de maintenir une alimentation en eau et en électricité pérenne des réacteurs en cas de forts séismes ou d’importantes inondations, diminuant ainsi fortement le risque d’accident. La France devrait suivre l’exemple des Etats Unis où 81 des 99 réacteurs évoqués ont déjà obtenu le droit de poursuivre leur exploitation jusqu’à 60 ans, et pourraient étendre leur durée d’exploitation de 60 à 80 ans. Selon des chercheurs de la NASA, l'énergie nucléaire pourrait avoir sauvé 1,8 million de vies autrement perdues à cause des combustibles fossiles, et pourrait en sauver jusqu'à 7 millions de plus au cours des quatre prochaines décennies.  Dans tous secteurs industriels de nombreux accidents se produisent, industrie chimique, rupture de barrages, exploitation et transport d’hydrocarbures, extraction et exploitation du charbon… Souvent ces accidents majeurs ne sont pas dus à une cause extérieure comme ce fut le cas à Fukushima, en revanche elles ont pu être déclenchées par des actions malveillantes. Dans certains cas, comme à Bhopal le nombre de décès immédiats et postérieurs à l’accident est très élevé. Ces accidents à l’instar de Tchernobyl et Fukushima occasionnent également dans certains cas de grands dommages à l’environnement (marées noires, mines de charbon). Pourtant malgré les nombreuses victimes dus à des accidents ou à des pollutions majeures comme c’est le cas pour l’extraction et la combustion du charbon ou du lignite, les écologistes privilégient l’utilisation du charbon plutôt celle du nucléaire.  L’IRSN considère à ce jour que la séparation/transmutation ne constitue pas une alternative au stockage géologique et se prononce pour le projet. Le rapport rendu public par l’ASN est une étape importante dans la validation technique du projet. Pour la grande majorité des déchets prévus dans Cigéo (plus de 80 %), l’ASN a considéré que les options de sûreté sont satisfaisantes. Les seules restrictions concernent les déchets bitumeux. Pour être acceptés dans Cigéo, ces déchets pourraient être conditionnés dans une matrice inerte. Actuellement le retraitement du combustible après séjour dans un réacteur consiste à séparer uranium et plutonium qui peuvent être réutilisés. Les éléments restants (actinides mineurs et produits de fission) sont entreposés après vitrification dans les usines de retraitement avant envoi ultérieur à Cigéo. Le recyclage des actinides mineurs permettrait de réduire notablement la quantité de déchets à vie longue, mais cette solution n’est pas envisageable à ce jour. Le recyclage nécessite une séparation préalable de ces actinides mineurs et des lanthanides du reste des produits de fission. Des essais au niveau laboratoire ont démontré la possibilité de séparer ensuite les actinides des lanthanides. Les actinides pourraient être éliminés par transmutation et les lanthanides dont le néodyme recyclés, les besoins pour ces éléments étant importants. De même pourraient être récupérés certains dans ces déchets platinoïdes rares et très onéreux (ruthénium, rhodium, palladium). L’élément de base de l’énergie nucléaire est l’uranium, si un jour les ressources en uranium venait à s’épuiser, le thorium beaucoup plus abondant, pourrait être un substitut à l’uranium, d’autant plus que des stocks de thorium existent déjà car cet élément est un sous-produit de l’extraction des terres rares. Le thorium est fertile, après passage dans un réacteur, est converti en 233U fissile. La fission de l’233U produit moins actinides que la fission de l’235U, ce qui peut être un avantage  Les réacteurs à neutrons rapides (RNR) présentent plusieurs atouts déterminants vis-à-vis de la gestion des matières en complémentarité des filières existantes: • ils peuvent utiliser sans limitation le plutonium produit par les réacteurs à eau assurant une gestion pérenne; • en permettant de valoriser l’238U, ils multiplient par un facteur voisin de 100, l’énergie que l’on peut extraire d’une masse donnée d’uranium naturel.  • ils ont la capacité, une fois constitué le stock nécessaire à leur démarrage, de se passer totalement d’uranium naturel. Ils n’ont besoin que d’un appoint d’238U. En France le stock d’uranium appauvri issu des opérations d’enrichissement lui assurerait une indépendance énergétique quasi inépuisable pour un parc de RNR; • le spectre des neutrons rapides ouvre aussi la possibilité de transmuter les actinides mineurs et permet une réduction de l’inventaire de ces radionucléides dans les déchets. La plupart des grands pays nucléaires s’intéressent fortement à la technologie des réacteurs à neutrons rapides refroidis au sodium. Ainsi, l’Inde devrait mettre en service dans les prochains mois un réacteur de puissance 500 MWe, et la Russie a démarré en juin 2014 un réacteur de 800MWe. La Chine est encore en retrait, mais affiche des ambitions importantes dans le domaine.  La France envisage la construction d’Astrid, un démonstrateur d’intégration technologique, d’une puissance électrique de 600 MWe environ, permettant une démonstration de sûreté et de fonctionnement à l’échelle préindustrielle de RNR‐Na de 4èmegénération. L’objectif est une mise en service au cours de la décennie 2020. Il serait judicieux de ne pas tarder à lancer le projet. L’exploitation d’Astrid pendant une dizaine d’années doit ensuite permettre le déploiement de réacteurs commerciaux. La Balance commerciale de la France est déficitaire depuis des décennies et se creuse ces dernières années, qu’en serait-il pour l’approvisionnement énergétiques du pays, si le nucléaire ne se substituait pas au gaz ou au pétrole ? Suite à l’accident de Fukushima, les comptes du commerce extérieur du Japon, généralement excédentaires, ont affiché un solde négatif historique pour la période d'avril 2011 à mars 2012 du fait de l’obligation d’importer plus d’hydrocarbures suite à la diminution de la production d’énergie d’origine nucléaire. Le déficit de la balance commerciale de la France pourrait être réduit en réduisant l’achat d’hydrocarbures et en augmentant la durée de fonctionnement de nos réacteurs.  Les composés organiques (à base de carbone) peuvent être synthétisés en cas de pénurie, ce fut le cas en Allemagne et Japon pour la synthèse de carburants pendant la seconde guerre mondiale. La synthèse de métaux n’est pas envisageable, il faut d’ores et déjà identifier les minerais exploitables en particulier en élargissant l'horizon géologique français qui n'est pas connu au-delà de 100 mètres de profondeur. Il est nécessaire aussi de développer le recyclage des métaux. Avant de se lancer dans des projets innovants, il faut s’assurer que ces projets sont durables. Ainsi les ressources en cobalt et en lithium sont-elles suffisantes, à des couts d’extraction acceptables, pour satisfaire la construction de voitures électriques au niveau mondial ? La France devrait s’inspirer de l'Allemagne qui a pris conscience de sa dépendance à l'égard des métaux critiques. Un petit explorateur minier a été formé par de grands groupes allemands pour découvrir et réserver des gisements futurs de ces métaux. Près de 50 % de l’énergie primaire provient des combustibles fossiles, en particulier du pétrole dont il faudra réduire la consommation pour atteindre les objectifs de la loi sur la transition énergétique. Le secteur du bâtiment pèse pour 44% dans la consommation énergétique finale française, tout secteur confondu. Le remplacement du chauffage au fioul des habitations par le chauffage électrique est un moyen drastique de réduire les rejets de CO2 dans les villes. Le chauffage au bois est une alternative pour remplacer sa chaudière au fioul, mais tout de même très polluante. La meilleure solution est les pompes à chaleur. Si elles sont relativement récentes, et à ce titre présentent encore un coût d’installation élevé, elles n’en sont pas moins le moyen le plus écologique et le plus économique pour se chauffer en France. A Marseille, deux compagnies ont équipé leurs navires d’un système d’alimentation électrique de courant à quai. Ce système, permet aux navires d’être branchés à quai 30 minutes après le débarquement des passagers et débranchés 2 heures avant l’appareillage : ainsi alimentés en électricité, le recours aux moteurs au fioul, n’est donc plus nécessaire pendant les escales. Ce système électrique innovant a permis de réduire de 30% la consommation de carburant de la flotte en un an. Les économies réalisées sont évaluées entre 2 et 4 tonnes de fioul par ferry et par escale quotidienne. Cet effort doit être poursuivi et étendu progressivement à l’ensemble des navires présents dans le port. A quai, les navires stationnant plus de deux heures non équipés d’un système d’alimentation électrique de courant à quai sont tenus de passer au diesel marin contenant un taux de 0,1% de soufre ce qui représente encore un taux 100 fois plus élevé que le diesel des voitures. Selon un institut de recherche néerlandais, l'approche la plus écologique pour un navire consiste à installer des filtres à particules et des systèmes de réduction catalytique sélective (SCR) qui convertissent les oxydes d’azote en azote et en eau.  Les solutions ne sont pas seulement technologiques. Ralentissement des navires à l'entrée des ports, pilotage plus efficace et économe en carburant. A Long Beach et au port de Los Angeles, les frais de stationnement sont réduits de 25% pour récompenser la vitesse réduite à l'approche. Le trolleybus est un véhicule électrique qui ne rejette   aucun gaz nocif. En prenant en compte l’impact de la production d’électricité, on peut estimer la production moyenne de CO2 d’un trolleybus à 4 g/km/voyageur contre 40 pour un autobus et 60 pour une automobile.  Un trolleybus parcourt une distance supérieure de 30% à celle d’un autobus. Ainsi, le parc nécessaire en trolleybus serait inférieur de 5 à 7% à celui requis par un service en autobus. Le rendement énergétique du trolleybus s'élève à 9,8 Mégajoules/km-véhicule contre plus de 24 pour l'autobus. Autre avantage du trolleybus, notamment par rapport aux autobus électriques : il s’affranchit des batteries, qui constituent non seulement un poids mort, mais aussi de la question de leur renouvellement.  Le trolleybus moderne est équipé d’un système de freinage à récupération d’énergie ce qui lui permet de réinjecter du courant dans les lignes aériennes;  ainsi à Lyon, trois trolleybus descendant fournissent par la récupération l’énergie nécessaire à un véhicule montant. Dans une approche qualitative globale de l’environnement urbain, la présence de ligne aérienne est compensée par une réduction importante des nuisances sonores et olfactives ainsi que l’absence de rejets de particules. Jamais les voitures vendues sur les marchés français et européens n'ont eu autant de chevaux. La tendance est encore plus nette au niveau européen. Berceau des constructeurs de grosses cylindrées, l'Allemagne redouterait en réalité que les données d'accidentalité soient une contre-publicité pour la vitesse. Sur l'ensemble du réseau allemand, il n'y a qu'un faible tronçon de 388 km où la vitesse est libre, l'accidentalité y est trois fois plus forte que celle en France. La voiture électrique est une voiture onéreuse du fait de l’utilisation de batteries sophistiquées. Avant que son utilisation se généralise et atteigne des prix abordables, il serait judicieux, plutôt que de fabriquer des voitures inutilement performantes, d’assurer la transition en fabriquant des véhicules fonctionnant avec une très faible consommation de carburants et si possible de biocarburants. Alors qu’en France aucun véhicule particulier n’est censé dépasser la vitesse de 130 km/h, les constructeurs offrent des véhicules qui sont capables de vitesses très supérieures à cette limite. Pour une vitesse max de 140 km/h par exemple, une voiture de type Peugeot 308 pourrait se « contenter » d’un moteur de 43 CV (32 kW) ; afin qu’elle soit capable de monter aisément les côtes, sa puissance pourrait être de 50 kW (70 CV). On imagine sans peine les économies de carburant et de coût qu’il serait possible de réaliser …  Une voiture de type Peugeot 308 a besoin de 25 KW pour rouler à 130 km/h. Si elle était équipée en tout électrique avec une batterie de 30 kWh son autonomie serait donc limitée à 1,2 h à cette vitesse, soit 156 km. Ceci démontre que la voiture tout électrique n’est pas un véhicule routier. Elle le deviendra le jour où l’on pourra produire l’électricité à bord avec une pile à combustible.  Ce problème d’autonomie limitée par la capacité de la batterie a conduit les constructeurs à limiter la puissance des moteurs électriques à la valeur que nous avons calculée plus haut, autour de 50 kW. Cette unanimité autour de 60 kW, imposée par la faible capacité spécifique des batteries, pourrait devenir la norme aussi pour les voitures à moteurs thermiques.  Les experts de l’ADEME n’éludent pas la pollution générée pendant sa phase de fabrication : "La voiture électrique consomme moins d'énergie que la voiture thermique car sa chaîne de traction présente un excellent rendement énergétique. Malgré cela, sur l’ensemble de son cycle de vie, la consommation énergétique d’un véhicule électrique est globalement proche de celle d’un véhicule diesel." En cause : la fabrication des batteries extrêmement énergivore.  Sur l'ensemble de son cycle de vie, le véhicule électrique émet l'équivalent de 9 tonnes de CO2 contre 22 tonnes pour un véhicule thermique, selon l'ADEME. Ces chiffres sont donnés pour la France où l’électricité, qui provient aux trois-quarts du nucléaire, est peu émettrice de CO2. Si la voiture électrique n'émet pas quand elle roule de composés organiques volatils ou d'oxyde d'azote même sans pot d'échappement, elle émet des particules fines issues de l'usure des pneus, des plaquettes de frein, des routes. Cette abrasion est responsable de 41% des émissions du secteur du transport routier.  Les méthodes d'extraction du lithium et du cobalt, utilisées pour fabriquer les batteries peuvent poser problème non seulement sur le plan environnemental mais aussi sur le plan éthique en Amérique du Sud, (Extraction polluante du lithium)et en République démocratique du Congo, qui a fourni en 2017 les deux tiers des exportations mondiales de cobalt, les mines sont parfois exploitées dans des conditions déplorables par une main d'œuvre notamment composée d'enfants. La France et le Royaume-Uni ont annoncé leur intention d'interdire les ventes de voitures à moteur à combustion à horizon 2040. La Ville de Paris bannit les vieux diesels. Mais il y a des obstacles : -	 le premier est la batterie, car la voiture électrique nécessite des métaux qui jouent un rôle clef dans leur fabrication. Le prix du lithium a triplé en trois ans, celui du cobalt a pratiquement doublé en un an. Quel sera le prix de la batterie si toutes les voitures sont équipées de moteurs électriques ? Et surtout leurs ressources en cobalt et lithium ne sont pas infinies.  -	le deuxième qu'est la production d'électricité. Car la charge des batteries en exige d'énormes quantités. Un ordre de grandeur : pour charger 1 % du parc français la nuit, il faut pratiquement la production d'une tranche nucléaire.  -	le troisième est le transport de cette électricité. Un dépôt de 200 bus à charger la nuit demande la puissance de 50 immeubles de cinq étages.  Carlos Tavares, patron de PSA, déplore que depuis 2 ans, dans le sillage du "Dieselgate" les gouvernements aient pris des positions de plus en plus radicales qui changent la nature des réglementations. "On est en train d’évoluer vers un monde où on nous instruit d’aller dans la direction du véhicule électrique". Si la feuille de route de PSA qui prévoit que 50% de la gamme sera électrifiée en 2020 et 80% en 2023 montre qu’il n’a pas d’état d’âme en tant que dirigeant, il s’en inquiète "en tant que citoyen" : "Qui traite la question de la mobilité propre dans sa globalité ? Comment est-ce que nous allons produire plus d’énergie électrique propre ? Comment faire pour que l’empreinte carbone de fabrication d’une batterie du véhicule électrique ne soit pas un désastre écologique ? Comment faire en sorte que le recyclage d’une batterie ne soit pas un désastre écologique ? Comment trouver suffisamment de matière première rare pour faire les cellules et les chimies des batteries dans la durée ? Qui aujourd’hui est en train de se poser la question de manière suffisamment large d’un point de vue sociétale pour tenir compte de l’ensemble de ces paramètres  "Pendant un siècle les Chinois ont couru après le moteur à combustion interne en versant des royalties à l’occident. Là, ils ont trouvé le point de rupture et maintenant ils prennent le lead sur le véhicule électrique qui est le symétrique pour le prochain siècle de ce qu’ils ont vécu au cours du précédent", a dit Carlos Tavares. Dans le cadre de leur engagement sur la 40ème Route du Rhum 2018, l’entreprise Leyton et son skipper, Arthur Le Vaillant, ont souhaité quantifier les impacts carbone et environnementaux de leur bateau. Ils ont fait appel à E6 pour réaliser cette mission. Un Class40 est un voilier monocoque de 12,2 m. Sa fabrication génère de l’ordre de 25 tonnes eq CO2, dont 90% de l’empreinte carbone est liée à la fabrication des matières premières. On peut réduire l’impact carbone en prolongeant la durée de vie des bateaux. La 40e édition du rallye Dakar (ex Paris Dakar) s’est déroulée avec un départ de Lima, au Pérou. Plus de 500 pilotes d'autos, de motos, de quads, ou de camions ont parcouru près de 9 000 km à travers le Pérou, la Bolivie et l'Argentine où l'arrivée s’est faite le 20 janvier à Cordoba. Le Dakar fait l'objet de nombreuses critiques en matière d'environnement. " C'est évidemment l'influence que peut avoir ce spectacle médiatique sur le dérèglement climatique mais aussi sur les écosystèmes au travers du passage de ces fous du volant avec des voitures et des camions qui empruntent des milieux fragiles. Il y a l'impact direct : le Dakar va émettre directement près de 40 000 tonnes de CO2. Nous sommes entrés dans l'ère du dérèglement climatique il serait souhaitable que les spectacles mis en avant soient au diapason de la contrainte climatique. L'impact direct, on le constate avec effroi, ce sont des décès d'enfants et de personnes qui traversent les rues de leurs villages et qui subissent les vitesses inouïes de ces véhicules. Quand le Dakar est passé au Chili il y a quelques années près de 180 sites archéologiques ont été détruits ou endommagés par les véhicules passant. Des fresques qui dataient de plusieurs centaines d'années ont été détruites.  Dès qu’on pense à un Grand Prix de F1, on pense pollution. Une chose est certaine : elles polluent beaucoup. Un Grand Prix, c’est une vingtaine de ces bolides qui crachent une quantité féroce de CO2, le tout dans un fracas motorisé digne des pires enfers. La FOTA a comptabilisé quelques 9900 tonnes de CO2 recraché par course. En comparaison, un avion qui voudrait recracher une telle quantité de CO2 devrait effectuer au moins 10 fois un aller-retour Paris-New-York. 918 courses ont été disputées depuis 1950, dans le seul cadre d’un Grand Prix (on ne comptabilise donc pas les multiples courses et essais) on dresse vite le constat de l’impact que la pratique de la course en formule 1 peut avoir sur l’environnement. Les courses de formule 1 et le Dakar devraient être purement et simplement supprimées. Le groupe écologiste de Paris a demandé  à la maire PS Anne Hidalgo «des comptes sur le coût écologique et financier» du ePrix de Formule E (monoplaces électriques), organisé depuis 2016 dans la capitale : En 2016, on a pu voir des bolides entièrement électriques foncer à 200km/h dans les rues de la capitale. Le circuit avait été asphalté en conséquence, le goudronnage du quartier des Invalides, a été vécu par certains comme un véritable désastre écologique. Il serait préférable que ce type de course sur un circuit déjà asphalté. Dès 2009, Génération Ecologie dénonçait « l’irresponsabilité environnementale des organisateurs du Tour de France ». Ils étaient alors pointés du doigt pour ne pas s’imposer de précautions en matière d’environnement et de pollution.  Le Tour est une belle course à vélo au gré de paysages magnifiques, mais sur le terrain, son empreinte carbone et écologique est à la hauteur du 3e événement sportif au monde, après les Jeux Olympiques et la Coupe du Monde de football. Quelque deux cents coureurs cyclistes, des centaines de voitures suiveuses, des camions techniques (service d’ordre, secours, presse…), des bus qui parcourent des milliers de kilomètres le long de la « Grande Boucle », des hélicoptères, des avions, sans compter les 10-12 millions de spectateurs qui se déplacent, en camping-cars ou en voitures, pour admirer la course le long des routes : l’empreinte écologique du tour est énorme et cette célèbre course illustre bien la difficulté à gérer les effets environnementaux d’événements sportifs majeurs.  L’une des attractions préférées du public, c’est la distribution de cadeaux par la caravane publicitaire : des « pognes » pleines de cadeaux, de porte-clés, d’échantillons, de confiseries qui sont jetés au public pendant le Tour. Au total, environ 14 millions de petits objets, les goodies, validés par l’organisation du Tour de France, sont distribués, jetés depuis des véhicules en mouvement. Des mesures devraient être prises pour réduire voire supprimer la caravane publicitaire La Cour des comptes critique la gestion des domaines skiables, de plus en plus vulnérables au réchauffement climatique. Après une première mise en garde il y a sept ans, la Cour des comptes s’est de nouveau alarmée il y a quelques jours de la « vulnérabilité croissante » des stations de ski des Alpes du Nord face au réchauffement climatique. Dans leur rapport annuel, les magistrats dénoncent les réponses inadaptées des gestionnaires des domaines skiables. Entre 2015 et 2017, la Cour a contrôlé la gestion de dix-sept domaines skiables, dont Chamonix, Megève, Courchevel et Tignes. Le rapport constate « l’aggravation de certains déséquilibres » liés à un modèle de développement « ayant atteint ses limites ». Pointant des investissements « privilégiant le court terme », elle dénonce notamment la généralisation de l’enneigement artificiel, présenté comme une solution « partielle et onéreuse ». Confrontées à une pénurie de neige ces dernières années, les stations y ont eu abondamment recours, ce qui pose des problèmes d’approvisionnement en eau. Actuellement, 30 millions de m3 d’eau sont utilisés chaque année pour fabriquer de la neige de culture pour les canons. Le recours de plus en plus systématique à ce palliatif soulève de nombreuses questions. Considérée parfois comme une garantie pour assurer la saison, la neige artificielle – qui nécessite de lourds investissements – ne peut être cependant utilisée comme la solution miracle. Malgré le coût important de l’enneigement artificiel, les stations sont de plus en plus nombreuses à s’équiper pour garantir à leurs visiteurs un enneigement de bonne qualité. Cette augmentation de l’enneigement artificiel a plusieurs conséquences sur l’environnement : • l’utilisation des ressources en eau  • une consommation d'énergie très importante (les 10.000 canons à neige français consomment 108 millions de kWh) • une pollution éventuelle par les additifs ajoutés dans l’eau  • une érosion supplémentaire due à la quantité de neige produite. Cette neige artificielle est 50 fois plus dure et 4 fois plus dense que la neige naturelle, ce qui favorise l’érosion.    CONCLUSIONS Lors de la campagne électorale, suite un accord avec les Verts, François Hollande avait annoncé son engagement de faire chuter de 75 % à 50 % la part du nucléaire dans la production d'électricité à l’horizon 2025. Ségolène Royal a décidé de fermer la centrale de Fessenheim quinze jours avant le premier tour de l’élection présidentielle de 2017afin de tenir la promesse faite par François Hollande. Cette décision a été prise sans tenir compte de l’avis de l’Académie des Sciences, ni de celui de l’Académie des Technologies, en contradiction avec l’avis du GIEC et de plusieurs scientifiques qui jugent irréaliste la baisse de la production d’électricité d’origine nucléaire. Du fait de l’intermittence des énergies renouvelables et de l’impossibilité de stocker massivement l’énergie électrique, il faudra faire appel à des énergies carbonées pour assurer une production suffisante d’électricité. Jean Marc Jancovici a démontré l’impossible pari de remplacer l’énergie d’origine nucléaire par des énergies renouvelables. La seule politique raisonnable consiste à prolonger la vie des réacteurs qui fonctionnent de façon satisfaisante et permanente. Continuer à développer les énergies renouvelables alors que le problème du stockage de l’électricité n’est pas résolu est une hérésie, il serait en revanche important de lancer des recherches pour augmenter la durée de vie de ces énergies et surtout pour réduire la quantité de terres rares nécessaires au fonctionnement des éoliennes. L’énergie nucléaire est un moyen de production massive d’électricité qui est pilotable et qui ne contribue pas au réchauffement climatique ni à la pollution de l’atmosphère. Le charbon autre moyen de production massive d’électricité présente l’inconvénient de relâcher dans l’environnement de grandes quantités de CO2, mais aussi des oxydes d’azote et de soufre, des particules fines et des composés organiques toxiques qui provoquent beaucoup plus de décès que le nucléaire lors de l’accident de Tchernobyl. Au contraire de l’énergie nucléaire qui produit des déchets extrêmement radioactifs, le charbon produit d’énormes quantités de déchets difficiles à gérer.  Il est curieux que l’ADEME financé par l’Etat ne soit pas objective et émette des rapports qui attirent de sévères critiques d’organismes compétents. Ce n’est pas étonnant de la part d’un organisme dirigé par un ancien « Verts »  et sous la tutelle d’un Ministère dirigé depuis des décennies par des écologistes. Il serait temps de mettre à la tête de ce Ministère et de l’ADEME des personnes compétentes et objectives. L’hydrogène est un vecteur énergétique et non pas une source d'énergie car il n'existe pratiquement pas à l'état naturel. Le procédé le plus courant de fabrication de l'hydrogène est le reformage du gaz naturel par de la vapeur d'eau surchauffée, ce procédé présente l’inconvénient de produire du CO2. L’hydrogène est aussi fabriqué par électrolyse de l'eau. Le rendement est de 50 % pour obtenir de l’hydrogène sous pression à 700 bars et de 40% pour obtenir de l’ l’hydrogène liquide. Son stockage est difficile et surtout son large domaine d’inflammabilité le rend très dangereux. L’expérience MYRTE conduite en Corse n’est pas concluante pour le stockage d’énergie, et n’est pas pertinente pour la production d’électricité, du fait du coût prohibitif de stockage de cette énergie. Le gouvernement s’abrite derrière la loi de transition énergétique pour promouvoir les véhicules à essence au détriment des véhicules diesels. La fiscalité dite « écologique » est indexée sur les émissions de CO2, le gouvernement favoriserait les véhicules à essence plus émetteurs de ce gaz afin d’augmenter les rentrées fiscales. PPE et respect des accords de Paris Pour des raisons « bassement » électorales, les « Verts » incitent le gouvernement à arrêter 14 réacteurs nucléaires d’ici 2035 pour les remplacer par des énergies renouvelables intermittentes. Le doublement du coût du kWh depuis les années 2000 est dû aux taxes, en particulier à la CSPE qui sert essentiellement à financer les énergies intermittentes. Les subventions à l’éolien et au photovoltaïque coûtent chaque année à la France 2 réacteurs EPR.  Plusieurs organismes ont élaboré pour la France des scénarios de transition énergétique, parmi les plus connus, Negawatt et Negatep. Le scénario Negawatt préconise que 90% de nos besoins soient assurés en 2050 par les énergies renouvelables essentiellement grâce à la biomasse, à l’éolien et au photovoltaïque. Un recours temporaire au gaz permettrait de fermer progressivement la totalité des réacteurs nucléaires. Un tel scénario envisage une production éolienne de 209 TWh en 2050, contre 15 TWh en 2012, les problèmes d’intermittence étant réglés par la production d’hydrogène et de méthane. Ce scénario est irréaliste D’autant plus qu’il faudrait réduire la demande en énergie primaire de 66% alors que la population augmenterait de 15%. Cette réduction devrait venir de l’efficacité et de la sobriété énergétique.  Le scénario Negatep prévoit une division par 4 des rejets de CO2 malgré une baisse de seulement 18 % de la consommation d'énergie finale. Les énergies fossiles seraient très largement remplacées par les énergies renouvelables et le nucléaire capables de produire de l'électricité décarbonée dont la production augmenterait de 61%. Aucun scénario ne prétend qu'il soit possible de remplacer les énergies fossiles et nucléaires par des renouvelables sans une diminution drastique de la consommation. Tous les scénarios préconisent une baisse de la consommation d'énergie malgré une hausse de la population en misant sur l'efficacité énergétique dont l'importance est donc cruciale. L’efficacité énergétique fait l’unanimité puisqu’il s’agit de consommer moins à service rendu égal. La sobriété énergétique est beaucoup plus complexe à développer car elle implique des changements considérables de modes de vie et d’organisation de la société. En 2011, l’Allemagne a décidé d’arrêter progressivement ses réacteurs nucléaires et de compenser la production d’électricité avec des énergies renouvelables. De 1995 à 2014, l'Allemagne a investi 350 milliards d'euros dans des éoliennes, panneaux solaires, méthaniseurs et modifications du réseau électrique, pour faire passer de 4 à 26 % la part de sa production électrique provenant de sources renouvelables.  Or cet investissement n'a pas changé l'évolution des émissions de CO2 de l'Allemagne, ni sa dépendance à l'énergie fossile importée. La production d'électricité renouvelable a fortement augmenté depuis les années 1990. De 20 milliards de kilowattheures électriques renouvelables produits en 1996 (soit 4 % de la production allemande), essentiellement à partir de barrages, l'Allemagne est passée à un peu plus de 150 en 2014, dont environ 24 d'hydroélectricité, 55 d'éolien, 35 de solaire, et 35 à partir de méthaniseurs. Pour arriver à ce résultat, les Allemands ont installé, à fin 2014, une puissance de 38 gigawatts en solaire, 40 en éolien, de l'ordre de 9 en biogaz, et un peu plus de 4 en hydraulique, soit plus de 90 gigawatts. La capacité nucléaire française est de l'ordre de 65 gigawatts qui produisent un peu plus de 400 térawattheures d'électricité par an, quand les 90 gigawatts de renouvelables allemands ne produisent « que » 150 térawattheures d'électricité sur la même durée. Par gigawatt installé, le nucléaire produit donc environ 4 fois plus que les renouvelables installées chez nos voisins. Aux États-Unis, les réacteurs nucléaires ont un facteur de charge de 90 % environ, car ils tournent toute l'année. En France, ces mêmes réacteurs sont plus proches de 70 à 75 %, car une partie de leur puissance ne sert que l'hiver. En Allemagne, ce facteur de charge baisse énormément : pour l'éolien, il varie entre 15 et 20 %, selon les années. Pour le solaire, ce facteur dépend beaucoup de la latitude il est légèrement inférieur à 10 % en Allemagne. Enfin pour le biogaz, le facteur de charge est plus proche de 60 %. Mais, comme le solaire et l'éolien dominent largement dans les capacités nouvelles en Allemagne, la moyenne pour l'ensemble du parc renouvelable est descendue de 40 à 20 % entre 1996 et 2014. On devrait donc s'attendre à ce que la production faite avec le reste ait baissé, et en particulier la production à base de combustibles fossiles puisque le développement des renouvelables est vu comme un moyen de faire baisser les émissions de CO2. Il n’en est rien Une première explication de ce paradoxe est qu'une bonne partie de la hausse des renouvelables est venue en plus de la production préexistante, et n'a donc rien substitué du tout.  La deuxième raison est due au fait que la production allemande renouvelable supplémentaire a servi à baisser le nucléaire. La baisse du nucléaire a donc été considérée comme prioritaire sur la baisse du charbon. L'histoire devra juger pourquoi nos voisins ont préféré diminuer le recours à une énergie qui présente des risques qui restent minimes et localisés, au profit d'une énergie qui disperse dans l’atmosphère massivement du CO2, différents polluants et des particules fines. Dans certaines régions d’Allemagne, des villages sont déplacés pour permettre l’extraction du charbon et du lignite. L’électricité produite par les EnRI doit être utilisée immédiatement car les possibilités de stockage sont négligeables quand le vent ne souffle pas et quand le soleil ne brille pas. Le réseau ne peut donc pas être alimenté uniquement à partir d’énergies renouvelables sans l’approvisionnement de sources stables et pilotables alimentées par des énergies fossiles ou par… du nucléaire acheté en France. La restructuration du système électrique belge, de manière générale, et du mix électrique, en particulier, agite beaucoup le monde politique belge ces derniers temps. Alors que les centrales nucléaires n’émettent pas plus, voire moins, de gaz à effet de serre (GES) que la production éolienne ou photovoltaïque sur un cycle complet de vie et que, d’autre part, la roadmap 2050 de la Commission européenne prévoit toujours, à cette échéance, du nucléaire dans le parc électrique européen, le gouvernement belge a décidé, de sortir de cette forme de génération d’électricité entre 2022 et 2025. Les conséquences néfastes d’un mix électrique sans nucléaire, viendraient s’ajouter aux dysfonctionnements causés par la priorité d’accès aux réseaux électriques concédée au renouvelable intermittent ainsi qu’aux subventions généreuses et autres avantages qui leur ont été accordés. La sortie totale du nucléaire ne se justifie ni par des raisons technique ou économique, ni d’un point de vue politique. D’autre part, sans capacité nucléaire, l’importation d’électricité va augmenter, soit en provenance de la France (essentiellement nucléaire) ou de l’Allemagne (principalement à partir de charbon et de lignite), donc des modes de production dont le gouvernement belge ne veut plus. Quelle est dès lors la logique qui sous-tend la dénucléarisation de la génération d’électricité? La sortie du nucléaire n’est pas non plus pertinente d’un point de vue économique. La pénétration croissante de l’éolien et du photovoltaïque et la fermeture des centrales nucléaires entraînent un gonflement du prix de l’électricité et partant une diminution de la compétitivité des entreprises et du pouvoir d’achat des ménages ainsi que de la sécurité d’approvisionnement électrique. Cette forte augmentation du prix de l’électricité résulte d’un certain nombre de facteurs dont: - le coût de la construction de nouvelles centrales au gaz indispensables pour assurer l’équilibre du système. - de rémunération pour convaincre les producteurs d’électricité d’investir dans de nouvelles centrales au gaz qui sont très loin d’être rentables si elles ne sont destinées qu’à compenser l’intermittence des énergies renouvelables - du coût de stockage d’électricité essentiel pour mitiger les fluctuations de la génération renouvelable au-delà d’un certain niveau de pénétration - du coût de renforcement et d’extension des infrastructures de transmission et de distribution d’électricité requis, entre autres, par la dispersion de la production renouvelable; - et, bien entendu, des subventions accordées au renouvelable. Imaginer que la consommation d'électricité pourrait décroitre est peu crédible. Prendre d'ores et déjà cette décroissance pour un fait acquis dans le dimensionnement de notre parc électrique est irresponsable. L'électricité ne représente cependant que 23 % de la consommation finale d'énergie en France, penser qu’elle peut décroitre est irréaliste, la production d’électricité d’origine renouvelable ou nucléaire doit croitre pour se substituer à celle produite par les énergies carbonées. De plus le développement même très progressif de la voiture électrique, l’essor de l'économie digitale qui pèsera plus de 20 % de la consommation mondiale d'électricité en 2020, le remplacement du chauffage au fioul par des pompes à chaleur… nécessiteront également un accroissement de la production d’électricité. Enfin, l'intermittence des énergies renouvelables en expansion exige une production pilotable d’électricité qui ne peut provenir que des énergies hydraulique ou nucléaire, si on exclut les énergies carbonées émettrices de C02. Car le développement de l'intermittence implique l'augmentation des moyens pilotables dédiés au lissage de sa production. En France, le choix ne réside qu'entre de nouvelles centrales thermiques ou l'asservissement du parc nucléaire aux caprices de la production éolienne, lui imposant des régimes chaotiques et à coups de fonctionnement, ainsi que c'est déjà le cas lors des records éoliens. Ce qui accélère le vieillissement des composants des centrales, ainsi qu'une perte de rentabilité, pour un avantage sur lequel il est permis de s'interroger. Les énergies renouvelables se sont pourtant révélées parfaitement inefficaces pour atteindre les trois objectifs qui leur étaient assignés : réduire l’impact environnemental, renforcer la sécurité d’approvisionnement, et maîtriser les coûts. Avec 500 milliards de kWh produits chaque année en France, les batteries resteront à jamais hors de portée pour du stockage d'une saison à l'autre, ce qui serait nécessaire car l'hiver la consommation augmente plus que la production de renouvelables. Malgré la multiplication de démonstrateurs hors de prix, aucune avancée technologique ne permet d’espérer stocker massivement l’énergie pour un coût acceptable par la collectivité. Ce stockage reste pourtant indispensable pour que les énergies intermittentes confèrent une valeur ajoutée au parc électrique français. C'est la flexibilité unique au monde qui a permis à notre parc électrique de réduire à l'extrême le recours aux centrales thermiques. Et c'est grâce à ce parc nucléaire que la Commission européenne attribue à la France une indépendance énergétique bien supérieure à celle de ses voisins, et notamment à celle de l'Allemagne. L'objectif de 50 % de nucléaire dans la production d'électricité - contre 75 % actuellement est né pendant la campagne présidentielle de François Hollande en 2012. Ce chiffre n'a été précédé d'aucune analyse sérieuse n’a tenu aucun compte de l’avis de l’Académie des sciences ou de l’Académie des technologies ou de la Cour des comptes. Cet objectif a été émis uniquement pour des motifs de basse politique. Le 28 mars 1979 est survenu l’accident de Three Mile Island, centrale située, à 15 km d’Harrisburg, une ville de 60.000 habitant. Malgré la fusion partielle du cœur l’enceinte de confinement a tenu son rôle, la quasi-totalité de la radioactivité est restée contenue à l’intérieur du bâtiment réacteur. Et pourtant, cet accident n’a causé aucune victime et le seul relâchement de radioactivité dans l’environnement n’a consisté qu’en une émission de gaz rares sans activité biologique. Tous les réacteurs du monde ont profité des enseignements tirés de l’accident de TMI2. La prise en compte de ces leçons a réduit d’un facteur 10 le risque de fusion de cœur dans les réacteurs occidentaux « de deuxième génération » La centrale de Tchernobyl comptait quatre réacteurs de type RBMK de conception soviétique. Ce modèle de réacteur est modéré au graphite et est refroidi à l'eau. Le combustible est de l'oxyde d'uranium enrichi à 2% en 235U. Les spécialistes jugent que ce réacteur comportait des défauts de conception qui le rendait potentiellement dangereux car le cœur du réacteur est instable en dessous de 700 MWth, c'est-à-dire à faible puissance. Du fait de son instabilité à faible puissance le réacteur, suite à des essais périlleux, le réacteur s’est emballé et a atteint une puissance de l'ordre de 100 fois sa valeur nominale provoquant la vaporisation de l’eau refroidissant le réacteur et produit une explosion de chaleur qui détruit le réacteur. Les 600 tonnes de graphite du cœur, s'enflamment. L’intensité d'incendie et l'absence d'enceinte de confinement favorisent la dispersion dans l'atmosphère de grandes quantités de produits radioactifs. Le principal effet détecté des rejets radioactifs est l'augmentation des cancers de la thyroïde, en particulier, chez les enfants et les adolescents. Des études internationales sont en cours pour quantifier les risques de leucémies chez les liquidateurs. On estime que 3 000 des 600 000 personnes ayant travaillé au contact direct de la centrale mourront des suites de l'exposition aux radiations. Cet accident a été exploité par les adversaires du nucléaire alors que ce réacteur n’a rien de commun avec les réacteurs en service  en France. Le nuage radioactif est encore évoqué, entraîné par les masses d'air jusqu'à dix mille mètres d'altitude et dérivant au gré des vents, a disséminé sur la plupart des pays d'Europe des produits radioactifs. Il est à noter que malgré un important relâchement de produits radioactifs dans l’atmosphère, la radioactivité due à l’accident de Tchernobyl est très inférieure à celle dégagée lors des essais nucléaires aériens effectués de 1945 à 1980. En deçà d’une certaine distance de Tchernobyl, l'impact sanitaire dû à l’accident est naturellement plus important que l'impact des essais. Mais, au-delà de cette distance, la retombée de l'accident devient rapidement négligeable devant la retombée globale due à la totalité des essais nucléaires aériens. L'accident nucléaire de Fukushima est un accident industriel majeur qui a débuté le 11 mars 2011 au Japon, à la suite d’un séisme de force 9 et d’un tsunami en résultant d’une violence exceptionnelle. Il s'agit de la plus grave catastrophe nucléaire du 21eme siècle, classée au niveau 7, le plus élevé sur l'échelle internationale des événements nucléaires (INES), au même degré de gravité que la catastrophe de Tchernobyl (1986), en particulier par le volume important des rejets radioactifs.  Quatre centrales nucléaires se situent sur la côte nord orientale et se sont arrêtées automatiquement à la suite des premières secousses : les centrales de Fukushima Daiichi, de Fukushima Daini, d’Onagawa et de Tokai. La détection des premières secousses provoque l'arrêt des réacteurs 1, 2 et 3 Fukushima Daiichi (soit 30 secondes avant les secousses principales qui ont duré près d’une minute). Le tremblement de terre entraine la destruction des six lignes d’alimentations électriques externes des réacteurs et le démarrage des douze groupes électrogènes de secours à moteur diesel pour faire fonctionner des pompes de refroidissement. Cinquante-et-une minutes après la première secousse, la première vague du tsunami, d'une hauteur de 15 mètres, atteint la centrale nucléaire de Fukushima Daiichi. Elle est suivie de plusieurs autres vagues de moindre importance. Le tsunami a eu pour conséquences une dégradation des prises d’eau en mer conduisant à la perte de la source froide, puis à la perte des Diesels de secours des réacteurs 1 à 4. À la suite de la perte des Diesels, un système d'ultime secours permettant de faire circuler l'eau contenue dans les tores situés en partie inférieure des bâtiments, au pied des cuves des réacteurs, s'est mis en marche puis s'est arrêté par défaillance des batteries électriques. Il n'y avait dès lors plus de moyens de refroidissement disponibles. Entre le 12 mars et le 15 mars les réacteurs 1, 3 et 2 sont successivement détruits suite à des explosions ^produites par des dégagements d’hydrogène. À partir de ce stade des rejets massifs vont se produire dans l'atmosphère et l'environnement et l'ensemble des acteurs vont devoir gérer la phase post-accidentelle : l'exploitant va tenter de refroidir les installations puis de réduire les émissions tout en n'exposant pas trop les travailleurs. Les autorités vont prendre des mesures pour tenter de protéger la population. L’accident est un accident de refroidissement comme celui survenu en 1979 à Three Mile Island aux Etats-Unis.  Les réacteurs se sont arrêtés automatiquement lors du tremblement de terre et avec eux les fissions nucléaires. Mais les désintégrations radioactives continuent de dégager de la chaleur. Il est impératif de refroidir. Or le séisme de force 9 et la vague du tsunami ont endommagé et inondé les circuits de refroidissement et installations de secours, conduisant à une perte totale des alimentations électriques et des moyens de refroidissement principaux durant de longues heures. A ces pannes multiples s’ajoutent des conditions d’intervention dramatiques. Villes et villages de la côte ont été dévastés par le tsunami, les routes sont impraticables. Ce tsunami a engendré plus de 18 000 morts et disparus, des blessés et des destructions considérables. Les premières équipes doivent intervenir alors que leurs vies ont été bouleversées et que les familles sont à la recherche de proches disparus. L’accident est la preuve que les scénarios extrêmes peuvent arriver, avec la concomitance de multiples pannes. La conduite à tenir dans de telles circonstances n’avait pas été envisagée et la gestion de la crise et de ses multiples rebondissements s’est effectuée de façon approximative, On peut jeter a posteriori un regard effrayé sur cette gestion. Cependant, les dispositifs existants quoique insuffisants ont porté leur fruit et atténué l’accident. Les enceintes de confinement ont joué leur rôle ; le gros de la radioactivité est resté dans ces enceintes ; quatre jours se sont écoulés avant le principal rejet de radioactivité donnant le temps de mettre à l’abri les populations.  Si les pertes en vies humaines dues à la radioactivité seront probablement minimes, les conséquences sont lourdes pour la société et l'économie japonaise. Il y a d'abord le coût humain des évacuations et des déracinements, celui des décontaminations.  On a beaucoup moins parlé de la crise qui a affecté Fukushima Daini, sa centrale sœur, à environ 10 kilomètres au sud ; elle aussi a essuyé d’importants dommages, mais a échappé au sort de Daiichi. Le directeur du site, ainsi que les 400 employés de Daini ont su se frayer un chemin dans le chaos de la situation, et la centrale s’en est tirée sans fusion ni explosion. Située au nord du Japon, la centrale nucléaire d’Onagawa, la plus proche de l'épicentre du tremblement de terre et soumise à des secousses encore plus violentes, n'a pas subi de dommages majeurs car conçue avec des marges de sécurité suffisantes. La centrale d'Onagawa a enregistré des secousses sismiques qui ont dépassé sa capacité nominale, et le sous-sol de l'un de ses bâtiments des réacteurs a été inondé. Mais l'usine a maintenu sa capacité de refroidissement, ses réacteurs se sont arrêtés sans dommages à leurs cœurs ni dommages importants aux systèmes de sécurité. Tous les réacteurs du monde ont profité des enseignements tirés de l’accident de Three Mile Island. La prise en compte de ces leçons a réduit le risque de fusion de cœur dans les réacteurs de deuxième génération. L’ASN a, suite à l’accident de Fukushima, demandé à EDF d’effectuer des travaux en particulier afin de maintenir une alimentation en eau et en électricité pérenne des réacteurs en cas de forts séismes ou d’importantes inondations, diminuant ainsi fortement le risque d’accident. La France devrait suivre l’exemple des Etats Unis où 81 des 99 réacteurs évoqués ont déjà obtenu le droit de poursuivre leur exploitation jusqu’à 60 ans, et pourraient étendre leur durée d’exploitation de 60 à 80 ans. Selon des chercheurs de la NASA, l'énergie nucléaire pourrait avoir sauvé 1,8 million de vies autrement perdues à cause des combustibles fossiles, et pourrait en sauver jusqu'à 7 millions de plus au cours des quatre prochaines décennies.  Dans tous secteurs industriels de nombreux accidents se produisent, industrie chimique, rupture de barrages, exploitation et transport d’hydrocarbures, extraction et exploitation du charbon… Souvent ces accidents majeurs ne sont pas dus à une cause extérieure comme ce fut le cas à Fukushima, en revanche elles ont pu être déclenchées par des actions malveillantes. Dans certains cas, comme à Bhopal le nombre de décès immédiats et postérieurs à l’accident est très élevé. Ces accidents à l’instar de Tchernobyl et Fukushima occasionnent également dans certains cas de grands dommages à l’environnement (marées noires, mines de charbon). Pourtant malgré les nombreuses victimes dus à des accidents ou à des pollutions majeures comme c’est le cas pour l’extraction et la combustion du charbon ou du lignite, les écologistes privilégient l’utilisation du charbon plutôt celle du nucléaire.  L’IRSN considère à ce jour que la séparation/transmutation ne constitue pas une alternative au stockage géologique et se prononce pour le projet. Le rapport rendu public par l’ASN est une étape importante dans la validation technique du projet. Pour la grande majorité des déchets prévus dans Cigéo (plus de 80 %), l’ASN a considéré que les options de sûreté sont satisfaisantes. Les seules restrictions concernent les déchets bitumeux. Pour être acceptés dans Cigéo, ces déchets pourraient être conditionnés dans une matrice inerte. Actuellement le retraitement du combustible après séjour dans un réacteur consiste à séparer uranium et plutonium qui peuvent être réutilisés. Les éléments restants (actinides mineurs et produits de fission) sont entreposés après vitrification dans les usines de retraitement avant envoi ultérieur à Cigéo. Le recyclage des actinides mineurs permettrait de réduire notablement la quantité de déchets à vie longue, mais cette solution n’est pas envisageable à ce jour. Le recyclage nécessite une séparation préalable de ces actinides mineurs et des lanthanides du reste des produits de fission. Des essais au niveau laboratoire ont démontré la possibilité de séparer ensuite les actinides des lanthanides. Les actinides pourraient être éliminés par transmutation et les lanthanides dont le néodyme recyclés, les besoins pour ces éléments étant importants. De même pourraient être récupérés certains dans ces déchets platinoïdes rares et très onéreux (ruthénium, rhodium, palladium). L’élément de base de l’énergie nucléaire est l’uranium, si un jour les ressources en uranium venait à s’épuiser, le thorium beaucoup plus abondant, pourrait être un substitut à l’uranium, d’autant plus que des stocks de thorium existent déjà car cet élément est un sous-produit de l’extraction des terres rares. Le thorium est fertile, après passage dans un réacteur, est converti en 233U fissile. La fission de l’233U produit moins actinides que la fission de l’235U, ce qui peut être un avantage  Les réacteurs à neutrons rapides (RNR) présentent plusieurs atouts déterminants vis-à-vis de la gestion des matières en complémentarité des filières existantes: • ils peuvent utiliser sans limitation le plutonium produit par les réacteurs à eau assurant une gestion pérenne; • en permettant de valoriser l’238U, ils multiplient par un facteur voisin de 100, l’énergie que l’on peut extraire d’une masse donnée d’uranium naturel.  • ils ont la capacité, une fois constitué le stock nécessaire à leur démarrage, de se passer totalement d’uranium naturel. Ils n’ont besoin que d’un appoint d’238U. En France le stock d’uranium appauvri issu des opérations d’enrichissement lui assurerait une indépendance énergétique quasi inépuisable pour un parc de RNR; • le spectre des neutrons rapides ouvre aussi la possibilité de transmuter les actinides mineurs et permet une réduction de l’inventaire de ces radionucléides dans les déchets. La plupart des grands pays nucléaires s’intéressent fortement à la technologie des réacteurs à neutrons rapides refroidis au sodium. Ainsi, l’Inde devrait mettre en service dans les prochains mois un réacteur de puissance 500 MWe, et la Russie a démarré en juin 2014 un réacteur de 800MWe. La Chine est encore en retrait, mais affiche des ambitions importantes dans le domaine.  La France envisage la construction d’Astrid, un démonstrateur d’intégration technologique, d’une puissance électrique de 600 MWe environ, permettant une démonstration de sûreté et de fonctionnement à l’échelle préindustrielle de RNR‐Na de 4èmegénération. L’objectif est une mise en service au cours de la décennie 2020. Il serait judicieux de ne pas tarder à lancer le projet. L’exploitation d’Astrid pendant une dizaine d’années doit ensuite permettre le déploiement de réacteurs commerciaux. La Balance commerciale de la France est déficitaire depuis des décennies et se creuse ces dernières années, qu’en serait-il pour l’approvisionnement énergétiques du pays, si le nucléaire ne se substituait pas au gaz ou au pétrole ? Suite à l’accident de Fukushima, les comptes du commerce extérieur du Japon, généralement excédentaires, ont affiché un solde négatif historique pour la période d'avril 2011 à mars 2012 du fait de l’obligation d’importer plus d’hydrocarbures suite à la diminution de la production d’énergie d’origine nucléaire. Le déficit de la balance commerciale de la France pourrait être réduit en réduisant l’achat d’hydrocarbures et en augmentant la durée de fonctionnement de nos réacteurs.  Les composés organiques (à base de carbone) peuvent être synthétisés en cas de pénurie, ce fut le cas en Allemagne et Japon pour la synthèse de carburants pendant la seconde guerre mondiale. La synthèse de métaux n’est pas envisageable, il faut d’ores et déjà identifier les minerais exploitables en particulier en élargissant l'horizon géologique français qui n'est pas connu au-delà de 100 mètres de profondeur. Il est nécessaire aussi de développer le recyclage des métaux. Avant de se lancer dans des projets innovants, il faut s’assurer que ces projets sont durables. Ainsi les ressources en cobalt et en lithium sont-elles suffisantes, à des couts d’extraction acceptables, pour satisfaire la construction de voitures électriques au niveau mondial ? La France devrait s’inspirer de l'Allemagne qui a pris conscience de sa dépendance à l'égard des métaux critiques. Un petit explorateur minier a été formé par de grands groupes allemands pour découvrir et réserver des gisements futurs de ces métaux. Près de 50 % de l’énergie primaire provient des combustibles fossiles, en particulier du pétrole dont il faudra réduire la consommation pour atteindre les objectifs de la loi sur la transition énergétique. Le secteur du bâtiment pèse pour 44% dans la consommation énergétique finale française, tout secteur confondu. Le remplacement du chauffage au fioul des habitations par le chauffage électrique est un moyen drastique de réduire les rejets de CO2 dans les villes. Le chauffage au bois est une alternative pour remplacer sa chaudière au fioul, mais tout de même très polluante. La meilleure solution est les pompes à chaleur. Si elles sont relativement récentes, et à ce titre présentent encore un coût d’installation élevé, elles n’en sont pas moins le moyen le plus écologique et le plus économique pour se chauffer en France. A Marseille, deux compagnies ont équipé leurs navires d’un système d’alimentation électrique de courant à quai. Ce système, permet aux navires d’être branchés à quai 30 minutes après le débarquement des passagers et débranchés 2 heures avant l’appareillage : ainsi alimentés en électricité, le recours aux moteurs au fioul, n’est donc plus nécessaire pendant les escales. Ce système électrique innovant a permis de réduire de 30% la consommation de carburant de la flotte en un an. Les économies réalisées sont évaluées entre 2 et 4 tonnes de fioul par ferry et par escale quotidienne. Cet effort doit être poursuivi et étendu progressivement à l’ensemble des navires présents dans le port. A quai, les navires stationnant plus de deux heures non équipés d’un système d’alimentation électrique de courant à quai sont tenus de passer au diesel marin contenant un taux de 0,1% de soufre ce qui représente encore un taux 100 fois plus élevé que le diesel des voitures. Selon un institut de recherche néerlandais, l'approche la plus écologique pour un navire consiste à installer des filtres à particules et des systèmes de réduction catalytique sélective (SCR) qui convertissent les oxydes d’azote en azote et en eau.  Les solutions ne sont pas seulement technologiques. Ralentissement des navires à l'entrée des ports, pilotage plus efficace et économe en carburant. A Long Beach et au port de Los Angeles, les frais de stationnement sont réduits de 25% pour récompenser la vitesse réduite à l'approche. Le trolleybus est un véhicule électrique qui ne rejette   aucun gaz nocif. En prenant en compte l’impact de la production d’électricité, on peut estimer la production moyenne de CO2 d’un trolleybus à 4 g/km/voyageur contre 40 pour un autobus et 60 pour une automobile.  Un trolleybus parcourt une distance supérieure de 30% à celle d’un autobus. Ainsi, le parc nécessaire en trolleybus serait inférieur de 5 à 7% à celui requis par un service en autobus. Le rendement énergétique du trolleybus s'élève à 9,8 Mégajoules/km-véhicule contre plus de 24 pour l'autobus. Autre avantage du trolleybus, notamment par rapport aux autobus électriques : il s’affranchit des batteries, qui constituent non seulement un poids mort, mais aussi de la question de leur renouvellement.  Le trolleybus moderne est équipé d’un système de freinage à récupération d’énergie ce qui lui permet de réinjecter du courant dans les lignes aériennes;  ainsi à Lyon, trois trolleybus descendant fournissent par la récupération l’énergie nécessaire à un véhicule montant. Dans une approche qualitative globale de l’environnement urbain, la présence de ligne aérienne est compensée par une réduction importante des nuisances sonores et olfactives ainsi que l’absence de rejets de particules. Jamais les voitures vendues sur les marchés français et européens n'ont eu autant de chevaux. La tendance est encore plus nette au niveau européen. Berceau des constructeurs de grosses cylindrées, l'Allemagne redouterait en réalité que les données d'accidentalité soient une contre-publicité pour la vitesse. Sur l'ensemble du réseau allemand, il n'y a qu'un faible tronçon de 388 km où la vitesse est libre, l'accidentalité y est trois fois plus forte que celle en France. La voiture électrique est une voiture onéreuse du fait de l’utilisation de batteries sophistiquées. Avant que son utilisation se généralise et atteigne des prix abordables, il serait judicieux, plutôt que de fabriquer des voitures inutilement performantes, d’assurer la transition en fabriquant des véhicules fonctionnant avec une très faible consommation de carburants et si possible de biocarburants. Alors qu’en France aucun véhicule particulier n’est censé dépasser la vitesse de 130 km/h, les constructeurs offrent des véhicules qui sont capables de vitesses très supérieures à cette limite. Pour une vitesse max de 140 km/h par exemple, une voiture de type Peugeot 308 pourrait se « contenter » d’un moteur de 43 CV (32 kW) ; afin qu’elle soit capable de monter aisément les côtes, sa puissance pourrait être de 50 kW (70 CV). On imagine sans peine les économies de carburant et de coût qu’il serait possible de réaliser …  Une voiture de type Peugeot 308 a besoin de 25 KW pour rouler à 130 km/h. Si elle était équipée en tout électrique avec une batterie de 30 kWh son autonomie serait donc limitée à 1,2 h à cette vitesse, soit 156 km. Ceci démontre que la voiture tout électrique n’est pas un véhicule routier. Elle le deviendra le jour où l’on pourra produire l’électricité à bord avec une pile à combustible.  Ce problème d’autonomie limitée par la capacité de la batterie a conduit les constructeurs à limiter la puissance des moteurs électriques à la valeur que nous avons calculée plus haut, autour de 50 kW. Cette unanimité autour de 60 kW, imposée par la faible capacité spécifique des batteries, pourrait devenir la norme aussi pour les voitures à moteurs thermiques.  Les experts de l’ADEME n’éludent pas la pollution générée pendant sa phase de fabrication : "La voiture électrique consomme moins d'énergie que la voiture thermique car sa chaîne de traction présente un excellent rendement énergétique. Malgré cela, sur l’ensemble de son cycle de vie, la consommation énergétique d’un véhicule électrique est globalement proche de celle d’un véhicule diesel." En cause : la fabrication des batteries extrêmement énergivore.  Sur l'ensemble de son cycle de vie, le véhicule électrique émet l'équivalent de 9 tonnes de CO2 contre 22 tonnes pour un véhicule thermique, selon l'ADEME. Ces chiffres sont donnés pour la France où l’électricité, qui provient aux trois-quarts du nucléaire, est peu émettrice de CO2. Si la voiture électrique n'émet pas quand elle roule de composés organiques volatils ou d'oxyde d'azote même sans pot d'échappement, elle émet des particules fines issues de l'usure des pneus, des plaquettes de frein, des routes. Cette abrasion est responsable de 41% des émissions du secteur du transport routier.  Les méthodes d'extraction du lithium et du cobalt, utilisées pour fabriquer les batteries peuvent poser problème non seulement sur le plan environnemental mais aussi sur le plan éthique en Amérique du Sud, (Extraction polluante du lithium)et en République démocratique du Congo, qui a fourni en 2017 les deux tiers des exportations mondiales de cobalt, les mines sont parfois exploitées dans des conditions déplorables par une main d'œuvre notamment composée d'enfants. La France et le Royaume-Uni ont annoncé leur intention d'interdire les ventes de voitures à moteur à combustion à horizon 2040. La Ville de Paris bannit les vieux diesels. Mais il y a des obstacles : -	 le premier est la batterie, car la voiture électrique nécessite des métaux qui jouent un rôle clef dans leur fabrication. Le prix du lithium a triplé en trois ans, celui du cobalt a pratiquement doublé en un an. Quel sera le prix de la batterie si toutes les voitures sont équipées de moteurs électriques ? Et surtout leurs ressources en cobalt et lithium ne sont pas infinies.  -	le deuxième qu'est la production d'électricité. Car la charge des batteries en exige d'énormes quantités. Un ordre de grandeur : pour charger 1 % du parc français la nuit, il faut pratiquement la production d'une tranche nucléaire.  -	le troisième est le transport de cette électricité. Un dépôt de 200 bus à charger la nuit demande la puissance de 50 immeubles de cinq étages.  Carlos Tavares, patron de PSA, déplore que depuis 2 ans, dans le sillage du "Dieselgate" les gouvernements aient pris des positions de plus en plus radicales qui changent la nature des réglementations. "On est en train d’évoluer vers un monde où on nous instruit d’aller dans la direction du véhicule électrique". Si la feuille de route de PSA qui prévoit que 50% de la gamme sera électrifiée en 2020 et 80% en 2023 montre qu’il n’a pas d’état d’âme en tant que dirigeant, il s’en inquiète "en tant que citoyen" : "Qui traite la question de la mobilité propre dans sa globalité ? Comment est-ce que nous allons produire plus d’énergie électrique propre ? Comment faire pour que l’empreinte carbone de fabrication d’une batterie du véhicule électrique ne soit pas un désastre écologique ? Comment faire en sorte que le recyclage d’une batterie ne soit pas un désastre écologique ? Comment trouver suffisamment de matière première rare pour faire les cellules et les chimies des batteries dans la durée ? Qui aujourd’hui est en train de se poser la question de manière suffisamment large d’un point de vue sociétale pour tenir compte de l’ensemble de ces paramètres  "Pendant un siècle les Chinois ont couru après le moteur à combustion interne en versant des royalties à l’occident. Là, ils ont trouvé le point de rupture et maintenant ils prennent le lead sur le véhicule électrique qui est le symétrique pour le prochain siècle de ce qu’ils ont vécu au cours du précédent", a dit Carlos Tavares. Dans le cadre de leur engagement sur la 40ème Route du Rhum 2018, l’entreprise Leyton et son skipper, Arthur Le Vaillant, ont souhaité quantifier les impacts carbone et environnementaux de leur bateau. Ils ont fait appel à E6 pour réaliser cette mission. Un Class40 est un voilier monocoque de 12,2 m. Sa fabrication génère de l’ordre de 25 tonnes eq CO2, dont 90% de l’empreinte carbone est liée à la fabrication des matières premières. On peut réduire l’impact carbone en prolongeant la durée de vie des bateaux. La 40e édition du rallye Dakar (ex Paris Dakar) s’est déroulée avec un départ de Lima, au Pérou. Plus de 500 pilotes d'autos, de motos, de quads, ou de camions ont parcouru près de 9 000 km à travers le Pérou, la Bolivie et l'Argentine où l'arrivée s’est faite le 20 janvier à Cordoba. Le Dakar fait l'objet de nombreuses critiques en matière d'environnement. " C'est évidemment l'influence que peut avoir ce spectacle médiatique sur le dérèglement climatique mais aussi sur les écosystèmes au travers du passage de ces fous du volant avec des voitures et des camions qui empruntent des milieux fragiles. Il y a l'impact direct : le Dakar va émettre directement près de 40 000 tonnes de CO2. Nous sommes entrés dans l'ère du dérèglement climatique il serait souhaitable que les spectacles mis en avant soient au diapason de la contrainte climatique. L'impact direct, on le constate avec effroi, ce sont des décès d'enfants et de personnes qui traversent les rues de leurs villages et qui subissent les vitesses inouïes de ces véhicules. Quand le Dakar est passé au Chili il y a quelques années près de 180 sites archéologiques ont été détruits ou endommagés par les véhicules passant. Des fresques qui dataient de plusieurs centaines d'années ont été détruites.  Dès qu’on pense à un Grand Prix de F1, on pense pollution. Une chose est certaine : elles polluent beaucoup. Un Grand Prix, c’est une vingtaine de ces bolides qui crachent une quantité féroce de CO2, le tout dans un fracas motorisé digne des pires enfers. La FOTA a comptabilisé quelques 9900 tonnes de CO2 recraché par course. En comparaison, un avion qui voudrait recracher une telle quantité de CO2 devrait effectuer au moins 10 fois un aller-retour Paris-New-York. 918 courses ont été disputées depuis 1950, dans le seul cadre d’un Grand Prix (on ne comptabilise donc pas les multiples courses et essais) on dresse vite le constat de l’impact que la pratique de la course en formule 1 peut avoir sur l’environnement. Les courses de formule 1 et le Dakar devraient être purement et simplement supprimées. Le groupe écologiste de Paris a demandé  à la maire PS Anne Hidalgo «des comptes sur le coût écologique et financier» du ePrix de Formule E (monoplaces électriques), organisé depuis 2016 dans la capitale : En 2016, on a pu voir des bolides entièrement électriques foncer à 200km/h dans les rues de la capitale. Le circuit avait été asphalté en conséquence, le goudronnage du quartier des Invalides, a été vécu par certains comme un véritable désastre écologique. Il serait préférable que ce type de course sur un circuit déjà asphalté. Dès 2009, Génération Ecologie dénonçait « l’irresponsabilité environnementale des organisateurs du Tour de France ». Ils étaient alors pointés du doigt pour ne pas s’imposer de précautions en matière d’environnement et de pollution.  Le Tour est une belle course à vélo au gré de paysages magnifiques, mais sur le terrain, son empreinte carbone et écologique est à la hauteur du 3e événement sportif au monde, après les Jeux Olympiques et la Coupe du Monde de football. Quelque deux cents coureurs cyclistes, des centaines de voitures suiveuses, des camions techniques (service d’ordre, secours, presse…), des bus qui parcourent des milliers de kilomètres le long de la « Grande Boucle », des hélicoptères, des avions, sans compter les 10-12 millions de spectateurs qui se déplacent, en camping-cars ou en voitures, pour admirer la course le long des routes : l’empreinte écologique du tour est énorme et cette célèbre course illustre bien la difficulté à gérer les effets environnementaux d’événements sportifs majeurs.  L’une des attractions préférées du public, c’est la distribution de cadeaux par la caravane publicitaire : des « pognes » pleines de cadeaux, de porte-clés, d’échantillons, de confiseries qui sont jetés au public pendant le Tour. Au total, environ 14 millions de petits objets, les goodies, validés par l’organisation du Tour de France, sont distribués, jetés depuis des véhicules en mouvement. Des mesures devraient être prises pour réduire voire supprimer la caravane publicitaire La Cour des comptes critique la gestion des domaines skiables, de plus en plus vulnérables au réchauffement climatique. Après une première mise en garde il y a sept ans, la Cour des comptes s’est de nouveau alarmée il y a quelques jours de la « vulnérabilité croissante » des stations de ski des Alpes du Nord face au réchauffement climatique. Dans leur rapport annuel, les magistrats dénoncent les réponses inadaptées des gestionnaires des domaines skiables. Entre 2015 et 2017, la Cour a contrôlé la gestion de dix-sept domaines skiables, dont Chamonix, Megève, Courchevel et Tignes. Le rapport constate « l’aggravation de certains déséquilibres » liés à un modèle de développement « ayant atteint ses limites ». Pointant des investissements « privilégiant le court terme », elle dénonce notamment la généralisation de l’enneigement artificiel, présenté comme une solution « partielle et onéreuse ». Confrontées à une pénurie de neige ces dernières années, les stations y ont eu abondamment recours, ce qui pose des problèmes d’approvisionnement en eau. Actuellement, 30 millions de m3 d’eau sont utilisés chaque année pour fabriquer de la neige de culture pour les canons. Le recours de plus en plus systématique à ce palliatif soulève de nombreuses questions. Considérée parfois comme une garantie pour assurer la saison, la neige artificielle – qui nécessite de lourds investissements – ne peut être cependant utilisée comme la solution miracle. Malgré le coût important de l’enneigement artificiel, les stations sont de plus en plus nombreuses à s’équiper pour garantir à leurs visiteurs un enneigement de bonne qualité. Cette augmentation de l’enneigement artificiel a plusieurs conséquences sur l’environnement : • l’utilisation des ressources en eau  • une consommation d'énergie très importante (les 10.000 canons à neige français consomment 108 millions de kWh) • une pollution éventuelle par les additifs ajoutés dans l’eau  • une érosion supplémentaire due à la quantité de neige produite. Cette neige artificielle est 50 fois plus dure et 4 fois plus dense que la neige naturelle, ce qui favorise l’érosion.